window.search = Object.assign(window.search, JSON.parse('{"doc_urls":["title-page.html#the-rust-programming-language","foreword.html#foreword","ch00-00-introduction.html#introduction","ch00-00-introduction.html#who-rust-is-for","ch00-00-introduction.html#teams-of-developers","ch00-00-introduction.html#students","ch00-00-introduction.html#companies","ch00-00-introduction.html#open-source-developers","ch00-00-introduction.html#people-who-value-speed-and-stability","ch00-00-introduction.html#who-this-book-is-for","ch00-00-introduction.html#how-to-use-this-book","ch00-00-introduction.html#source-code","ch01-00-getting-started.html#getting-started","ch01-01-installation.html#installation","ch01-01-installation.html#command-line-notation","ch01-01-installation.html#installing-rustup-on-linux-or-macos","ch01-01-installation.html#installing-rustup-on-windows","ch01-01-installation.html#troubleshooting","ch01-01-installation.html#updating-and-uninstalling","ch01-01-installation.html#reading-the-local-documentation","ch01-01-installation.html#using-text-editors-and-ides","ch01-01-installation.html#working-offline-with-this-book","ch01-02-hello-world.html#hello-world","ch01-02-hello-world.html#project-directory-setup","ch01-02-hello-world.html#rust-program-basics","ch01-02-hello-world.html#the-anatomy-of-a-rust-program","ch01-02-hello-world.html#compilation-and-execution","ch01-03-hello-cargo.html#hello-cargo","ch01-03-hello-cargo.html#creating-a-project-with-cargo","ch01-03-hello-cargo.html#building-and-running-a-cargo-project","ch01-03-hello-cargo.html#building-for-release","ch01-03-hello-cargo.html#leveraging-cargos-conventions","ch01-03-hello-cargo.html#summary","ch02-00-guessing-game-tutorial.html#programming-a-guessing-game","ch02-00-guessing-game-tutorial.html#setting-up-a-new-project","ch02-00-guessing-game-tutorial.html#processing-a-guess","ch02-00-guessing-game-tutorial.html#storing-values-with-variables","ch02-00-guessing-game-tutorial.html#receiving-user-input","ch02-00-guessing-game-tutorial.html#handling-potential-failure-with-result","ch02-00-guessing-game-tutorial.html#printing-values-with-println-placeholders","ch02-00-guessing-game-tutorial.html#testing-the-first-part","ch02-00-guessing-game-tutorial.html#generating-a-secret-number","ch02-00-guessing-game-tutorial.html#increasing-functionality-with-a-crate","ch02-00-guessing-game-tutorial.html#generating-a-random-number","ch02-00-guessing-game-tutorial.html#comparing-the-guess-to-the-secret-number","ch02-00-guessing-game-tutorial.html#allowing-multiple-guesses-with-looping","ch02-00-guessing-game-tutorial.html#quitting-after-a-correct-guess","ch02-00-guessing-game-tutorial.html#handling-invalid-input","ch02-00-guessing-game-tutorial.html#summary","ch03-00-common-programming-concepts.html#common-programming-concepts","ch03-01-variables-and-mutability.html#variables-and-mutability","ch03-01-variables-and-mutability.html#declaring-constants","ch03-01-variables-and-mutability.html#shadowing","ch03-02-data-types.html#data-types","ch03-02-data-types.html#scalar-types","ch03-02-data-types.html#compound-types","ch03-03-how-functions-work.html#functions","ch03-03-how-functions-work.html#parameters","ch03-03-how-functions-work.html#statements-and-expressions","ch03-03-how-functions-work.html#functions-with-return-values","ch03-04-comments.html#comments","ch03-05-control-flow.html#control-flow","ch03-05-control-flow.html#if-expressions","ch03-05-control-flow.html#repetition-with-loops","ch03-05-control-flow.html#summary","ch04-00-understanding-ownership.html#understanding-ownership","ch04-01-what-is-ownership.html#what-is-ownership","ch04-01-what-is-ownership.html#the-stack-and-the-heap","ch04-01-what-is-ownership.html#ownership-rules","ch04-01-what-is-ownership.html#variable-scope","ch04-01-what-is-ownership.html#the-string-type","ch04-01-what-is-ownership.html#memory-and-allocation","ch04-01-what-is-ownership.html#ownership-and-functions","ch04-01-what-is-ownership.html#return-values-and-scope","ch04-02-references-and-borrowing.html#references-and-borrowing","ch04-02-references-and-borrowing.html#mutable-references","ch04-02-references-and-borrowing.html#dangling-references","ch04-02-references-and-borrowing.html#the-rules-of-references","ch04-03-slices.html#the-slice-type","ch04-03-slices.html#string-slices","ch04-03-slices.html#other-slices","ch04-03-slices.html#summary","ch05-00-structs.html#using-structs-to-structure-related-data","ch05-01-defining-structs.html#defining-and-instantiating-structs","ch05-01-defining-structs.html#using-the-field-init-shorthand","ch05-01-defining-structs.html#creating-instances-with-struct-update-syntax","ch05-01-defining-structs.html#creating-different-types-with-tuple-structs","ch05-01-defining-structs.html#defining-unit-like-structs","ch05-01-defining-structs.html#ownership-of-struct-data","ch05-02-example-structs.html#an-example-program-using-structs","ch05-02-example-structs.html#refactoring-with-tuples","ch05-02-example-structs.html#refactoring-with-structs","ch05-02-example-structs.html#adding-functionality-with-derived-traits","ch05-03-method-syntax.html#methods","ch05-03-method-syntax.html#method-syntax","ch05-03-method-syntax.html#wheres-the---operator","ch05-03-method-syntax.html#methods-with-more-parameters","ch05-03-method-syntax.html#associated-functions","ch05-03-method-syntax.html#multiple-impl-blocks","ch05-03-method-syntax.html#summary","ch06-00-enums.html#enums-and-pattern-matching","ch06-01-defining-an-enum.html#defining-an-enum","ch06-01-defining-an-enum.html#enum-values","ch06-01-defining-an-enum.html#the-option-enum","ch06-02-match.html#the-match-control-flow-construct","ch06-02-match.html#patterns-that-bind-to-values","ch06-02-match.html#the-option-match-pattern","ch06-02-match.html#matches-are-exhaustive","ch06-02-match.html#catch-all-patterns-and-the-_-placeholder","ch06-03-if-let.html#concise-control-flow-with-if-let-and-let-else","ch06-03-if-let.html#staying-on-the-happy-path-with-letelse","ch06-03-if-let.html#summary","ch07-00-managing-growing-projects-with-packages-crates-and-modules.html#packages-crates-and-modules","ch07-01-packages-and-crates.html#packages-and-crates","ch07-02-defining-modules-to-control-scope-and-privacy.html#control-scope-and-privacy-with-modules","ch07-02-defining-modules-to-control-scope-and-privacy.html#modules-cheat-sheet","ch07-02-defining-modules-to-control-scope-and-privacy.html#grouping-related-code-in-modules","ch07-03-paths-for-referring-to-an-item-in-the-module-tree.html#paths-for-referring-to-an-item-in-the-module-tree","ch07-03-paths-for-referring-to-an-item-in-the-module-tree.html#exposing-paths-with-the-pub-keyword","ch07-03-paths-for-referring-to-an-item-in-the-module-tree.html#starting-relative-paths-with-super","ch07-03-paths-for-referring-to-an-item-in-the-module-tree.html#making-structs-and-enums-public","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#bringing-paths-into-scope-with-the-use-keyword","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#creating-idiomatic-use-paths","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#providing-new-names-with-the-as-keyword","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#re-exporting-names-with-pub-use","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#using-external-packages","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#using-nested-paths-to-clean-up-use-lists","ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#importing-items-with-the-glob-operator","ch07-05-separating-modules-into-different-files.html#separating-modules-into-different-files","ch07-05-separating-modules-into-different-files.html#alternate-file-paths","ch07-05-separating-modules-into-different-files.html#summary","ch08-00-common-collections.html#common-collections","ch08-01-vectors.html#storing-lists-of-values-with-vectors","ch08-01-vectors.html#creating-a-new-vector","ch08-01-vectors.html#updating-a-vector","ch08-01-vectors.html#reading-elements-of-vectors","ch08-01-vectors.html#iterating-over-the-values-in-a-vector","ch08-01-vectors.html#using-an-enum-to-store-multiple-types","ch08-01-vectors.html#dropping-a-vector-drops-its-elements","ch08-02-strings.html#storing-utf-8-encoded-text-with-strings","ch08-02-strings.html#defining-strings","ch08-02-strings.html#creating-a-new-string","ch08-02-strings.html#updating-a-string","ch08-02-strings.html#indexing-into-strings","ch08-02-strings.html#slicing-strings","ch08-02-strings.html#iterating-over-strings","ch08-02-strings.html#handling-the-complexities-of-strings","ch08-03-hash-maps.html#storing-keys-with-associated-values-in-hash-maps","ch08-03-hash-maps.html#creating-a-new-hash-map","ch08-03-hash-maps.html#accessing-values-in-a-hash-map","ch08-03-hash-maps.html#managing-ownership-in-hash-maps","ch08-03-hash-maps.html#updating-a-hash-map","ch08-03-hash-maps.html#hashing-functions","ch08-03-hash-maps.html#summary","ch09-00-error-handling.html#error-handling","ch09-01-unrecoverable-errors-with-panic.html#unrecoverable-errors-with-panic","ch09-01-unrecoverable-errors-with-panic.html#unwinding-the-stack-or-aborting-in-response-to-a-panic","ch09-02-recoverable-errors-with-result.html#recoverable-errors-with-result","ch09-02-recoverable-errors-with-result.html#matching-on-different-errors","ch09-02-recoverable-errors-with-result.html#propagating-errors","ch09-03-to-panic-or-not-to-panic.html#to-panic-or-not-to-panic","ch09-03-to-panic-or-not-to-panic.html#examples-prototype-code-and-tests","ch09-03-to-panic-or-not-to-panic.html#when-you-have-more-information-than-the-compiler","ch09-03-to-panic-or-not-to-panic.html#guidelines-for-error-handling","ch09-03-to-panic-or-not-to-panic.html#custom-types-for-validation","ch09-03-to-panic-or-not-to-panic.html#summary","ch10-00-generics.html#generic-types-traits-and-lifetimes","ch10-00-generics.html#removing-duplication-by-extracting-a-function","ch10-01-syntax.html#generic-data-types","ch10-01-syntax.html#in-function-definitions","ch10-01-syntax.html#in-struct-definitions","ch10-01-syntax.html#in-enum-definitions","ch10-01-syntax.html#in-method-definitions","ch10-01-syntax.html#performance-of-code-using-generics","ch10-02-traits.html#defining-shared-behavior-with-traits","ch10-02-traits.html#defining-a-trait","ch10-02-traits.html#implementing-a-trait-on-a-type","ch10-02-traits.html#using-default-implementations","ch10-02-traits.html#using-traits-as-parameters","ch10-02-traits.html#returning-types-that-implement-traits","ch10-02-traits.html#using-trait-bounds-to-conditionally-implement-methods","ch10-03-lifetime-syntax.html#validating-references-with-lifetimes","ch10-03-lifetime-syntax.html#dangling-references","ch10-03-lifetime-syntax.html#the-borrow-checker","ch10-03-lifetime-syntax.html#generic-lifetimes-in-functions","ch10-03-lifetime-syntax.html#lifetime-annotation-syntax","ch10-03-lifetime-syntax.html#in-function-signatures","ch10-03-lifetime-syntax.html#relationships","ch10-03-lifetime-syntax.html#in-struct-definitions","ch10-03-lifetime-syntax.html#lifetime-elision","ch10-03-lifetime-syntax.html#in-method-definitions","ch10-03-lifetime-syntax.html#the-static-lifetime","ch10-03-lifetime-syntax.html#generic-type-parameters-trait-bounds-and-lifetimes","ch10-03-lifetime-syntax.html#summary","ch11-00-testing.html#writing-automated-tests","ch11-01-writing-tests.html#how-to-write-tests","ch11-01-writing-tests.html#structuring-test-functions","ch11-01-writing-tests.html#checking-results-with-assert","ch11-01-writing-tests.html#testing-equality-with-assert_eq-and-assert_ne","ch11-01-writing-tests.html#adding-custom-failure-messages","ch11-01-writing-tests.html#checking-for-panics-with-should_panic","ch11-01-writing-tests.html#using-result-in-tests","ch11-02-running-tests.html#controlling-how-tests-are-run","ch11-02-running-tests.html#running-tests-in-parallel-or-consecutively","ch11-02-running-tests.html#showing-function-output","ch11-02-running-tests.html#running-a-subset-of-tests-by-name","ch11-02-running-tests.html#ignoring-tests-unless-specifically-requested","ch11-03-test-organization.html#test-organization","ch11-03-test-organization.html#unit-tests","ch11-03-test-organization.html#integration-tests","ch11-03-test-organization.html#summary","ch12-00-an-io-project.html#an-io-project-building-a-command-line-program","ch12-01-accepting-command-line-arguments.html#accepting-command-line-arguments","ch12-01-accepting-command-line-arguments.html#reading-the-argument-values","ch12-01-accepting-command-line-arguments.html#the-args-function-and-invalid-unicode","ch12-01-accepting-command-line-arguments.html#saving-the-argument-values-in-variables","ch12-02-reading-a-file.html#reading-a-file","ch12-03-improving-error-handling-and-modularity.html#refactoring-to-improve-modularity-and-error-handling","ch12-03-improving-error-handling-and-modularity.html#separating-concerns-in-binary-projects","ch12-03-improving-error-handling-and-modularity.html#the-trade-offs-of-using-clone","ch12-03-improving-error-handling-and-modularity.html#fixing-the-error-handling","ch12-03-improving-error-handling-and-modularity.html#extracting-logic-from-main","ch12-03-improving-error-handling-and-modularity.html#splitting-code-into-a-library-crate","ch12-04-testing-the-librarys-functionality.html#adding-functionality-with-test-driven-development","ch12-04-testing-the-librarys-functionality.html#writing-a-failing-test","ch12-04-testing-the-librarys-functionality.html#writing-code-to-pass-the-test","ch12-05-working-with-environment-variables.html#working-with-environment-variables","ch12-05-working-with-environment-variables.html#writing-a-failing-test-for-case-insensitive-search","ch12-05-working-with-environment-variables.html#implementing-the-search_case_insensitive-function","ch12-06-writing-to-stderr-instead-of-stdout.html#redirecting-errors-to-standard-error","ch12-06-writing-to-stderr-instead-of-stdout.html#checking-where-errors-are-written","ch12-06-writing-to-stderr-instead-of-stdout.html#printing-errors-to-standard-error","ch12-06-writing-to-stderr-instead-of-stdout.html#summary","ch13-00-functional-features.html#functional-language-features-iterators-and-closures","ch13-01-closures.html#closures","ch13-01-closures.html#capturing-the-environment","ch13-01-closures.html#inferring-and-annotating-closure-types","ch13-01-closures.html#capturing-references-or-moving-ownership","ch13-01-closures.html#moving-captured-values-out-of-closures","ch13-02-iterators.html#processing-a-series-of-items-with-iterators","ch13-02-iterators.html#the-iterator-trait-and-the-next-method","ch13-02-iterators.html#methods-that-consume-the-iterator","ch13-02-iterators.html#methods-that-produce-other-iterators","ch13-02-iterators.html#closures-that-capture-their-environment","ch13-03-improving-our-io-project.html#improving-our-io-project","ch13-03-improving-our-io-project.html#removing-a-clone-using-an-iterator","ch13-03-improving-our-io-project.html#clarifying-code-with-iterator-adapters","ch13-03-improving-our-io-project.html#choosing-between-loops-and-iterators","ch13-04-performance.html#performance-in-loops-vs-iterators","ch13-04-performance.html#summary","ch14-00-more-about-cargo.html#more-about-cargo-and-cratesio","ch14-01-release-profiles.html#customizing-builds-with-release-profiles","ch14-02-publishing-to-crates-io.html#publishing-a-crate-to-cratesio","ch14-02-publishing-to-crates-io.html#making-useful-documentation-comments","ch14-02-publishing-to-crates-io.html#exporting-a-convenient-public-api","ch14-02-publishing-to-crates-io.html#setting-up-a-cratesio-account","ch14-02-publishing-to-crates-io.html#adding-metadata-to-a-new-crate","ch14-02-publishing-to-crates-io.html#publishing-to-cratesio","ch14-02-publishing-to-crates-io.html#publishing-a-new-version-of-an-existing-crate","ch14-02-publishing-to-crates-io.html#deprecating-versions-from-cratesio","ch14-03-cargo-workspaces.html#cargo-workspaces","ch14-03-cargo-workspaces.html#creating-a-workspace","ch14-03-cargo-workspaces.html#creating-the-second-package-in-the-workspace","ch14-03-cargo-workspaces.html#depending-on-an-external-package","ch14-03-cargo-workspaces.html#adding-a-test-to-a-workspace","ch14-04-installing-binaries.html#installing-binaries-with-cargo-install","ch14-05-extending-cargo.html#extending-cargo-with-custom-commands","ch14-05-extending-cargo.html#summary","ch15-00-smart-pointers.html#smart-pointers","ch15-01-box.html#using-box-to-point-to-data-on-the-heap","ch15-01-box.html#storing-data-on-the-heap","ch15-01-box.html#enabling-recursive-types-with-boxes","ch15-02-deref.html#treating-smart-pointers-like-regular-references","ch15-02-deref.html#following-the-reference-to-the-value","ch15-02-deref.html#using-box-like-a-reference","ch15-02-deref.html#defining-our-own-smart-pointer","ch15-02-deref.html#implementing-the-deref-trait","ch15-02-deref.html#using-deref-coercion-in-functions-and-methods","ch15-02-deref.html#handling-deref-coercion-with-mutable-references","ch15-03-drop.html#running-code-on-cleanup-with-the-drop-trait","ch15-04-rc.html#rc-the-reference-counted-smart-pointer","ch15-04-rc.html#sharing-data","ch15-04-rc.html#cloning-to-increase-the-reference-count","ch15-05-interior-mutability.html#refcell-and-the-interior-mutability-pattern","ch15-05-interior-mutability.html#enforcing-borrowing-rules-at-runtime","ch15-05-interior-mutability.html#using-interior-mutability","ch15-05-interior-mutability.html#allowing-multiple-owners-of-mutable-data","ch15-06-reference-cycles.html#reference-cycles-can-leak-memory","ch15-06-reference-cycles.html#creating-a-reference-cycle","ch15-06-reference-cycles.html#preventing-reference-cycles-using-weak","ch15-06-reference-cycles.html#summary","ch16-00-concurrency.html#fearless-concurrency","ch16-01-threads.html#using-threads-to-run-code-simultaneously","ch16-01-threads.html#creating-a-new-thread-with-spawn","ch16-01-threads.html#waiting-for-all-threads-to-finish","ch16-01-threads.html#using-move-closures-with-threads","ch16-02-message-passing.html#transfer-data-between-threads-with-message-passing","ch16-02-message-passing.html#transferring-ownership-through-channels","ch16-02-message-passing.html#sending-multiple-values","ch16-02-message-passing.html#creating-multiple-producers","ch16-03-shared-state.html#shared-state-concurrency","ch16-03-shared-state.html#controlling-access-with-mutexes","ch16-03-shared-state.html#comparing-refcellrc-and-mutexarc","ch16-04-extensible-concurrency-sync-and-send.html#extensible-concurrency-with-send-and-sync","ch16-04-extensible-concurrency-sync-and-send.html#transferring-ownership-between-threads","ch16-04-extensible-concurrency-sync-and-send.html#accessing-from-multiple-threads","ch16-04-extensible-concurrency-sync-and-send.html#implementing-send-and-sync-manually-is-unsafe","ch16-04-extensible-concurrency-sync-and-send.html#summary","ch17-00-async-await.html#fundamentals-of-asynchronous-programming-async-await-futures-and-streams","ch17-00-async-await.html#parallelism-and-concurrency","ch17-01-futures-and-syntax.html#futures-and-the-async-syntax","ch17-01-futures-and-syntax.html#our-first-async-program","ch17-01-futures-and-syntax.html#defining-the-page_title-function","ch17-01-futures-and-syntax.html#executing-an-async-function-with-a-runtime","ch17-01-futures-and-syntax.html#racing-two-urls-against-each-other-concurrently","ch17-02-concurrency-with-async.html#applying-concurrency-with-async","ch17-02-concurrency-with-async.html#creating-a-new-task-with-spawn_task","ch17-02-concurrency-with-async.html#sending-data-between-two-tasks-using-message-passing","ch17-03-more-futures.html#yielding-control-to-the-runtime","ch17-03-more-futures.html#building-our-own-async-abstractions","ch17-04-streams.html#streams-futures-in-sequence","ch17-05-traits-for-async.html#a-closer-look-at-the-traits-for-async","ch17-05-traits-for-async.html#the-future-trait","ch17-05-traits-for-async.html#the-pin-type-and-the-unpin-trait","ch17-05-traits-for-async.html#the-stream-trait","ch17-06-futures-tasks-threads.html#putting-it-all-together-futures-tasks-and-threads","ch17-06-futures-tasks-threads.html#summary","ch18-00-oop.html#object-oriented-programming-features","ch18-01-what-is-oo.html#characteristics-of-object-oriented-languages","ch18-01-what-is-oo.html#objects-contain-data-and-behavior","ch18-01-what-is-oo.html#encapsulation-that-hides-implementation-details","ch18-01-what-is-oo.html#inheritance-as-a-type-system-and-as-code-sharing","ch18-01-what-is-oo.html#polymorphism","ch18-02-trait-objects.html#using-trait-objects-to-abstract-over-shared-behavior","ch18-02-trait-objects.html#defining-a-trait-for-common-behavior","ch18-02-trait-objects.html#implementing-the-trait","ch18-02-trait-objects.html#performing-dynamic-dispatch","ch18-03-oo-design-patterns.html#implementing-an-object-oriented-design-pattern","ch18-03-oo-design-patterns.html#attempting-traditional-object-oriented-style","ch18-03-oo-design-patterns.html#why-not-an-enum","ch18-03-oo-design-patterns.html#encoding-states-and-behavior-as-types","ch18-03-oo-design-patterns.html#summary","ch19-00-patterns.html#patterns-and-matching","ch19-01-all-the-places-for-patterns.html#all-the-places-patterns-can-be-used","ch19-01-all-the-places-for-patterns.html#match-arms","ch19-01-all-the-places-for-patterns.html#let-statements","ch19-01-all-the-places-for-patterns.html#conditional-if-let-expressions","ch19-01-all-the-places-for-patterns.html#while-let-conditional-loops","ch19-01-all-the-places-for-patterns.html#for-loops","ch19-01-all-the-places-for-patterns.html#function-parameters","ch19-02-refutability.html#refutability-whether-a-pattern-might-fail-to-match","ch19-03-pattern-syntax.html#pattern-syntax","ch19-03-pattern-syntax.html#matching-literals","ch19-03-pattern-syntax.html#matching-named-variables","ch19-03-pattern-syntax.html#matching-multiple-patterns","ch19-03-pattern-syntax.html#matching-ranges-of-values-with-","ch19-03-pattern-syntax.html#destructuring-to-break-apart-values","ch19-03-pattern-syntax.html#ignoring-values-in-a-pattern","ch19-03-pattern-syntax.html#adding-conditionals-with-match-guards","ch19-03-pattern-syntax.html#using--bindings","ch19-03-pattern-syntax.html#summary","ch20-00-advanced-features.html#advanced-features","ch20-01-unsafe-rust.html#unsafe-rust","ch20-01-unsafe-rust.html#performing-unsafe-superpowers","ch20-01-unsafe-rust.html#dereferencing-a-raw-pointer","ch20-01-unsafe-rust.html#calling-an-unsafe-function-or-method","ch20-01-unsafe-rust.html#accessing-or-modifying-a-mutable-static-variable","ch20-01-unsafe-rust.html#implementing-an-unsafe-trait","ch20-01-unsafe-rust.html#accessing-fields-of-a-union","ch20-01-unsafe-rust.html#using-miri-to-check-unsafe-code","ch20-01-unsafe-rust.html#using-unsafe-code-correctly","ch20-02-advanced-traits.html#advanced-traits","ch20-02-advanced-traits.html#defining-traits-with-associated-types","ch20-02-advanced-traits.html#using-default-generic-parameters-and-operator-overloading","ch20-02-advanced-traits.html#disambiguating-between-identically-named-methods","ch20-02-advanced-traits.html#using-supertraits","ch20-02-advanced-traits.html#implementing-external-traits-with-the-newtype-pattern","ch20-03-advanced-types.html#advanced-types","ch20-03-advanced-types.html#type-safety-and-abstraction-with-the-newtype-pattern","ch20-03-advanced-types.html#type-synonyms-and-type-aliases","ch20-03-advanced-types.html#the-never-type-that-never-returns","ch20-03-advanced-types.html#dynamically-sized-types-and-the-sized-trait","ch20-04-advanced-functions-and-closures.html#advanced-functions-and-closures","ch20-04-advanced-functions-and-closures.html#function-pointers","ch20-04-advanced-functions-and-closures.html#returning-closures","ch20-05-macros.html#macros","ch20-05-macros.html#the-difference-between-macros-and-functions","ch20-05-macros.html#declarative-macros-for-general-metaprogramming","ch20-05-macros.html#procedural-macros-for-generating-code-from-attributes","ch20-05-macros.html#custom-derive-macros","ch20-05-macros.html#attribute-like-macros","ch20-05-macros.html#function-like-macros","ch20-05-macros.html#summary","ch21-00-final-project-a-web-server.html#final-project-building-a-multithreaded-web-server","ch21-01-single-threaded.html#building-a-single-threaded-web-server","ch21-01-single-threaded.html#listening-to-the-tcp-connection","ch21-01-single-threaded.html#reading-the-request","ch21-01-single-threaded.html#looking-more-closely-at-an-http-request","ch21-01-single-threaded.html#writing-a-response","ch21-01-single-threaded.html#returning-real-html","ch21-01-single-threaded.html#validating-the-request-and-selectively-responding","ch21-01-single-threaded.html#refactoring","ch21-02-multithreaded.html#from-a-single-threaded-to-a-multithreaded-server","ch21-02-multithreaded.html#simulating-a-slow-request","ch21-02-multithreaded.html#improving-throughput-with-a-thread-pool","ch21-03-graceful-shutdown-and-cleanup.html#graceful-shutdown-and-cleanup","ch21-03-graceful-shutdown-and-cleanup.html#implementing-the-drop-trait-on-threadpool","ch21-03-graceful-shutdown-and-cleanup.html#signaling-to-the-threads-to-stop-listening-for-jobs","ch21-03-graceful-shutdown-and-cleanup.html#summary","appendix-00.html#appendix","appendix-01-keywords.html#appendix-a-keywords","appendix-01-keywords.html#keywords-currently-in-use","appendix-01-keywords.html#keywords-reserved-for-future-use","appendix-01-keywords.html#raw-identifiers","appendix-02-operators.html#appendix-b-operators-and-symbols","appendix-02-operators.html#operators","appendix-02-operators.html#non-operator-symbols","appendix-03-derivable-traits.html#appendix-c-derivable-traits","appendix-03-derivable-traits.html#debug-for-programmer-output","appendix-03-derivable-traits.html#partialeq-and-eq-for-equality-comparisons","appendix-03-derivable-traits.html#partialord-and-ord-for-ordering-comparisons","appendix-03-derivable-traits.html#clone-and-copy-for-duplicating-values","appendix-03-derivable-traits.html#hash-for-mapping-a-value-to-a-value-of-fixed-size","appendix-03-derivable-traits.html#default-for-default-values","appendix-04-useful-development-tools.html#appendix-d-useful-development-tools","appendix-04-useful-development-tools.html#automatic-formatting-with-rustfmt","appendix-04-useful-development-tools.html#fix-your-code-with-rustfix","appendix-04-useful-development-tools.html#more-lints-with-clippy","appendix-04-useful-development-tools.html#ide-integration-using-rust-analyzer","appendix-05-editions.html#appendix-e-editions","appendix-06-translation.html#appendix-f-translations-of-the-book","appendix-07-nightly-rust.html#appendix-g---how-rust-is-made-and-nightly-rust","appendix-07-nightly-rust.html#stability-without-stagnation","appendix-07-nightly-rust.html#choo-choo-release-channels-and-riding-the-trains","appendix-07-nightly-rust.html#maintenance-time","appendix-07-nightly-rust.html#unstable-features","appendix-07-nightly-rust.html#rustup-and-the-role-of-rust-nightly","appendix-07-nightly-rust.html#the-rfc-process-and-teams"],"index":{"documentStore":{"docInfo":{"0":{"body":91,"breadcrumbs":6,"title":3},"1":{"body":249,"breadcrumbs":2,"title":1},"10":{"body":526,"breadcrumbs":3,"title":2},"100":{"body":62,"breadcrumbs":6,"title":3},"101":{"body":154,"breadcrumbs":7,"title":2},"102":{"body":675,"breadcrumbs":7,"title":2},"103":{"body":651,"breadcrumbs":7,"title":2},"104":{"body":337,"breadcrumbs":11,"title":4},"105":{"body":203,"breadcrumbs":10,"title":3},"106":{"body":265,"breadcrumbs":10,"title":3},"107":{"body":162,"breadcrumbs":9,"title":2},"108":{"body":313,"breadcrumbs":11,"title":4},"109":{"body":278,"breadcrumbs":9,"title":3},"11":{"body":6,"breadcrumbs":3,"title":2},"110":{"body":398,"breadcrumbs":10,"title":4},"111":{"body":82,"breadcrumbs":7,"title":1},"112":{"body":251,"breadcrumbs":6,"title":3},"113":{"body":336,"breadcrumbs":7,"title":2},"114":{"body":29,"breadcrumbs":11,"title":4},"115":{"body":281,"breadcrumbs":10,"title":3},"116":{"body":347,"breadcrumbs":11,"title":4},"117":{"body":539,"breadcrumbs":13,"title":5},"118":{"body":504,"breadcrumbs":12,"title":4},"119":{"body":145,"breadcrumbs":12,"title":4},"12":{"body":30,"breadcrumbs":4,"title":2},"120":{"body":315,"breadcrumbs":12,"title":4},"121":{"body":265,"breadcrumbs":13,"title":5},"122":{"body":249,"breadcrumbs":12,"title":4},"123":{"body":88,"breadcrumbs":12,"title":4},"124":{"body":175,"breadcrumbs":13,"title":5},"125":{"body":160,"breadcrumbs":11,"title":3},"126":{"body":273,"breadcrumbs":15,"title":7},"127":{"body":90,"breadcrumbs":12,"title":4},"128":{"body":284,"breadcrumbs":11,"title":4},"129":{"body":148,"breadcrumbs":10,"title":3},"13":{"body":77,"breadcrumbs":4,"title":1},"130":{"body":54,"breadcrumbs":8,"title":1},"131":{"body":123,"breadcrumbs":4,"title":2},"132":{"body":38,"breadcrumbs":10,"title":4},"133":{"body":171,"breadcrumbs":9,"title":3},"134":{"body":54,"breadcrumbs":8,"title":2},"135":{"body":453,"breadcrumbs":9,"title":3},"136":{"body":148,"breadcrumbs":10,"title":4},"137":{"body":195,"breadcrumbs":11,"title":5},"138":{"body":58,"breadcrumbs":10,"title":4},"139":{"body":88,"breadcrumbs":14,"title":6},"14":{"body":38,"breadcrumbs":6,"title":3},"140":{"body":90,"breadcrumbs":10,"title":2},"141":{"body":215,"breadcrumbs":11,"title":3},"142":{"body":474,"breadcrumbs":10,"title":2},"143":{"body":495,"breadcrumbs":10,"title":2},"144":{"body":120,"breadcrumbs":10,"title":2},"145":{"body":88,"breadcrumbs":11,"title":3},"146":{"body":93,"breadcrumbs":11,"title":3},"147":{"body":105,"breadcrumbs":14,"title":6},"148":{"body":109,"breadcrumbs":12,"title":4},"149":{"body":109,"breadcrumbs":12,"title":4},"15":{"body":94,"breadcrumbs":7,"title":4},"150":{"body":96,"breadcrumbs":12,"title":4},"151":{"body":470,"breadcrumbs":11,"title":3},"152":{"body":71,"breadcrumbs":10,"title":2},"153":{"body":131,"breadcrumbs":9,"title":1},"154":{"body":129,"breadcrumbs":4,"title":2},"155":{"body":60,"breadcrumbs":8,"title":3},"156":{"body":625,"breadcrumbs":10,"title":5},"157":{"body":392,"breadcrumbs":8,"title":3},"158":{"body":495,"breadcrumbs":8,"title":3},"159":{"body":1430,"breadcrumbs":7,"title":2},"16":{"body":43,"breadcrumbs":6,"title":3},"160":{"body":100,"breadcrumbs":6,"title":2},"161":{"body":81,"breadcrumbs":8,"title":4},"162":{"body":156,"breadcrumbs":7,"title":3},"163":{"body":334,"breadcrumbs":7,"title":3},"164":{"body":486,"breadcrumbs":7,"title":3},"165":{"body":81,"breadcrumbs":5,"title":1},"166":{"body":152,"breadcrumbs":8,"title":4},"167":{"body":459,"breadcrumbs":8,"title":4},"168":{"body":30,"breadcrumbs":10,"title":3},"169":{"body":456,"breadcrumbs":9,"title":2},"17":{"body":77,"breadcrumbs":4,"title":1},"170":{"body":322,"breadcrumbs":9,"title":2},"171":{"body":159,"breadcrumbs":9,"title":2},"172":{"body":423,"breadcrumbs":9,"title":2},"173":{"body":180,"breadcrumbs":11,"title":4},"174":{"body":32,"breadcrumbs":12,"title":4},"175":{"body":194,"breadcrumbs":10,"title":2},"176":{"body":341,"breadcrumbs":11,"title":3},"177":{"body":399,"breadcrumbs":11,"title":3},"178":{"body":429,"breadcrumbs":11,"title":3},"179":{"body":302,"breadcrumbs":12,"title":4},"18":{"body":28,"breadcrumbs":5,"title":2},"180":{"body":264,"breadcrumbs":14,"title":6},"181":{"body":94,"breadcrumbs":10,"title":3},"182":{"body":244,"breadcrumbs":9,"title":2},"183":{"body":150,"breadcrumbs":9,"title":2},"184":{"body":297,"breadcrumbs":10,"title":3},"185":{"body":120,"breadcrumbs":10,"title":3},"186":{"body":620,"breadcrumbs":9,"title":2},"187":{"body":267,"breadcrumbs":8,"title":1},"188":{"body":129,"breadcrumbs":9,"title":2},"189":{"body":562,"breadcrumbs":9,"title":2},"19":{"body":32,"breadcrumbs":6,"title":3},"190":{"body":209,"breadcrumbs":9,"title":2},"191":{"body":82,"breadcrumbs":9,"title":2},"192":{"body":101,"breadcrumbs":13,"title":6},"193":{"body":102,"breadcrumbs":8,"title":1},"194":{"body":175,"breadcrumbs":6,"title":3},"195":{"body":46,"breadcrumbs":7,"title":2},"196":{"body":877,"breadcrumbs":8,"title":3},"197":{"body":640,"breadcrumbs":8,"title":3},"198":{"body":504,"breadcrumbs":9,"title":4},"199":{"body":352,"breadcrumbs":9,"title":4},"2":{"body":66,"breadcrumbs":2,"title":1},"20":{"body":34,"breadcrumbs":7,"title":4},"200":{"body":667,"breadcrumbs":8,"title":3},"201":{"body":136,"breadcrumbs":9,"title":4},"202":{"body":98,"breadcrumbs":9,"title":3},"203":{"body":159,"breadcrumbs":10,"title":4},"204":{"body":318,"breadcrumbs":9,"title":3},"205":{"body":353,"breadcrumbs":10,"title":4},"206":{"body":253,"breadcrumbs":11,"title":5},"207":{"body":69,"breadcrumbs":7,"title":2},"208":{"body":301,"breadcrumbs":7,"title":2},"209":{"body":891,"breadcrumbs":7,"title":2},"21":{"body":72,"breadcrumbs":6,"title":3},"210":{"body":76,"breadcrumbs":6,"title":1},"211":{"body":215,"breadcrumbs":12,"title":6},"212":{"body":87,"breadcrumbs":14,"title":4},"213":{"body":142,"breadcrumbs":13,"title":3},"214":{"body":191,"breadcrumbs":14,"title":4},"215":{"body":163,"breadcrumbs":14,"title":4},"216":{"body":281,"breadcrumbs":10,"title":2},"217":{"body":197,"breadcrumbs":16,"title":5},"218":{"body":527,"breadcrumbs":15,"title":4},"219":{"body":289,"breadcrumbs":15,"title":4},"22":{"body":77,"breadcrumbs":6,"title":2},"220":{"body":794,"breadcrumbs":14,"title":3},"221":{"body":649,"breadcrumbs":14,"title":3},"222":{"body":323,"breadcrumbs":15,"title":4},"223":{"body":122,"breadcrumbs":16,"title":5},"224":{"body":408,"breadcrumbs":14,"title":3},"225":{"body":592,"breadcrumbs":15,"title":4},"226":{"body":43,"breadcrumbs":12,"title":3},"227":{"body":222,"breadcrumbs":15,"title":6},"228":{"body":977,"breadcrumbs":12,"title":3},"229":{"body":47,"breadcrumbs":14,"title":4},"23":{"body":63,"breadcrumbs":7,"title":3},"230":{"body":146,"breadcrumbs":13,"title":3},"231":{"body":212,"breadcrumbs":14,"title":4},"232":{"body":59,"breadcrumbs":11,"title":1},"233":{"body":102,"breadcrumbs":10,"title":5},"234":{"body":36,"breadcrumbs":7,"title":1},"235":{"body":388,"breadcrumbs":8,"title":2},"236":{"body":480,"breadcrumbs":10,"title":4},"237":{"body":493,"breadcrumbs":10,"title":4},"238":{"body":777,"breadcrumbs":11,"title":5},"239":{"body":209,"breadcrumbs":13,"title":4},"24":{"body":113,"breadcrumbs":7,"title":3},"240":{"body":216,"breadcrumbs":13,"title":4},"241":{"body":117,"breadcrumbs":12,"title":3},"242":{"body":271,"breadcrumbs":12,"title":3},"243":{"body":203,"breadcrumbs":12,"title":3},"244":{"body":25,"breadcrumbs":11,"title":3},"245":{"body":808,"breadcrumbs":12,"title":4},"246":{"body":302,"breadcrumbs":12,"title":4},"247":{"body":88,"breadcrumbs":12,"title":4},"248":{"body":202,"breadcrumbs":13,"title":4},"249":{"body":50,"breadcrumbs":10,"title":1},"25":{"body":191,"breadcrumbs":7,"title":3},"250":{"body":51,"breadcrumbs":6,"title":3},"251":{"body":268,"breadcrumbs":11,"title":4},"252":{"body":40,"breadcrumbs":9,"title":3},"253":{"body":538,"breadcrumbs":10,"title":4},"254":{"body":615,"breadcrumbs":10,"title":4},"255":{"body":69,"breadcrumbs":10,"title":4},"256":{"body":300,"breadcrumbs":10,"title":4},"257":{"body":145,"breadcrumbs":8,"title":2},"258":{"body":35,"breadcrumbs":11,"title":5},"259":{"body":125,"breadcrumbs":9,"title":3},"26":{"body":204,"breadcrumbs":6,"title":2},"260":{"body":35,"breadcrumbs":7,"title":2},"261":{"body":227,"breadcrumbs":7,"title":2},"262":{"body":220,"breadcrumbs":9,"title":4},"263":{"body":256,"breadcrumbs":8,"title":3},"264":{"body":314,"breadcrumbs":8,"title":3},"265":{"body":171,"breadcrumbs":11,"title":4},"266":{"body":40,"breadcrumbs":11,"title":4},"267":{"body":36,"breadcrumbs":8,"title":1},"268":{"body":244,"breadcrumbs":4,"title":2},"269":{"body":145,"breadcrumbs":12,"title":5},"27":{"body":118,"breadcrumbs":6,"title":2},"270":{"body":120,"breadcrumbs":10,"title":3},"271":{"body":980,"breadcrumbs":11,"title":4},"272":{"body":77,"breadcrumbs":12,"title":5},"273":{"body":170,"breadcrumbs":10,"title":3},"274":{"body":91,"breadcrumbs":10,"title":3},"275":{"body":243,"breadcrumbs":10,"title":3},"276":{"body":275,"breadcrumbs":10,"title":3},"277":{"body":374,"breadcrumbs":12,"title":5},"278":{"body":134,"breadcrumbs":12,"title":5},"279":{"body":795,"breadcrumbs":12,"title":5},"28":{"body":320,"breadcrumbs":7,"title":3},"280":{"body":159,"breadcrumbs":12,"title":5},"281":{"body":416,"breadcrumbs":9,"title":2},"282":{"body":276,"breadcrumbs":11,"title":4},"283":{"body":87,"breadcrumbs":10,"title":4},"284":{"body":265,"breadcrumbs":10,"title":4},"285":{"body":1496,"breadcrumbs":9,"title":3},"286":{"body":291,"breadcrumbs":11,"title":5},"287":{"body":59,"breadcrumbs":10,"title":4},"288":{"body":585,"breadcrumbs":9,"title":3},"289":{"body":923,"breadcrumbs":11,"title":5},"29":{"body":334,"breadcrumbs":8,"title":4},"290":{"body":100,"breadcrumbs":7,"title":1},"291":{"body":280,"breadcrumbs":4,"title":2},"292":{"body":171,"breadcrumbs":12,"title":5},"293":{"body":201,"breadcrumbs":11,"title":4},"294":{"body":336,"breadcrumbs":10,"title":3},"295":{"body":587,"breadcrumbs":11,"title":4},"296":{"body":589,"breadcrumbs":14,"title":6},"297":{"body":228,"breadcrumbs":12,"title":4},"298":{"body":155,"breadcrumbs":11,"title":3},"299":{"body":158,"breadcrumbs":11,"title":3},"3":{"body":11,"breadcrumbs":2,"title":1},"30":{"body":62,"breadcrumbs":6,"title":2},"300":{"body":104,"breadcrumbs":8,"title":3},"301":{"body":1075,"breadcrumbs":8,"title":3},"302":{"body":119,"breadcrumbs":8,"title":3},"303":{"body":36,"breadcrumbs":10,"title":4},"304":{"body":99,"breadcrumbs":10,"title":4},"305":{"body":86,"breadcrumbs":9,"title":3},"306":{"body":68,"breadcrumbs":11,"title":5},"307":{"body":113,"breadcrumbs":7,"title":1},"308":{"body":463,"breadcrumbs":14,"title":7},"309":{"body":322,"breadcrumbs":9,"title":2},"31":{"body":73,"breadcrumbs":7,"title":3},"310":{"body":220,"breadcrumbs":13,"title":3},"311":{"body":155,"breadcrumbs":13,"title":3},"312":{"body":567,"breadcrumbs":13,"title":3},"313":{"body":630,"breadcrumbs":14,"title":4},"314":{"body":274,"breadcrumbs":16,"title":6},"315":{"body":56,"breadcrumbs":13,"title":3},"316":{"body":712,"breadcrumbs":14,"title":4},"317":{"body":1121,"breadcrumbs":18,"title":8},"318":{"body":732,"breadcrumbs":13,"title":3},"319":{"body":414,"breadcrumbs":13,"title":3},"32":{"body":69,"breadcrumbs":5,"title":1},"320":{"body":456,"breadcrumbs":13,"title":3},"321":{"body":56,"breadcrumbs":15,"title":4},"322":{"body":356,"breadcrumbs":13,"title":2},"323":{"body":1376,"breadcrumbs":15,"title":4},"324":{"body":371,"breadcrumbs":13,"title":2},"325":{"body":458,"breadcrumbs":15,"title":5},"326":{"body":69,"breadcrumbs":11,"title":1},"327":{"body":77,"breadcrumbs":8,"title":4},"328":{"body":42,"breadcrumbs":12,"title":4},"329":{"body":80,"breadcrumbs":12,"title":4},"33":{"body":74,"breadcrumbs":6,"title":3},"330":{"body":349,"breadcrumbs":12,"title":4},"331":{"body":156,"breadcrumbs":13,"title":5},"332":{"body":116,"breadcrumbs":9,"title":1},"333":{"body":203,"breadcrumbs":18,"title":7},"334":{"body":413,"breadcrumbs":15,"title":4},"335":{"body":533,"breadcrumbs":13,"title":2},"336":{"body":144,"breadcrumbs":14,"title":3},"337":{"body":180,"breadcrumbs":14,"title":5},"338":{"body":1709,"breadcrumbs":14,"title":5},"339":{"body":345,"breadcrumbs":10,"title":1},"34":{"body":124,"breadcrumbs":7,"title":4},"340":{"body":655,"breadcrumbs":13,"title":4},"341":{"body":77,"breadcrumbs":10,"title":1},"342":{"body":133,"breadcrumbs":4,"title":2},"343":{"body":16,"breadcrumbs":8,"title":3},"344":{"body":131,"breadcrumbs":7,"title":2},"345":{"body":297,"breadcrumbs":6,"title":1},"346":{"body":246,"breadcrumbs":7,"title":2},"347":{"body":103,"breadcrumbs":7,"title":2},"348":{"body":101,"breadcrumbs":6,"title":1},"349":{"body":135,"breadcrumbs":7,"title":2},"35":{"body":226,"breadcrumbs":5,"title":2},"350":{"body":452,"breadcrumbs":12,"title":5},"351":{"body":10,"breadcrumbs":6,"title":2},"352":{"body":42,"breadcrumbs":6,"title":2},"353":{"body":263,"breadcrumbs":7,"title":3},"354":{"body":47,"breadcrumbs":7,"title":3},"355":{"body":119,"breadcrumbs":7,"title":3},"356":{"body":780,"breadcrumbs":8,"title":4},"357":{"body":817,"breadcrumbs":7,"title":3},"358":{"body":451,"breadcrumbs":8,"title":4},"359":{"body":181,"breadcrumbs":6,"title":2},"36":{"body":210,"breadcrumbs":6,"title":3},"360":{"body":56,"breadcrumbs":5,"title":1},"361":{"body":111,"breadcrumbs":4,"title":2},"362":{"body":138,"breadcrumbs":6,"title":2},"363":{"body":206,"breadcrumbs":7,"title":3},"364":{"body":431,"breadcrumbs":7,"title":3},"365":{"body":1183,"breadcrumbs":8,"title":4},"366":{"body":367,"breadcrumbs":9,"title":5},"367":{"body":125,"breadcrumbs":7,"title":3},"368":{"body":44,"breadcrumbs":7,"title":3},"369":{"body":381,"breadcrumbs":9,"title":5},"37":{"body":177,"breadcrumbs":6,"title":3},"370":{"body":64,"breadcrumbs":8,"title":4},"371":{"body":21,"breadcrumbs":6,"title":2},"372":{"body":339,"breadcrumbs":8,"title":4},"373":{"body":424,"breadcrumbs":10,"title":6},"374":{"body":847,"breadcrumbs":9,"title":5},"375":{"body":432,"breadcrumbs":6,"title":2},"376":{"body":249,"breadcrumbs":9,"title":5},"377":{"body":33,"breadcrumbs":6,"title":2},"378":{"body":137,"breadcrumbs":9,"title":5},"379":{"body":451,"breadcrumbs":8,"title":4},"38":{"body":280,"breadcrumbs":7,"title":4},"380":{"body":338,"breadcrumbs":8,"title":4},"381":{"body":389,"breadcrumbs":9,"title":5},"382":{"body":12,"breadcrumbs":8,"title":3},"383":{"body":426,"breadcrumbs":7,"title":2},"384":{"body":403,"breadcrumbs":7,"title":2},"385":{"body":62,"breadcrumbs":4,"title":1},"386":{"body":142,"breadcrumbs":7,"title":4},"387":{"body":467,"breadcrumbs":7,"title":4},"388":{"body":151,"breadcrumbs":8,"title":5},"389":{"body":1062,"breadcrumbs":6,"title":3},"39":{"body":109,"breadcrumbs":7,"title":4},"390":{"body":103,"breadcrumbs":5,"title":2},"391":{"body":95,"breadcrumbs":5,"title":2},"392":{"body":46,"breadcrumbs":4,"title":1},"393":{"body":180,"breadcrumbs":12,"title":6},"394":{"body":108,"breadcrumbs":16,"title":5},"395":{"body":485,"breadcrumbs":14,"title":3},"396":{"body":364,"breadcrumbs":13,"title":2},"397":{"body":173,"breadcrumbs":16,"title":5},"398":{"body":219,"breadcrumbs":13,"title":2},"399":{"body":231,"breadcrumbs":14,"title":3},"4":{"body":110,"breadcrumbs":3,"title":2},"40":{"body":43,"breadcrumbs":6,"title":3},"400":{"body":367,"breadcrumbs":15,"title":4},"401":{"body":213,"breadcrumbs":12,"title":1},"402":{"body":54,"breadcrumbs":14,"title":4},"403":{"body":219,"breadcrumbs":13,"title":3},"404":{"body":3635,"breadcrumbs":14,"title":4},"405":{"body":105,"breadcrumbs":12,"title":3},"406":{"body":516,"breadcrumbs":13,"title":4},"407":{"body":963,"breadcrumbs":14,"title":5},"408":{"body":31,"breadcrumbs":10,"title":1},"409":{"body":9,"breadcrumbs":2,"title":1},"41":{"body":41,"breadcrumbs":6,"title":3},"410":{"body":37,"breadcrumbs":4,"title":2},"411":{"body":213,"breadcrumbs":5,"title":3},"412":{"body":21,"breadcrumbs":6,"title":4},"413":{"body":174,"breadcrumbs":4,"title":2},"414":{"body":20,"breadcrumbs":8,"title":4},"415":{"body":321,"breadcrumbs":5,"title":1},"416":{"body":527,"breadcrumbs":7,"title":3},"417":{"body":170,"breadcrumbs":8,"title":4},"418":{"body":50,"breadcrumbs":7,"title":3},"419":{"body":103,"breadcrumbs":8,"title":4},"42":{"body":655,"breadcrumbs":6,"title":3},"420":{"body":158,"breadcrumbs":8,"title":4},"421":{"body":171,"breadcrumbs":8,"title":4},"422":{"body":49,"breadcrumbs":10,"title":6},"423":{"body":80,"breadcrumbs":7,"title":3},"424":{"body":20,"breadcrumbs":10,"title":5},"425":{"body":76,"breadcrumbs":8,"title":3},"426":{"body":132,"breadcrumbs":8,"title":3},"427":{"body":128,"breadcrumbs":8,"title":3},"428":{"body":59,"breadcrumbs":10,"title":5},"429":{"body":300,"breadcrumbs":6,"title":3},"43":{"body":279,"breadcrumbs":6,"title":3},"430":{"body":42,"breadcrumbs":8,"title":4},"431":{"body":6,"breadcrumbs":12,"title":6},"432":{"body":57,"breadcrumbs":9,"title":3},"433":{"body":327,"breadcrumbs":12,"title":6},"434":{"body":22,"breadcrumbs":8,"title":2},"435":{"body":111,"breadcrumbs":8,"title":2},"436":{"body":122,"breadcrumbs":10,"title":4},"437":{"body":132,"breadcrumbs":9,"title":3},"44":{"body":843,"breadcrumbs":7,"title":4},"45":{"body":216,"breadcrumbs":7,"title":4},"46":{"body":83,"breadcrumbs":6,"title":3},"47":{"body":371,"breadcrumbs":6,"title":3},"48":{"body":56,"breadcrumbs":4,"title":1},"49":{"body":86,"breadcrumbs":6,"title":3},"5":{"body":41,"breadcrumbs":2,"title":1},"50":{"body":366,"breadcrumbs":7,"title":2},"51":{"body":206,"breadcrumbs":7,"title":2},"52":{"body":312,"breadcrumbs":6,"title":1},"53":{"body":146,"breadcrumbs":7,"title":2},"54":{"body":761,"breadcrumbs":7,"title":2},"55":{"body":675,"breadcrumbs":7,"title":2},"56":{"body":164,"breadcrumbs":5,"title":1},"57":{"body":228,"breadcrumbs":5,"title":1},"58":{"body":332,"breadcrumbs":6,"title":2},"59":{"body":302,"breadcrumbs":7,"title":3},"6":{"body":38,"breadcrumbs":2,"title":1},"60":{"body":121,"breadcrumbs":5,"title":1},"61":{"body":27,"breadcrumbs":7,"title":2},"62":{"body":648,"breadcrumbs":6,"title":1},"63":{"body":862,"breadcrumbs":7,"title":2},"64":{"body":55,"breadcrumbs":6,"title":1},"65":{"body":38,"breadcrumbs":4,"title":2},"66":{"body":106,"breadcrumbs":4,"title":1},"67":{"body":352,"breadcrumbs":5,"title":2},"68":{"body":26,"breadcrumbs":5,"title":2},"69":{"body":142,"breadcrumbs":5,"title":2},"7":{"body":16,"breadcrumbs":4,"title":3},"70":{"body":200,"breadcrumbs":5,"title":2},"71":{"body":1173,"breadcrumbs":5,"title":2},"72":{"body":138,"breadcrumbs":5,"title":2},"73":{"body":223,"breadcrumbs":6,"title":3},"74":{"body":360,"breadcrumbs":6,"title":2},"75":{"body":526,"breadcrumbs":6,"title":2},"76":{"body":278,"breadcrumbs":6,"title":2},"77":{"body":23,"breadcrumbs":6,"title":2},"78":{"body":492,"breadcrumbs":6,"title":2},"79":{"body":710,"breadcrumbs":6,"title":2},"8":{"body":92,"breadcrumbs":5,"title":4},"80":{"body":63,"breadcrumbs":5,"title":1},"81":{"body":64,"breadcrumbs":5,"title":1},"82":{"body":81,"breadcrumbs":10,"title":5},"83":{"body":384,"breadcrumbs":11,"title":3},"84":{"body":106,"breadcrumbs":12,"title":4},"85":{"body":268,"breadcrumbs":13,"title":5},"86":{"body":162,"breadcrumbs":13,"title":5},"87":{"body":108,"breadcrumbs":11,"title":3},"88":{"body":192,"breadcrumbs":11,"title":3},"89":{"body":190,"breadcrumbs":13,"title":4},"9":{"body":42,"breadcrumbs":2,"title":1},"90":{"body":108,"breadcrumbs":11,"title":2},"91":{"body":166,"breadcrumbs":11,"title":2},"92":{"body":629,"breadcrumbs":13,"title":4},"93":{"body":43,"breadcrumbs":7,"title":1},"94":{"body":405,"breadcrumbs":8,"title":2},"95":{"body":145,"breadcrumbs":8,"title":2},"96":{"body":273,"breadcrumbs":9,"title":3},"97":{"body":145,"breadcrumbs":8,"title":2},"98":{"body":108,"breadcrumbs":9,"title":3},"99":{"body":49,"breadcrumbs":7,"title":1}},"docs":{"0":{"body":"by Steve Klabnik, Carol Nichols, and Chris Krycho, with contributions from the Rust Community This version of the text assumes you‚Äôre using Rust 1.85.0 (released 2025-02-17) or later with edition = \\"2024\\" in the Cargo.toml file of all projects to configure them to use Rust 2024 Edition idioms. See the ‚ÄúInstallation‚Äù section of Chapter 1 for instructions on installing or updating Rust, and see Appendix E for information on editions. The HTML format is available online at https://doc.rust-lang.org/stable/book/ and offline with installations of Rust made with rustup; run rustup doc --book to open. Several community translations are also available. This text is available in paperback and ebook format from No Starch Press . üö® Want a more interactive learning experience? Try out a different version of the Rust Book, featuring: quizzes, highlighting, visualizations, and more : https://rust-book.cs.brown.edu","breadcrumbs":"The Rust Programming Language ¬ª The Rust Programming Language","id":"0","title":"The Rust Programming Language"},"1":{"body":"The Rust programming language has come a long way in a few short years, from its creation and incubation by a small and nascent community of enthusiasts, to becoming one of the most loved and in-demand programming languages in the world. Looking back, it was inevitable that the power and promise of Rust would turn heads and gain a foothold in systems programming. What was not inevitable was the global growth in interest and innovation that permeated through open source communities and catalyzed wide-scale adoption across industries. At this point in time, it is easy to point to the wonderful features that Rust has to offer to explain this explosion in interest and adoption. Who doesn‚Äôt want memory safety, and fast performance, and a friendly compiler, and great tooling, among a host of other wonderful features? The Rust language you see today combines years of research in systems programming with the practical wisdom of a vibrant and passionate community. This language was designed with purpose and crafted with care, offering developers a tool that makes it easier to write safe, fast, and reliable code. But what makes Rust truly special is its roots in empowering you, the user, to achieve your goals. This is a language that wants you to succeed, and the principle of empowerment runs through the core of the community that builds, maintains, and advocates for this language. Since the previous edition of this definitive text, Rust has further developed into a truly global and trusted language. The Rust Project is now robustly supported by the Rust Foundation, which also invests in key initiatives to ensure that Rust is secure, stable, and sustainable. This edition of The Rust Programming Language is a comprehensive update, reflecting the language‚Äôs evolution over the years and providing valuable new information. But it is not just a guide to syntax and libraries‚Äîit‚Äôs an invitation to join a community that values quality, performance, and thoughtful design. Whether you‚Äôre a seasoned developer looking to explore Rust for the first time or an experienced Rustacean looking to refine your skills, this edition offers something for everyone. The Rust journey has been one of collaboration, learning, and iteration. The growth of the language and its ecosystem is a direct reflection of the vibrant, diverse community behind it. The contributions of thousands of developers, from core language designers to casual contributors, are what make Rust such a unique and powerful tool. By picking up this book, you‚Äôre not just learning a new programming language‚Äîyou‚Äôre joining a movement to make software better, safer, and more enjoyable to work with. Welcome to the Rust community! Bec Rumbul, Executive Director of the Rust Foundation","breadcrumbs":"Foreword ¬ª Foreword","id":"1","title":"Foreword"},"10":{"body":"In general, this book assumes that you‚Äôre reading it in sequence from front to back. Later chapters build on concepts in earlier chapters, and earlier chapters might not delve into details on a particular topic but will revisit the topic in a later chapter. You‚Äôll find two kinds of chapters in this book: concept chapters and project chapters. In concept chapters, you‚Äôll learn about an aspect of Rust. In project chapters, we‚Äôll build small programs together, applying what you‚Äôve learned so far. Chapter 2, Chapter 12, and Chapter 21 are project chapters; the rest are concept chapters. Chapter 1 explains how to install Rust, how to write a ‚ÄúHello, world!‚Äù program, and how to use Cargo, Rust‚Äôs package manager and build tool. Chapter 2 is a hands-on introduction to writing a program in Rust, having you build up a number-guessing game. Here, we cover concepts at a high level, and later chapters will provide additional detail. If you want to get your hands dirty right away, Chapter 2 is the place for that. If you‚Äôre a particularly meticulous learner who prefers to learn every detail before moving on to the next, you might want to skip Chapter 2 and go straight to Chapter 3 , which covers Rust features that are similar to those of other programming languages; then, you can return to Chapter 2 when you‚Äôd like to work on a project applying the details you‚Äôve learned. In Chapter 4 , you‚Äôll learn about Rust‚Äôs ownership system. Chapter 5 discusses structs and methods. Chapter 6 covers enums, match expressions, and the if let and let...else control flow constructs. You‚Äôll use structs and enums to make custom types. In Chapter 7 , you‚Äôll learn about Rust‚Äôs module system and about privacy rules for organizing your code and its public application programming interface (API). Chapter 8 discusses some common collection data structures that the standard library provides: vectors, strings, and hash maps. Chapter 9 explores Rust‚Äôs error-handling philosophy and techniques. Chapter 10 digs into generics, traits, and lifetimes, which give you the power to define code that applies to multiple types. Chapter 11 is all about testing, which even with Rust‚Äôs safety guarantees is necessary to ensure that your program‚Äôs logic is correct. In Chapter 12 , we‚Äôll build our own implementation of a subset of functionality from the grep command line tool that searches for text within files. For this, we‚Äôll use many of the concepts we discussed in the previous chapters. Chapter 13 explores closures and iterators: features of Rust that come from functional programming languages. In Chapter 14 , we‚Äôll examine Cargo in more depth and talk about best practices for sharing your libraries with others. Chapter 15 discusses smart pointers that the standard library provides and the traits that enable their functionality. In Chapter 16 , we‚Äôll walk through different models of concurrent programming and talk about how Rust helps you program in multiple threads fearlessly. In Chapter 17 , we build on that by exploring Rust‚Äôs async and await syntax, along with tasks, futures, and streams, and the lightweight concurrency model they enable. Chapter 18 looks at how Rust idioms compare to object-oriented programming principles you might be familiar with. Chapter 19 is a reference on patterns and pattern matching, which are powerful ways of expressing ideas throughout Rust programs. Chapter 20 contains a smorgasbord of advanced topics of interest, including unsafe Rust, macros, and more about lifetimes, traits, types, functions, and closures. In Chapter 21 , we‚Äôll complete a project in which we‚Äôll implement a low-level multithreaded web server! Finally, some appendixes contain useful information about the language in a more reference-like format. Appendix A covers Rust‚Äôs keywords, Appendix B covers Rust‚Äôs operators and symbols, Appendix C covers derivable traits provided by the standard library, Appendix D covers some useful development tools, and Appendix E explains Rust editions. In Appendix F , you can find translations of the book, and in Appendix G we‚Äôll cover how Rust is made and what nightly Rust is. There is no wrong way to read this book: If you want to skip ahead, go for it! You might have to jump back to earlier chapters if you experience any confusion. But do whatever works for you. An important part of the process of learning Rust is learning how to read the error messages the compiler displays: These will guide you toward working code. As such, we‚Äôll provide many examples that don‚Äôt compile along with the error message the compiler will show you in each situation. Know that if you enter and run a random example, it may not compile! Make sure you read the surrounding text to see whether the example you‚Äôre trying to run is meant to error. In most situations, we‚Äôll lead you to the correct version of any code that doesn‚Äôt compile. Ferris will also help you distinguish code that isn‚Äôt meant to work: Ferris Meaning This code does not compile! This code panics! This code does not produce the desired behavior. In most situations, we‚Äôll lead you to the correct version of any code that doesn‚Äôt compile.","breadcrumbs":"Introduction ¬ª How to Use This Book","id":"10","title":"How to Use This Book"},"100":{"body":"In this chapter, we‚Äôll look at enumerations, also referred to as enums . Enums allow you to define a type by enumerating its possible variants. First we‚Äôll define and use an enum to show how an enum can encode meaning along with data. Next, we‚Äôll explore a particularly useful enum, called Option, which expresses that a value can be either something or nothing. Then, we‚Äôll look at how pattern matching in the match expression makes it easy to run different code for different values of an enum. Finally, we‚Äôll cover how the if let construct is another convenient and concise idiom available to handle enums in your code.","breadcrumbs":"Enums and Pattern Matching ¬ª Enums and Pattern Matching","id":"100","title":"Enums and Pattern Matching"},"101":{"body":"Where structs give you a way of grouping together related fields and data, like a Rectangle with its width and height, enums give you a way of saying a value is one of a possible set of values. For example, we may want to say that Rectangle is one of a set of possible shapes that also includes Circle and Triangle. To do this, Rust allows us to encode these possibilities as an enum. Let‚Äôs look at a situation we might want to express in code and see why enums are useful and more appropriate than structs in this case. Say we need to work with IP addresses. Currently, two major standards are used for IP addresses: version four and version six. Because these are the only possibilities for an IP address that our program will come across, we can enumerate all possible variants, which is where enumeration gets its name. Any IP address can be either a version four or a version six address, but not both at the same time. That property of IP addresses makes the enum data structure appropriate because an enum value can only be one of its variants. Both version four and version six addresses are still fundamentally IP addresses, so they should be treated as the same type when the code is handling situations that apply to any kind of IP address. We can express this concept in code by defining an IpAddrKind enumeration and listing the possible kinds an IP address can be, V4 and V6. These are the variants of the enum: enum IpAddrKind { V4, V6,\\n}\\n# # fn main() {\\n# let four = IpAddrKind::V4;\\n# let six = IpAddrKind::V6;\\n# # route(IpAddrKind::V4);\\n# route(IpAddrKind::V6);\\n# }\\n# # fn route(ip_kind: IpAddrKind) {} IpAddrKind is now a custom data type that we can use elsewhere in our code.","breadcrumbs":"Enums and Pattern Matching ¬ª Defining an Enum ¬ª Defining an Enum","id":"101","title":"Defining an Enum"},"102":{"body":"We can create instances of each of the two variants of IpAddrKind like this: # enum IpAddrKind {\\n# V4,\\n# V6,\\n# }\\n# # fn main() { let four = IpAddrKind::V4; let six = IpAddrKind::V6;\\n# # route(IpAddrKind::V4);\\n# route(IpAddrKind::V6);\\n# }\\n# # fn route(ip_kind: IpAddrKind) {} Note that the variants of the enum are namespaced under its identifier, and we use a double colon to separate the two. This is useful because now both values IpAddrKind::V4 and IpAddrKind::V6 are of the same type: IpAddrKind. We can then, for instance, define a function that takes any IpAddrKind: # enum IpAddrKind {\\n# V4,\\n# V6,\\n# }\\n# # fn main() {\\n# let four = IpAddrKind::V4;\\n# let six = IpAddrKind::V6;\\n# # route(IpAddrKind::V4);\\n# route(IpAddrKind::V6);\\n# }\\n# fn route(ip_kind: IpAddrKind) {} And we can call this function with either variant: # enum IpAddrKind {\\n# V4,\\n# V6,\\n# }\\n# # fn main() {\\n# let four = IpAddrKind::V4;\\n# let six = IpAddrKind::V6;\\n# route(IpAddrKind::V4); route(IpAddrKind::V6);\\n# }\\n# # fn route(ip_kind: IpAddrKind) {} Using enums has even more advantages. Thinking more about our IP address type, at the moment we don‚Äôt have a way to store the actual IP address data ; we only know what kind it is. Given that you just learned about structs in Chapter 5, you might be tempted to tackle this problem with structs as shown in Listing 6-1. # fn main() { enum IpAddrKind { V4, V6, } struct IpAddr { kind: IpAddrKind, address: String, } let home = IpAddr { kind: IpAddrKind::V4, address: String::from(\\"127.0.0.1\\"), }; let loopback = IpAddr { kind: IpAddrKind::V6, address: String::from(\\"::1\\"), };\\n# } Listing 6-1: Storing the data and IpAddrKind variant of an IP address using a struct Here, we‚Äôve defined a struct IpAddr that has two fields: a kind field that is of type IpAddrKind (the enum we defined previously) and an address field of type String. We have two instances of this struct. The first is home, and it has the value IpAddrKind::V4 as its kind with associated address data of 127.0.0.1. The second instance is loopback. It has the other variant of IpAddrKind as its kind value, V6, and has address ::1 associated with it. We‚Äôve used a struct to bundle the kind and address values together, so now the variant is associated with the value. However, representing the same concept using just an enum is more concise: Rather than an enum inside a struct, we can put data directly into each enum variant. This new definition of the IpAddr enum says that both V4 and V6 variants will have associated String values: # fn main() { enum IpAddr { V4(String), V6(String), } let home = IpAddr::V4(String::from(\\"127.0.0.1\\")); let loopback = IpAddr::V6(String::from(\\"::1\\"));\\n# } We attach data to each variant of the enum directly, so there is no need for an extra struct. Here, it‚Äôs also easier to see another detail of how enums work: The name of each enum variant that we define also becomes a function that constructs an instance of the enum. That is, IpAddr::V4() is a function call that takes a String argument and returns an instance of the IpAddr type. We automatically get this constructor function defined as a result of defining the enum. There‚Äôs another advantage to using an enum rather than a struct: Each variant can have different types and amounts of associated data. Version four IP addresses will always have four numeric components that will have values between 0 and 255. If we wanted to store V4 addresses as four u8 values but still express V6 addresses as one String value, we wouldn‚Äôt be able to with a struct. Enums handle this case with ease: # fn main() { enum IpAddr { V4(u8, u8, u8, u8), V6(String), } let home = IpAddr::V4(127, 0, 0, 1); let loopback = IpAddr::V6(String::from(\\"::1\\"));\\n# } We‚Äôve shown several different ways to define data structures to store version four and version six IP addresses. However, as it turns out, wanting to store IP addresses and encode which kind they are is so common that the standard library has a definition we can use! Let‚Äôs look at how the standard library defines IpAddr. It has the exact enum and variants that we‚Äôve defined and used, but it embeds the address data inside the variants in the form of two different structs, which are defined differently for each variant: struct Ipv4Addr { // --snip--\\n} struct Ipv6Addr { // --snip--\\n} enum IpAddr { V4(Ipv4Addr), V6(Ipv6Addr),\\n} This code illustrates that you can put any kind of data inside an enum variant: strings, numeric types, or structs, for example. You can even include another enum! Also, standard library types are often not much more complicated than what you might come up with. Note that even though the standard library contains a definition for IpAddr, we can still create and use our own definition without conflict because we haven‚Äôt brought the standard library‚Äôs definition into our scope. We‚Äôll talk more about bringing types into scope in Chapter 7. Let‚Äôs look at another example of an enum in Listing 6-2: This one has a wide variety of types embedded in its variants. enum Message { Quit, Move { x: i32, y: i32 }, Write(String), ChangeColor(i32, i32, i32),\\n}\\n# # fn main() {} Listing 6-2: A Message enum whose variants each store different amounts and types of values This enum has four variants with different types: Quit: Has no data associated with it at all Move: Has named fields, like a struct does Write: Includes a single String ChangeColor: Includes three i32 values Defining an enum with variants such as the ones in Listing 6-2 is similar to defining different kinds of struct definitions, except the enum doesn‚Äôt use the struct keyword and all the variants are grouped together under the Message type. The following structs could hold the same data that the preceding enum variants hold: struct QuitMessage; // unit struct\\nstruct MoveMessage { x: i32, y: i32,\\n}\\nstruct WriteMessage(String); // tuple struct\\nstruct ChangeColorMessage(i32, i32, i32); // tuple struct\\n# # fn main() {} But if we used the different structs, each of which has its own type, we couldn‚Äôt as easily define a function to take any of these kinds of messages as we could with the Message enum defined in Listing 6-2, which is a single type. There is one more similarity between enums and structs: Just as we‚Äôre able to define methods on structs using impl, we‚Äôre also able to define methods on enums. Here‚Äôs a method named call that we could define on our Message enum: # fn main() {\\n# enum Message {\\n# Quit,\\n# Move { x: i32, y: i32 },\\n# Write(String),\\n# ChangeColor(i32, i32, i32),\\n# }\\n# impl Message { fn call(&self) { // method body would be defined here } } let m = Message::Write(String::from(\\"hello\\")); m.call();\\n# } The body of the method would use self to get the value that we called the method on. In this example, we‚Äôve created a variable m that has the value Message::Write(String::from(\\"hello\\")), and that is what self will be in the body of the call method when m.call() runs. Let‚Äôs look at another enum in the standard library that is very common and useful: Option.","breadcrumbs":"Enums and Pattern Matching ¬ª Defining an Enum ¬ª Enum Values","id":"102","title":"Enum Values"},"103":{"body":"This section explores a case study of Option, which is another enum defined by the standard library. The Option type encodes the very common scenario in which a value could be something, or it could be nothing. For example, if you request the first item in a non-empty list, you would get a value. If you request the first item in an empty list, you would get nothing. Expressing this concept in terms of the type system means the compiler can check whether you‚Äôve handled all the cases you should be handling; this functionality can prevent bugs that are extremely common in other programming languages. Programming language design is often thought of in terms of which features you include, but the features you exclude are important too. Rust doesn‚Äôt have the null feature that many other languages have. Null is a value that means there is no value there. In languages with null, variables can always be in one of two states: null or not-null. In his 2009 presentation ‚ÄúNull References: The Billion Dollar Mistake,‚Äù Tony Hoare, the inventor of null, had this to say: I call it my billion-dollar mistake. At that time, I was designing the first comprehensive type system for references in an object-oriented language. My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn‚Äôt resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years. The problem with null values is that if you try to use a null value as a not-null value, you‚Äôll get an error of some kind. Because this null or not-null property is pervasive, it‚Äôs extremely easy to make this kind of error. However, the concept that null is trying to express is still a useful one: A null is a value that is currently invalid or absent for some reason. The problem isn‚Äôt really with the concept but with the particular implementation. As such, Rust does not have nulls, but it does have an enum that can encode the concept of a value being present or absent. This enum is Option<T>, and it is defined by the standard library as follows: enum Option<T> { None, Some(T),\\n} The Option<T> enum is so useful that it‚Äôs even included in the prelude; you don‚Äôt need to bring it into scope explicitly. Its variants are also included in the prelude: You can use Some and None directly without the Option:: prefix. The Option<T> enum is still just a regular enum, and Some(T) and None are still variants of type Option<T>. The <T> syntax is a feature of Rust we haven‚Äôt talked about yet. It‚Äôs a generic type parameter, and we‚Äôll cover generics in more detail in Chapter 10. For now, all you need to know is that <T> means that the Some variant of the Option enum can hold one piece of data of any type, and that each concrete type that gets used in place of T makes the overall Option<T> type a different type. Here are some examples of using Option values to hold number types and char types: # fn main() { let some_number = Some(5); let some_char = Some(\'e\'); let absent_number: Option<i32> = None;\\n# } The type of some_number is Option<i32>. The type of some_char is Option<char>, which is a different type. Rust can infer these types because we‚Äôve specified a value inside the Some variant. For absent_number, Rust requires us to annotate the overall Option type: The compiler can‚Äôt infer the type that the corresponding Some variant will hold by looking only at a None value. Here, we tell Rust that we mean for absent_number to be of type Option<i32>. When we have a Some value, we know that a value is present, and the value is held within the Some. When we have a None value, in some sense it means the same thing as null: We don‚Äôt have a valid value. So, why is having Option<T> any better than having null? In short, because Option<T> and T (where T can be any type) are different types, the compiler won‚Äôt let us use an Option<T> value as if it were definitely a valid value. For example, this code won‚Äôt compile, because it‚Äôs trying to add an i8 to an Option<i8>: # fn main() { let x: i8 = 5; let y: Option<i8> = Some(5); let sum = x + y;\\n# } If we run this code, we get an error message like this one: $ cargo run Compiling enums v0.1.0 (file:///projects/enums)\\nerror[E0277]: cannot add `Option<i8>` to `i8` --> src/main.rs:5:17 |\\n5 | let sum = x + y; | ^ no implementation for `i8 + Option<i8>` | = help: the trait `Add<Option<i8>>` is not implemented for `i8` = help: the following other types implement trait `Add<Rhs>`: `&i8` implements `Add<i8>` `&i8` implements `Add` `i8` implements `Add<&i8>` `i8` implements `Add` For more information about this error, try `rustc --explain E0277`.\\nerror: could not compile `enums` (bin \\"enums\\") due to 1 previous error Intense! In effect, this error message means that Rust doesn‚Äôt understand how to add an i8 and an Option<i8>, because they‚Äôre different types. When we have a value of a type like i8 in Rust, the compiler will ensure that we always have a valid value. We can proceed confidently without having to check for null before using that value. Only when we have an Option<i8> (or whatever type of value we‚Äôre working with) do we have to worry about possibly not having a value, and the compiler will make sure we handle that case before using the value. In other words, you have to convert an Option<T> to a T before you can perform T operations with it. Generally, this helps catch one of the most common issues with null: assuming that something isn‚Äôt null when it actually is. Eliminating the risk of incorrectly assuming a not-null value helps you be more confident in your code. In order to have a value that can possibly be null, you must explicitly opt in by making the type of that value Option<T>. Then, when you use that value, you are required to explicitly handle the case when the value is null. Everywhere that a value has a type that isn‚Äôt an Option<T>, you can safely assume that the value isn‚Äôt null. This was a deliberate design decision for Rust to limit null‚Äôs pervasiveness and increase the safety of Rust code. So how do you get the T value out of a Some variant when you have a value of type Option<T> so that you can use that value? The Option<T> enum has a large number of methods that are useful in a variety of situations; you can check them out in its documentation . Becoming familiar with the methods on Option<T> will be extremely useful in your journey with Rust. In general, in order to use an Option<T> value, you want to have code that will handle each variant. You want some code that will run only when you have a Some(T) value, and this code is allowed to use the inner T. You want some other code to run only if you have a None value, and that code doesn‚Äôt have a T value available. The match expression is a control flow construct that does just this when used with enums: It will run different code depending on which variant of the enum it has, and that code can use the data inside the matching value.","breadcrumbs":"Enums and Pattern Matching ¬ª Defining an Enum ¬ª The Option Enum","id":"103","title":"The Option Enum"},"104":{"body":"Rust has an extremely powerful control flow construct called match that allows you to compare a value against a series of patterns and then execute code based on which pattern matches. Patterns can be made up of literal values, variable names, wildcards, and many other things; Chapter 19 covers all the different kinds of patterns and what they do. The power of match comes from the expressiveness of the patterns and the fact that the compiler confirms that all possible cases are handled. Think of a match expression as being like a coin-sorting machine: Coins slide down a track with variously sized holes along it, and each coin falls through the first hole it encounters that it fits into. In the same way, values go through each pattern in a match, and at the first pattern the value ‚Äúfits,‚Äù the value falls into the associated code block to be used during execution. Speaking of coins, let‚Äôs use them as an example using match! We can write a function that takes an unknown US coin and, in a similar way as the counting machine, determines which coin it is and returns its value in cents, as shown in Listing 6-3. enum Coin { Penny, Nickel, Dime, Quarter,\\n} fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => 1, Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter => 25, }\\n}\\n# # fn main() {} Listing 6-3: An enum and a match expression that has the variants of the enum as its patterns Let‚Äôs break down the match in the value_in_cents function. First, we list the match keyword followed by an expression, which in this case is the value coin. This seems very similar to a conditional expression used with if, but there‚Äôs a big difference: With if, the condition needs to evaluate to a Boolean value, but here it can be any type. The type of coin in this example is the Coin enum that we defined on the first line. Next are the match arms. An arm has two parts: a pattern and some code. The first arm here has a pattern that is the value Coin::Penny and then the => operator that separates the pattern and the code to run. The code in this case is just the value 1. Each arm is separated from the next with a comma. When the match expression executes, it compares the resultant value against the pattern of each arm, in order. If a pattern matches the value, the code associated with that pattern is executed. If that pattern doesn‚Äôt match the value, execution continues to the next arm, much as in a coin-sorting machine. We can have as many arms as we need: In Listing 6-3, our match has four arms. The code associated with each arm is an expression, and the resultant value of the expression in the matching arm is the value that gets returned for the entire match expression. We don‚Äôt typically use curly brackets if the match arm code is short, as it is in Listing 6-3 where each arm just returns a value. If you want to run multiple lines of code in a match arm, you must use curly brackets, and the comma following the arm is then optional. For example, the following code prints ‚ÄúLucky penny!‚Äù every time the method is called with a Coin::Penny, but it still returns the last value of the block, 1: # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter,\\n# }\\n# fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => { println!(\\"Lucky penny!\\"); 1 } Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter => 25, }\\n}\\n# # fn main() {}","breadcrumbs":"Enums and Pattern Matching ¬ª The match Control Flow Construct ¬ª The match Control Flow Construct","id":"104","title":"The match Control Flow Construct"},"105":{"body":"Another useful feature of match arms is that they can bind to the parts of the values that match the pattern. This is how we can extract values out of enum variants. As an example, let‚Äôs change one of our enum variants to hold data inside it. From 1999 through 2008, the United States minted quarters with different designs for each of the 50 states on one side. No other coins got state designs, so only quarters have this extra value. We can add this information to our enum by changing the Quarter variant to include a UsState value stored inside it, which we‚Äôve done in Listing 6-4. #[derive(Debug)] // so we can inspect the state in a minute\\nenum UsState { Alabama, Alaska, // --snip--\\n} enum Coin { Penny, Nickel, Dime, Quarter(UsState),\\n}\\n# # fn main() {} Listing 6-4: A Coin enum in which the Quarter variant also holds a UsState value Let‚Äôs imagine that a friend is trying to collect all 50 state quarters. While we sort our loose change by coin type, we‚Äôll also call out the name of the state associated with each quarter so that if it‚Äôs one our friend doesn‚Äôt have, they can add it to their collection. In the match expression for this code, we add a variable called state to the pattern that matches values of the variant Coin::Quarter. When a Coin::Quarter matches, the state variable will bind to the value of that quarter‚Äôs state. Then, we can use state in the code for that arm, like so: # #[derive(Debug)]\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => 1, Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter(state) => { println!(\\"State quarter from {state:?}!\\"); 25 } }\\n}\\n# # fn main() {\\n# value_in_cents(Coin::Quarter(UsState::Alaska));\\n# } If we were to call value_in_cents(Coin::Quarter(UsState::Alaska)), coin would be Coin::Quarter(UsState::Alaska). When we compare that value with each of the match arms, none of them match until we reach Coin::Quarter(state). At that point, the binding for state will be the value UsState::Alaska. We can then use that binding in the println! expression, thus getting the inner state value out of the Coin enum variant for Quarter.","breadcrumbs":"Enums and Pattern Matching ¬ª The match Control Flow Construct ¬ª Patterns That Bind to Values","id":"105","title":"Patterns That Bind to Values"},"106":{"body":"In the previous section, we wanted to get the inner T value out of the Some case when using Option<T>; we can also handle Option<T> using match, as we did with the Coin enum! Instead of comparing coins, we‚Äôll compare the variants of Option<T>, but the way the match expression works remains the same. Let‚Äôs say we want to write a function that takes an Option<i32> and, if there‚Äôs a value inside, adds 1 to that value. If there isn‚Äôt a value inside, the function should return the None value and not attempt to perform any operations. This function is very easy to write, thanks to match, and will look like Listing 6-5. # fn main() { fn plus_one(x: Option<i32>) -> Option<i32> { match x { None => None, Some(i) => Some(i + 1), } } let five = Some(5); let six = plus_one(five); let none = plus_one(None);\\n# } Listing 6-5: A function that uses a match expression on an Option&lt;i32&gt; Let‚Äôs examine the first execution of plus_one in more detail. When we call plus_one(five), the variable x in the body of plus_one will have the value Some(5). We then compare that against each match arm: # fn main() {\\n# fn plus_one(x: Option<i32>) -> Option<i32> {\\n# match x { None => None,\\n# Some(i) => Some(i + 1),\\n# }\\n# }\\n# # let five = Some(5);\\n# let six = plus_one(five);\\n# let none = plus_one(None);\\n# } The Some(5) value doesn‚Äôt match the pattern None, so we continue to the next arm: # fn main() {\\n# fn plus_one(x: Option<i32>) -> Option<i32> {\\n# match x {\\n# None => None, Some(i) => Some(i + 1),\\n# }\\n# }\\n# # let five = Some(5);\\n# let six = plus_one(five);\\n# let none = plus_one(None);\\n# } Does Some(5) match Some(i)? It does! We have the same variant. The i binds to the value contained in Some, so i takes the value 5. The code in the match arm is then executed, so we add 1 to the value of i and create a new Some value with our total 6 inside. Now let‚Äôs consider the second call of plus_one in Listing 6-5, where x is None. We enter the match and compare to the first arm: # fn main() {\\n# fn plus_one(x: Option<i32>) -> Option<i32> {\\n# match x { None => None,\\n# Some(i) => Some(i + 1),\\n# }\\n# }\\n# # let five = Some(5);\\n# let six = plus_one(five);\\n# let none = plus_one(None);\\n# } It matches! There‚Äôs no value to add to, so the program stops and returns the None value on the right side of =>. Because the first arm matched, no other arms are compared. Combining match and enums is useful in many situations. You‚Äôll see this pattern a lot in Rust code: match against an enum, bind a variable to the data inside, and then execute code based on it. It‚Äôs a bit tricky at first, but once you get used to it, you‚Äôll wish you had it in all languages. It‚Äôs consistently a user favorite.","breadcrumbs":"Enums and Pattern Matching ¬ª The match Control Flow Construct ¬ª The Option<T> match Pattern","id":"106","title":"The Option<T> match Pattern"},"107":{"body":"There‚Äôs one other aspect of match we need to discuss: The arms‚Äô patterns must cover all possibilities. Consider this version of our plus_one function, which has a bug and won‚Äôt compile: # fn main() { fn plus_one(x: Option<i32>) -> Option<i32> { match x { Some(i) => Some(i + 1), } }\\n# # let five = Some(5);\\n# let six = plus_one(five);\\n# let none = plus_one(None);\\n# } We didn‚Äôt handle the None case, so this code will cause a bug. Luckily, it‚Äôs a bug Rust knows how to catch. If we try to compile this code, we‚Äôll get this error: $ cargo run Compiling enums v0.1.0 (file:///projects/enums)\\nerror[E0004]: non-exhaustive patterns: `None` not covered --> src/main.rs:3:15 |\\n3 | match x { | ^ pattern `None` not covered |\\nnote: `Option<i32>` defined here --> /rustc/4eb161250e340c8f48f66e2b929ef4a5bed7c181/library/core/src/option.rs:572:1 ::: /rustc/4eb161250e340c8f48f66e2b929ef4a5bed7c181/library/core/src/option.rs:576:5 | = note: not covered = note: the matched value is of type `Option<i32>`\\nhelp: ensure that all possible cases are being handled by adding a match arm with a wildcard pattern or an explicit pattern as shown |\\n4 ~ Some(i) => Some(i + 1),\\n5 ~ None => todo!(), | For more information about this error, try `rustc --explain E0004`.\\nerror: could not compile `enums` (bin \\"enums\\") due to 1 previous error Rust knows that we didn‚Äôt cover every possible case and even knows which pattern we forgot! Matches in Rust are exhaustive : We must exhaust every last possibility in order for the code to be valid. Especially in the case of Option<T>, when Rust prevents us from forgetting to explicitly handle the None case, it protects us from assuming that we have a value when we might have null, thus making the billion-dollar mistake discussed earlier impossible.","breadcrumbs":"Enums and Pattern Matching ¬ª The match Control Flow Construct ¬ª Matches Are Exhaustive","id":"107","title":"Matches Are Exhaustive"},"108":{"body":"Using enums, we can also take special actions for a few particular values, but for all other values take one default action. Imagine we‚Äôre implementing a game where, if you roll a 3 on a dice roll, your player doesn‚Äôt move but instead gets a fancy new hat. If you roll a 7, your player loses a fancy hat. For all other values, your player moves that number of spaces on the game board. Here‚Äôs a match that implements that logic, with the result of the dice roll hardcoded rather than a random value, and all other logic represented by functions without bodies because actually implementing them is out of scope for this example: # fn main() { let dice_roll = 9; match dice_roll { 3 => add_fancy_hat(), 7 => remove_fancy_hat(), other => move_player(other), } fn add_fancy_hat() {} fn remove_fancy_hat() {} fn move_player(num_spaces: u8) {}\\n# } For the first two arms, the patterns are the literal values 3 and 7. For the last arm that covers every other possible value, the pattern is the variable we‚Äôve chosen to name other. The code that runs for the other arm uses the variable by passing it to the move_player function. This code compiles, even though we haven‚Äôt listed all the possible values a u8 can have, because the last pattern will match all values not specifically listed. This catch-all pattern meets the requirement that match must be exhaustive. Note that we have to put the catch-all arm last because the patterns are evaluated in order. If we had put the catch-all arm earlier, the other arms would never run, so Rust will warn us if we add arms after a catch-all! Rust also has a pattern we can use when we want a catch-all but don‚Äôt want to use the value in the catch-all pattern: _ is a special pattern that matches any value and does not bind to that value. This tells Rust we aren‚Äôt going to use the value, so Rust won‚Äôt warn us about an unused variable. Let‚Äôs change the rules of the game: Now, if you roll anything other than a 3 or a 7, you must roll again. We no longer need to use the catch-all value, so we can change our code to use _ instead of the variable named other: # fn main() { let dice_roll = 9; match dice_roll { 3 => add_fancy_hat(), 7 => remove_fancy_hat(), _ => reroll(), } fn add_fancy_hat() {} fn remove_fancy_hat() {} fn reroll() {}\\n# } This example also meets the exhaustiveness requirement because we‚Äôre explicitly ignoring all other values in the last arm; we haven‚Äôt forgotten anything. Finally, we‚Äôll change the rules of the game one more time so that nothing else happens on your turn if you roll anything other than a 3 or a 7. We can express that by using the unit value (the empty tuple type we mentioned in ‚ÄúThe Tuple Type‚Äù section) as the code that goes with the _ arm: # fn main() { let dice_roll = 9; match dice_roll { 3 => add_fancy_hat(), 7 => remove_fancy_hat(), _ => (), } fn add_fancy_hat() {} fn remove_fancy_hat() {}\\n# } Here, we‚Äôre telling Rust explicitly that we aren‚Äôt going to use any other value that doesn‚Äôt match a pattern in an earlier arm, and we don‚Äôt want to run any code in this case. There‚Äôs more about patterns and matching that we‚Äôll cover in Chapter 19 . For now, we‚Äôre going to move on to the if let syntax, which can be useful in situations where the match expression is a bit wordy.","breadcrumbs":"Enums and Pattern Matching ¬ª The match Control Flow Construct ¬ª Catch-All Patterns and the _ Placeholder","id":"108","title":"Catch-All Patterns and the _ Placeholder"},"109":{"body":"The if let syntax lets you combine if and let into a less verbose way to handle values that match one pattern while ignoring the rest. Consider the program in Listing 6-6 that matches on an Option<u8> value in the config_max variable but only wants to execute code if the value is the Some variant. # fn main() { let config_max = Some(3u8); match config_max { Some(max) => println!(\\"The maximum is configured to be {max}\\"), _ => (), }\\n# } Listing 6-6: A match that only cares about executing code when the value is Some If the value is Some, we print out the value in the Some variant by binding the value to the variable max in the pattern. We don‚Äôt want to do anything with the None value. To satisfy the match expression, we have to add _ => () after processing just one variant, which is annoying boilerplate code to add. Instead, we could write this in a shorter way using if let. The following code behaves the same as the match in Listing 6-6: # fn main() { let config_max = Some(3u8); if let Some(max) = config_max { println!(\\"The maximum is configured to be {max}\\"); }\\n# } The syntax if let takes a pattern and an expression separated by an equal sign. It works the same way as a match, where the expression is given to the match and the pattern is its first arm. In this case, the pattern is Some(max), and the max binds to the value inside the Some. We can then use max in the body of the if let block in the same way we used max in the corresponding match arm. The code in the if let block only runs if the value matches the pattern. Using if let means less typing, less indentation, and less boilerplate code. However, you lose the exhaustive checking match enforces that ensures that you aren‚Äôt forgetting to handle any cases. Choosing between match and if let depends on what you‚Äôre doing in your particular situation and whether gaining conciseness is an appropriate trade-off for losing exhaustive checking. In other words, you can think of if let as syntax sugar for a match that runs code when the value matches one pattern and then ignores all other values. We can include an else with an if let. The block of code that goes with the else is the same as the block of code that would go with the _ case in the match expression that is equivalent to the if let and else. Recall the Coin enum definition in Listing 6-4, where the Quarter variant also held a UsState value. If we wanted to count all non-quarter coins we see while also announcing the state of the quarters, we could do that with a match expression, like this: # #[derive(Debug)]\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# # fn main() {\\n# let coin = Coin::Penny; let mut count = 0; match coin { Coin::Quarter(state) => println!(\\"State quarter from {state:?}!\\"), _ => count += 1, }\\n# } Or we could use an if let and else expression, like this: # #[derive(Debug)]\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# # fn main() {\\n# let coin = Coin::Penny; let mut count = 0; if let Coin::Quarter(state) = coin { println!(\\"State quarter from {state:?}!\\"); } else { count += 1; }\\n# }","breadcrumbs":"Enums and Pattern Matching ¬ª Concise Control Flow with if let and let else ¬ª Concise Control Flow with if let and let else","id":"109","title":"Concise Control Flow with if let and let else"},"11":{"body":"The source files from which this book is generated can be found on GitHub .","breadcrumbs":"Introduction ¬ª Source Code","id":"11","title":"Source Code"},"110":{"body":"The common pattern is to perform some computation when a value is present and return a default value otherwise. Continuing with our example of coins with a UsState value, if we wanted to say something funny depending on how old the state on the quarter was, we might introduce a method on UsState to check the age of a state, like so: # #[derive(Debug)] // so we can inspect the state in a minute\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# impl UsState { fn existed_in(&self, year: u16) -> bool { match self { UsState::Alabama => year >= 1819, UsState::Alaska => year >= 1959, // -- snip -- } }\\n}\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# # fn describe_state_quarter(coin: Coin) -> Option<String> {\\n# if let Coin::Quarter(state) = coin {\\n# if state.existed_in(1900) {\\n# Some(format!(\\"{state:?} is pretty old, for America!\\"))\\n# } else {\\n# Some(format!(\\"{state:?} is relatively new.\\"))\\n# }\\n# } else {\\n# None\\n# }\\n# }\\n# # fn main() {\\n# if let Some(desc) = describe_state_quarter(Coin::Quarter(UsState::Alaska)) {\\n# println!(\\"{desc}\\");\\n# }\\n# } Then, we might use if let to match on the type of coin, introducing a state variable within the body of the condition, as in Listing 6-7. # #[derive(Debug)] // so we can inspect the state in a minute\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # impl UsState {\\n# fn existed_in(&self, year: u16) -> bool {\\n# match self {\\n# UsState::Alabama => year >= 1819,\\n# UsState::Alaska => year >= 1959,\\n# // -- snip --\\n# }\\n# }\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# fn describe_state_quarter(coin: Coin) -> Option<String> { if let Coin::Quarter(state) = coin { if state.existed_in(1900) { Some(format!(\\"{state:?} is pretty old, for America!\\")) } else { Some(format!(\\"{state:?} is relatively new.\\")) } } else { None }\\n}\\n# # fn main() {\\n# if let Some(desc) = describe_state_quarter(Coin::Quarter(UsState::Alaska)) {\\n# println!(\\"{desc}\\");\\n# }\\n# } Listing 6-7: Checking whether a state existed in 1900 by using conditionals nested inside an if let That gets the job done, but it has pushed the work into the body of the if let statement, and if the work to be done is more complicated, it might be hard to follow exactly how the top-level branches relate. We could also take advantage of the fact that expressions produce a value either to produce the state from the if let or to return early, as in Listing 6-8. (You could do something similar with a match, too.) # #[derive(Debug)] // so we can inspect the state in a minute\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # impl UsState {\\n# fn existed_in(&self, year: u16) -> bool {\\n# match self {\\n# UsState::Alabama => year >= 1819,\\n# UsState::Alaska => year >= 1959,\\n# // -- snip --\\n# }\\n# }\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# fn describe_state_quarter(coin: Coin) -> Option<String> { let state = if let Coin::Quarter(state) = coin { state } else { return None; }; if state.existed_in(1900) { Some(format!(\\"{state:?} is pretty old, for America!\\")) } else { Some(format!(\\"{state:?} is relatively new.\\")) }\\n}\\n# # fn main() {\\n# if let Some(desc) = describe_state_quarter(Coin::Quarter(UsState::Alaska)) {\\n# println!(\\"{desc}\\");\\n# }\\n# } Listing 6-8: Using if let to produce a value or return early This is a bit annoying to follow in its own way, though! One branch of the if let produces a value, and the other one returns from the function entirely. To make this common pattern nicer to express, Rust has let...else. The let...else syntax takes a pattern on the left side and an expression on the right, very similar to if let, but it does not have an if branch, only an else branch. If the pattern matches, it will bind the value from the pattern in the outer scope. If the pattern does not match, the program will flow into the else arm, which must return from the function. In Listing 6-9, you can see how Listing 6-8 looks when using let...else in place of if let. # #[derive(Debug)] // so we can inspect the state in a minute\\n# enum UsState {\\n# Alabama,\\n# Alaska,\\n# // --snip--\\n# }\\n# # impl UsState {\\n# fn existed_in(&self, year: u16) -> bool {\\n# match self {\\n# UsState::Alabama => year >= 1819,\\n# UsState::Alaska => year >= 1959,\\n# // -- snip --\\n# }\\n# }\\n# }\\n# # enum Coin {\\n# Penny,\\n# Nickel,\\n# Dime,\\n# Quarter(UsState),\\n# }\\n# fn describe_state_quarter(coin: Coin) -> Option<String> { let Coin::Quarter(state) = coin else { return None; }; if state.existed_in(1900) { Some(format!(\\"{state:?} is pretty old, for America!\\")) } else { Some(format!(\\"{state:?} is relatively new.\\")) }\\n}\\n# # fn main() {\\n# if let Some(desc) = describe_state_quarter(Coin::Quarter(UsState::Alaska)) {\\n# println!(\\"{desc}\\");\\n# }\\n# } Listing 6-9: Using let...else to clarify the flow through the function Notice that it stays on the ‚Äúhappy path‚Äù in the main body of the function this way, without having significantly different control flow for two branches the way the if let did. If you have a situation in which your program has logic that is too verbose to express using a match, remember that if let and let...else are in your Rust toolbox as well.","breadcrumbs":"Enums and Pattern Matching ¬ª Concise Control Flow with if let and let else ¬ª Staying on the ‚ÄúHappy Path‚Äù with let...else","id":"110","title":"Staying on the ‚ÄúHappy Path‚Äù with let...else"},"111":{"body":"We‚Äôve now covered how to use enums to create custom types that can be one of a set of enumerated values. We‚Äôve shown how the standard library‚Äôs Option<T> type helps you use the type system to prevent errors. When enum values have data inside them, you can use match or if let to extract and use those values, depending on how many cases you need to handle. Your Rust programs can now express concepts in your domain using structs and enums. Creating custom types to use in your API ensures type safety: The compiler will make certain your functions only get values of the type each function expects. In order to provide a well-organized API to your users that is straightforward to use and only exposes exactly what your users will need, let‚Äôs now turn to Rust‚Äôs modules.","breadcrumbs":"Enums and Pattern Matching ¬ª Concise Control Flow with if let and let else ¬ª Summary","id":"111","title":"Summary"},"112":{"body":"As you write large programs, organizing your code will become increasingly important. By grouping related functionality and separating code with distinct features, you‚Äôll clarify where to find code that implements a particular feature and where to go to change how a feature works. The programs we‚Äôve written so far have been in one module in one file. As a project grows, you should organize code by splitting it into multiple modules and then multiple files. A package can contain multiple binary crates and optionally one library crate. As a package grows, you can extract parts into separate crates that become external dependencies. This chapter covers all these techniques. For very large projects comprising a set of interrelated packages that evolve together, Cargo provides workspaces, which we‚Äôll cover in ‚ÄúCargo Workspaces‚Äù in Chapter 14. We‚Äôll also discuss encapsulating implementation details, which lets you reuse code at a higher level: Once you‚Äôve implemented an operation, other code can call your code via its public interface without having to know how the implementation works. The way you write code defines which parts are public for other code to use and which parts are private implementation details that you reserve the right to change. This is another way to limit the amount of detail you have to keep in your head. A related concept is scope: The nested context in which code is written has a set of names that are defined as ‚Äúin scope.‚Äù When reading, writing, and compiling code, programmers and compilers need to know whether a particular name at a particular spot refers to a variable, function, struct, enum, module, constant, or other item and what that item means. You can create scopes and change which names are in or out of scope. You can‚Äôt have two items with the same name in the same scope; tools are available to resolve name conflicts. Rust has a number of features that allow you to manage your code‚Äôs organization, including which details are exposed, which details are private, and what names are in each scope in your programs. These features, sometimes collectively referred to as the module system , include: Packages : A Cargo feature that lets you build, test, and share crates Crates : A tree of modules that produces a library or executable Modules and use : Let you control the organization, scope, and privacy of paths Paths : A way of naming an item, such as a struct, function, or module In this chapter, we‚Äôll cover all these features, discuss how they interact, and explain how to use them to manage scope. By the end, you should have a solid understanding of the module system and be able to work with scopes like a pro!","breadcrumbs":"Packages, Crates, and Modules ¬ª Packages, Crates, and Modules","id":"112","title":"Packages, Crates, and Modules"},"113":{"body":"The first parts of the module system we‚Äôll cover are packages and crates. A crate is the smallest amount of code that the Rust compiler considers at a time. Even if you run rustc rather than cargo and pass a single source code file (as we did all the way back in ‚ÄúRust Program Basics‚Äù in Chapter 1), the compiler considers that file to be a crate. Crates can contain modules, and the modules may be defined in other files that get compiled with the crate, as we‚Äôll see in the coming sections. A crate can come in one of two forms: a binary crate or a library crate. Binary crates are programs you can compile to an executable that you can run, such as a command line program or a server. Each must have a function called main that defines what happens when the executable runs. All the crates we‚Äôve created so far have been binary crates. Library crates don‚Äôt have a main function, and they don‚Äôt compile to an executable. Instead, they define functionality intended to be shared with multiple projects. For example, the rand crate we used in Chapter 2 provides functionality that generates random numbers. Most of the time when Rustaceans say ‚Äúcrate,‚Äù they mean library crate, and they use ‚Äúcrate‚Äù interchangeably with the general programming concept of a ‚Äúlibrary.‚Äù The crate root is a source file that the Rust compiler starts from and makes up the root module of your crate (we‚Äôll explain modules in depth in ‚ÄúControl Scope and Privacy with Modules‚Äù ). A package is a bundle of one or more crates that provides a set of functionality. A package contains a Cargo.toml file that describes how to build those crates. Cargo is actually a package that contains the binary crate for the command line tool you‚Äôve been using to build your code. The Cargo package also contains a library crate that the binary crate depends on. Other projects can depend on the Cargo library crate to use the same logic the Cargo command line tool uses. A package can contain as many binary crates as you like, but at most only one library crate. A package must contain at least one crate, whether that‚Äôs a library or binary crate. Let‚Äôs walk through what happens when we create a package. First, we enter the command cargo new my-project: $ cargo new my-project Created binary (application) `my-project` package\\n$ ls my-project\\nCargo.toml\\nsrc\\n$ ls my-project/src\\nmain.rs After we run cargo new my-project, we use ls to see what Cargo creates. In the my-project directory, there‚Äôs a Cargo.toml file, giving us a package. There‚Äôs also a src directory that contains main.rs . Open Cargo.toml in your text editor and note that there‚Äôs no mention of src/main.rs . Cargo follows a convention that src/main.rs is the crate root of a binary crate with the same name as the package. Likewise, Cargo knows that if the package directory contains src/lib.rs , the package contains a library crate with the same name as the package, and src/lib.rs is its crate root. Cargo passes the crate root files to rustc to build the library or binary. Here, we have a package that only contains src/main.rs , meaning it only contains a binary crate named my-project. If a package contains src/main.rs and src/lib.rs , it has two crates: a binary and a library, both with the same name as the package. A package can have multiple binary crates by placing files in the src/bin directory: Each file will be a separate binary crate.","breadcrumbs":"Packages, Crates, and Modules ¬ª Packages and Crates ¬ª Packages and Crates","id":"113","title":"Packages and Crates"},"114":{"body":"In this section, we‚Äôll talk about modules and other parts of the module system, namely paths , which allow you to name items; the use keyword that brings a path into scope; and the pub keyword to make items public. We‚Äôll also discuss the as keyword, external packages, and the glob operator.","breadcrumbs":"Packages, Crates, and Modules ¬ª Control Scope and Privacy with Modules ¬ª Control Scope and Privacy with Modules","id":"114","title":"Control Scope and Privacy with Modules"},"115":{"body":"Before we get to the details of modules and paths, here we provide a quick reference on how modules, paths, the use keyword, and the pub keyword work in the compiler, and how most developers organize their code. We‚Äôll be going through examples of each of these rules throughout this chapter, but this is a great place to refer to as a reminder of how modules work. Start from the crate root : When compiling a crate, the compiler first looks in the crate root file (usually src/lib.rs for a library crate and src/main.rs for a binary crate) for code to compile. Declaring modules : In the crate root file, you can declare new modules; say you declare a ‚Äúgarden‚Äù module with mod garden;. The compiler will look for the module‚Äôs code in these places: Inline, within curly brackets that replace the semicolon following mod garden In the file src/garden.rs In the file src/garden/mod.rs Declaring submodules : In any file other than the crate root, you can declare submodules. For example, you might declare mod vegetables; in src/garden.rs . The compiler will look for the submodule‚Äôs code within the directory named for the parent module in these places: Inline, directly following mod vegetables, within curly brackets instead of the semicolon In the file src/garden/vegetables.rs In the file src/garden/vegetables/mod.rs Paths to code in modules : Once a module is part of your crate, you can refer to code in that module from anywhere else in that same crate, as long as the privacy rules allow, using the path to the code. For example, an Asparagus type in the garden vegetables module would be found at crate::garden::vegetables::Asparagus. Private vs. public : Code within a module is private from its parent modules by default. To make a module public, declare it with pub mod instead of mod. To make items within a public module public as well, use pub before their declarations. The use keyword : Within a scope, the use keyword creates shortcuts to items to reduce repetition of long paths. In any scope that can refer to crate::garden::vegetables::Asparagus, you can create a shortcut with use crate::garden::vegetables::Asparagus;, and from then on you only need to write Asparagus to make use of that type in the scope. Here, we create a binary crate named backyard that illustrates these rules. The crate‚Äôs directory, also named backyard , contains these files and directories: backyard\\n‚îú‚îÄ‚îÄ Cargo.lock\\n‚îú‚îÄ‚îÄ Cargo.toml\\n‚îî‚îÄ‚îÄ src ‚îú‚îÄ‚îÄ garden ‚îÇ ‚îî‚îÄ‚îÄ vegetables.rs ‚îú‚îÄ‚îÄ garden.rs ‚îî‚îÄ‚îÄ main.rs The crate root file in this case is src/main.rs , and it contains: Filename: src/main.rs use crate::garden::vegetables::Asparagus; pub mod garden; fn main() { let plant = Asparagus {}; println!(\\"I\'m growing {plant:?}!\\");\\n} The pub mod garden; line tells the compiler to include the code it finds in src/garden.rs , which is: Filename: src/garden.rs pub mod vegetables; Here, pub mod vegetables; means the code in src/garden/vegetables.rs is included too. That code is: #[derive(Debug)]\\npub struct Asparagus {} Now let‚Äôs get into the details of these rules and demonstrate them in action!","breadcrumbs":"Packages, Crates, and Modules ¬ª Control Scope and Privacy with Modules ¬ª Modules Cheat Sheet","id":"115","title":"Modules Cheat Sheet"},"116":{"body":"Modules let us organize code within a crate for readability and easy reuse. Modules also allow us to control the privacy of items because code within a module is private by default. Private items are internal implementation details not available for outside use. We can choose to make modules and the items within them public, which exposes them to allow external code to use and depend on them. As an example, let‚Äôs write a library crate that provides the functionality of a restaurant. We‚Äôll define the signatures of functions but leave their bodies empty to concentrate on the organization of the code rather than the implementation of a restaurant. In the restaurant industry, some parts of a restaurant are referred to as front of house and others as back of house. Front of house is where customers are; this encompasses where the hosts seat customers, servers take orders and payment, and bartenders make drinks. Back of house is where the chefs and cooks work in the kitchen, dishwashers clean up, and managers do administrative work. To structure our crate in this way, we can organize its functions into nested modules. Create a new library named restaurant by running cargo new restaurant --lib. Then, enter the code in Listing 7-1 into src/lib.rs to define some modules and function signatures; this code is the front of house section. Filename: src/lib.rs mod front_of_house { mod hosting { fn add_to_waitlist() {} fn seat_at_table() {} } mod serving { fn take_order() {} fn serve_order() {} fn take_payment() {} }\\n} Listing 7-1: A front_of_house module containing other modules that then contain functions We define a module with the mod keyword followed by the name of the module (in this case, front_of_house). The body of the module then goes inside curly brackets. Inside modules, we can place other modules, as in this case with the modules hosting and serving. Modules can also hold definitions for other items, such as structs, enums, constants, traits, and as in Listing 7-1, functions. By using modules, we can group related definitions together and name why they‚Äôre related. Programmers using this code can navigate the code based on the groups rather than having to read through all the definitions, making it easier to find the definitions relevant to them. Programmers adding new functionality to this code would know where to place the code to keep the program organized. Earlier, we mentioned that src/main.rs and src/lib.rs are called crate roots _. The reason for their name is that the contents of either of these two files form a module named crate at the root of the crate‚Äôs module structure, known as the module tree . Listing 7-2 shows the module tree for the structure in Listing 7-1. crate ‚îî‚îÄ‚îÄ front_of_house ‚îú‚îÄ‚îÄ hosting ‚îÇ ‚îú‚îÄ‚îÄ add_to_waitlist ‚îÇ ‚îî‚îÄ‚îÄ seat_at_table ‚îî‚îÄ‚îÄ serving ‚îú‚îÄ‚îÄ take_order ‚îú‚îÄ‚îÄ serve_order ‚îî‚îÄ‚îÄ take_payment Listing 7-2: The module tree for the code in Listing 7-1 This tree shows how some of the modules nest inside other modules; for example, hosting nests inside front_of_house. The tree also shows that some modules are siblings , meaning they‚Äôre defined in the same module; hosting and serving are siblings defined within front_of_house. If module A is contained inside module B, we say that module A is the child of module B and that module B is the parent of module A. Notice that the entire module tree is rooted under the implicit module named crate. The module tree might remind you of the filesystem‚Äôs directory tree on your computer; this is a very apt comparison! Just like directories in a filesystem, you use modules to organize your code. And just like files in a directory, we need a way to find our modules.","breadcrumbs":"Packages, Crates, and Modules ¬ª Control Scope and Privacy with Modules ¬ª Grouping Related Code in Modules","id":"116","title":"Grouping Related Code in Modules"},"117":{"body":"To show Rust where to find an item in a module tree, we use a path in the same way we use a path when navigating a filesystem. To call a function, we need to know its path. A path can take two forms: An absolute path is the full path starting from a crate root; for code from an external crate, the absolute path begins with the crate name, and for code from the current crate, it starts with the literal crate. A relative path starts from the current module and uses self, super, or an identifier in the current module. Both absolute and relative paths are followed by one or more identifiers separated by double colons (::). Returning to Listing 7-1, say we want to call the add_to_waitlist function. This is the same as asking: What‚Äôs the path of the add_to_waitlist function? Listing 7-3 contains Listing 7-1 with some of the modules and functions removed. We‚Äôll show two ways to call the add_to_waitlist function from a new function, eat_at_restaurant, defined in the crate root. These paths are correct, but there‚Äôs another problem remaining that will prevent this example from compiling as is. We‚Äôll explain why in a bit. The eat_at_restaurant function is part of our library crate‚Äôs public API, so we mark it with the pub keyword. In the ‚ÄúExposing Paths with the pub Keyword‚Äù section, we‚Äôll go into more detail about pub. Filename: src/lib.rs mod front_of_house { mod hosting { fn add_to_waitlist() {} }\\n} pub fn eat_at_restaurant() { // Absolute path crate::front_of_house::hosting::add_to_waitlist(); // Relative path front_of_house::hosting::add_to_waitlist();\\n} Listing 7-3: Calling the add_to_waitlist function using absolute and relative paths The first time we call the add_to_waitlist function in eat_at_restaurant, we use an absolute path. The add_to_waitlist function is defined in the same crate as eat_at_restaurant, which means we can use the crate keyword to start an absolute path. We then include each of the successive modules until we make our way to add_to_waitlist. You can imagine a filesystem with the same structure: We‚Äôd specify the path /front_of_house/hosting/add_to_waitlist to run the add_to_waitlist program; using the crate name to start from the crate root is like using / to start from the filesystem root in your shell. The second time we call add_to_waitlist in eat_at_restaurant, we use a relative path. The path starts with front_of_house, the name of the module defined at the same level of the module tree as eat_at_restaurant. Here the filesystem equivalent would be using the path front_of_house/hosting/add_to_waitlist. Starting with a module name means that the path is relative. Choosing whether to use a relative or absolute path is a decision you‚Äôll make based on your project, and it depends on whether you‚Äôre more likely to move item definition code separately from or together with the code that uses the item. For example, if we moved the front_of_house module and the eat_at_restaurant function into a module named customer_experience, we‚Äôd need to update the absolute path to add_to_waitlist, but the relative path would still be valid. However, if we moved the eat_at_restaurant function separately into a module named dining, the absolute path to the add_to_waitlist call would stay the same, but the relative path would need to be updated. Our preference in general is to specify absolute paths because it‚Äôs more likely we‚Äôll want to move code definitions and item calls independently of each other. Let‚Äôs try to compile Listing 7-3 and find out why it won‚Äôt compile yet! The errors we get are shown in Listing 7-4. $ cargo build Compiling restaurant v0.1.0 (file:///projects/restaurant)\\nerror[E0603]: module `hosting` is private --> src/lib.rs:9:28 |\\n9 | crate::front_of_house::hosting::add_to_waitlist(); | ^^^^^^^ --------------- function `add_to_waitlist` is not publicly re-exported | | | private module |\\nnote: the module `hosting` is defined here --> src/lib.rs:2:5 |\\n2 | mod hosting { | ^^^^^^^^^^^ error[E0603]: module `hosting` is private --> src/lib.rs:12:21 |\\n12 | front_of_house::hosting::add_to_waitlist(); | ^^^^^^^ --------------- function `add_to_waitlist` is not publicly re-exported | | | private module |\\nnote: the module `hosting` is defined here --> src/lib.rs:2:5 |\\n2 | mod hosting { | ^^^^^^^^^^^ For more information about this error, try `rustc --explain E0603`.\\nerror: could not compile `restaurant` (lib) due to 2 previous errors Listing 7-4: Compiler errors from building the code in Listing 7-3 The error messages say that module hosting is private. In other words, we have the correct paths for the hosting module and the add_to_waitlist function, but Rust won‚Äôt let us use them because it doesn‚Äôt have access to the private sections. In Rust, all items (functions, methods, structs, enums, modules, and constants) are private to parent modules by default. If you want to make an item like a function or struct private, you put it in a module. Items in a parent module can‚Äôt use the private items inside child modules, but items in child modules can use the items in their ancestor modules. This is because child modules wrap and hide their implementation details, but the child modules can see the context in which they‚Äôre defined. To continue with our metaphor, think of the privacy rules as being like the back office of a restaurant: What goes on in there is private to restaurant customers, but office managers can see and do everything in the restaurant they operate. Rust chose to have the module system function this way so that hiding inner implementation details is the default. That way, you know which parts of the inner code you can change without breaking the outer code. However, Rust does give you the option to expose inner parts of child modules‚Äô code to outer ancestor modules by using the pub keyword to make an item public.","breadcrumbs":"Packages, Crates, and Modules ¬ª Paths for Referring to an Item in the Module Tree ¬ª Paths for Referring to an Item in the Module Tree","id":"117","title":"Paths for Referring to an Item in the Module Tree"},"118":{"body":"Let‚Äôs return to the error in Listing 7-4 that told us the hosting module is private. We want the eat_at_restaurant function in the parent module to have access to the add_to_waitlist function in the child module, so we mark the hosting module with the pub keyword, as shown in Listing 7-5. Filename: src/lib.rs mod front_of_house { pub mod hosting { fn add_to_waitlist() {} }\\n} // -- snip --\\n# pub fn eat_at_restaurant() {\\n# // Absolute path\\n# crate::front_of_house::hosting::add_to_waitlist();\\n# # // Relative path\\n# front_of_house::hosting::add_to_waitlist();\\n# } Listing 7-5: Declaring the hosting module as pub to use it from eat_at_restaurant Unfortunately, the code in Listing 7-5 still results in compiler errors, as shown in Listing 7-6. $ cargo build Compiling restaurant v0.1.0 (file:///projects/restaurant)\\nerror[E0603]: function `add_to_waitlist` is private --> src/lib.rs:10:37 |\\n10 | crate::front_of_house::hosting::add_to_waitlist(); | ^^^^^^^^^^^^^^^ private function |\\nnote: the function `add_to_waitlist` is defined here --> src/lib.rs:3:9 |\\n3 | fn add_to_waitlist() {} | ^^^^^^^^^^^^^^^^^^^^ error[E0603]: function `add_to_waitlist` is private --> src/lib.rs:13:30 |\\n13 | front_of_house::hosting::add_to_waitlist(); | ^^^^^^^^^^^^^^^ private function |\\nnote: the function `add_to_waitlist` is defined here --> src/lib.rs:3:9 |\\n3 | fn add_to_waitlist() {} | ^^^^^^^^^^^^^^^^^^^^ For more information about this error, try `rustc --explain E0603`.\\nerror: could not compile `restaurant` (lib) due to 2 previous errors Listing 7-6: Compiler errors from building the code in Listing 7-5 What happened? Adding the pub keyword in front of mod hosting makes the module public. With this change, if we can access front_of_house, we can access hosting. But the contents of hosting are still private; making the module public doesn‚Äôt make its contents public. The pub keyword on a module only lets code in its ancestor modules refer to it, not access its inner code. Because modules are containers, there‚Äôs not much we can do by only making the module public; we need to go further and choose to make one or more of the items within the module public as well. The errors in Listing 7-6 say that the add_to_waitlist function is private. The privacy rules apply to structs, enums, functions, and methods as well as modules. Let‚Äôs also make the add_to_waitlist function public by adding the pub keyword before its definition, as in Listing 7-7. Filename: src/lib.rs mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} }\\n} // -- snip --\\n# pub fn eat_at_restaurant() {\\n# // Absolute path\\n# crate::front_of_house::hosting::add_to_waitlist();\\n# # // Relative path\\n# front_of_house::hosting::add_to_waitlist();\\n# } Listing 7-7: Adding the pub keyword to mod hosting and fn add_to_waitlist lets us call the function from eat_at_restaurant. Now the code will compile! To see why adding the pub keyword lets us use these paths in eat_at_restaurant with respect to the privacy rules, let‚Äôs look at the absolute and the relative paths. In the absolute path, we start with crate, the root of our crate‚Äôs module tree. The front_of_house module is defined in the crate root. While front_of_house isn‚Äôt public, because the eat_at_restaurant function is defined in the same module as front_of_house (that is, eat_at_restaurant and front_of_house are siblings), we can refer to front_of_house from eat_at_restaurant. Next is the hosting module marked with pub. We can access the parent module of hosting, so we can access hosting. Finally, the add_to_waitlist function is marked with pub, and we can access its parent module, so this function call works! In the relative path, the logic is the same as the absolute path except for the first step: Rather than starting from the crate root, the path starts from front_of_house. The front_of_house module is defined within the same module as eat_at_restaurant, so the relative path starting from the module in which eat_at_restaurant is defined works. Then, because hosting and add_to_waitlist are marked with pub, the rest of the path works, and this function call is valid! If you plan to share your library crate so that other projects can use your code, your public API is your contract with users of your crate that determines how they can interact with your code. There are many considerations around managing changes to your public API to make it easier for people to depend on your crate. These considerations are beyond the scope of this book; if you‚Äôre interested in this topic, see the Rust API Guidelines . Best Practices for Packages with a Binary and a Library We mentioned that a package can contain both a src/main.rs binary crate root as well as a src/lib.rs library crate root, and both crates will have the package name by default. Typically, packages with this pattern of containing both a library and a binary crate will have just enough code in the binary crate to start an executable that calls code defined in the library crate. This lets other projects benefit from the most functionality that the package provides because the library crate‚Äôs code can be shared. The module tree should be defined in src/lib.rs . Then, any public items can be used in the binary crate by starting paths with the name of the package. The binary crate becomes a user of the library crate just like a completely external crate would use the library crate: It can only use the public API. This helps you design a good API; not only are you the author, but you‚Äôre also a client! In Chapter 12 , we‚Äôll demonstrate this organizational practice with a command line program that will contain both a binary crate and a library crate.","breadcrumbs":"Packages, Crates, and Modules ¬ª Paths for Referring to an Item in the Module Tree ¬ª Exposing Paths with the pub Keyword","id":"118","title":"Exposing Paths with the pub Keyword"},"119":{"body":"We can construct relative paths that begin in the parent module, rather than the current module or the crate root, by using super at the start of the path. This is like starting a filesystem path with the .. syntax that means to go to the parent directory. Using super allows us to reference an item that we know is in the parent module, which can make rearranging the module tree easier when the module is closely related to the parent but the parent might be moved elsewhere in the module tree someday. Consider the code in Listing 7-8 that models the situation in which a chef fixes an incorrect order and personally brings it out to the customer. The function fix_incorrect_order defined in the back_of_house module calls the function deliver_order defined in the parent module by specifying the path to deliver_order, starting with super. Filename: src/lib.rs fn deliver_order() {} mod back_of_house { fn fix_incorrect_order() { cook_order(); super::deliver_order(); } fn cook_order() {}\\n} Listing 7-8: Calling a function using a relative path starting with super The fix_incorrect_order function is in the back_of_house module, so we can use super to go to the parent module of back_of_house, which in this case is crate, the root. From there, we look for deliver_order and find it. Success! We think the back_of_house module and the deliver_order function are likely to stay in the same relationship to each other and get moved together should we decide to reorganize the crate‚Äôs module tree. Therefore, we used super so that we‚Äôll have fewer places to update code in the future if this code gets moved to a different module.","breadcrumbs":"Packages, Crates, and Modules ¬ª Paths for Referring to an Item in the Module Tree ¬ª Starting Relative Paths with super","id":"119","title":"Starting Relative Paths with super"},"12":{"body":"Let‚Äôs start your Rust journey! There‚Äôs a lot to learn, but every journey starts somewhere. In this chapter, we‚Äôll discuss: Installing Rust on Linux, macOS, and Windows Writing a program that prints Hello, world! Using cargo, Rust‚Äôs package manager and build system","breadcrumbs":"Getting Started ¬ª Getting Started","id":"12","title":"Getting Started"},"120":{"body":"We can also use pub to designate structs and enums as public, but there are a few extra details to the usage of pub with structs and enums. If we use pub before a struct definition, we make the struct public, but the struct‚Äôs fields will still be private. We can make each field public or not on a case-by-case basis. In Listing 7-9, we‚Äôve defined a public back_of_house::Breakfast struct with a public toast field but a private seasonal_fruit field. This models the case in a restaurant where the customer can pick the type of bread that comes with a meal, but the chef decides which fruit accompanies the meal based on what‚Äôs in season and in stock. The available fruit changes quickly, so customers can‚Äôt choose the fruit or even see which fruit they‚Äôll get. Filename: src/lib.rs mod back_of_house { pub struct Breakfast { pub toast: String, seasonal_fruit: String, } impl Breakfast { pub fn summer(toast: &str) -> Breakfast { Breakfast { toast: String::from(toast), seasonal_fruit: String::from(\\"peaches\\"), } } }\\n} pub fn eat_at_restaurant() { // Order a breakfast in the summer with Rye toast. let mut meal = back_of_house::Breakfast::summer(\\"Rye\\"); // Change our mind about what bread we\'d like. meal.toast = String::from(\\"Wheat\\"); println!(\\"I\'d like {} toast please\\", meal.toast); // The next line won\'t compile if we uncomment it; we\'re not allowed // to see or modify the seasonal fruit that comes with the meal. // meal.seasonal_fruit = String::from(\\"blueberries\\");\\n} Listing 7-9: A struct with some public fields and some private fields Because the toast field in the back_of_house::Breakfast struct is public, in eat_at_restaurant we can write and read to the toast field using dot notation. Notice that we can‚Äôt use the seasonal_fruit field in eat_at_restaurant, because seasonal_fruit is private. Try uncommenting the line modifying the seasonal_fruit field value to see what error you get! Also, note that because back_of_house::Breakfast has a private field, the struct needs to provide a public associated function that constructs an instance of Breakfast (we‚Äôve named it summer here). If Breakfast didn‚Äôt have such a function, we couldn‚Äôt create an instance of Breakfast in eat_at_restaurant, because we couldn‚Äôt set the value of the private seasonal_fruit field in eat_at_restaurant. In contrast, if we make an enum public, all of its variants are then public. We only need the pub before the enum keyword, as shown in Listing 7-10. Filename: src/lib.rs mod back_of_house { pub enum Appetizer { Soup, Salad, }\\n} pub fn eat_at_restaurant() { let order1 = back_of_house::Appetizer::Soup; let order2 = back_of_house::Appetizer::Salad;\\n} Listing 7-10: Designating an enum as public makes all its variants public. Because we made the Appetizer enum public, we can use the Soup and Salad variants in eat_at_restaurant. Enums aren‚Äôt very useful unless their variants are public; it would be annoying to have to annotate all enum variants with pub in every case, so the default for enum variants is to be public. Structs are often useful without their fields being public, so struct fields follow the general rule of everything being private by default unless annotated with pub. There‚Äôs one more situation involving pub that we haven‚Äôt covered, and that is our last module system feature: the use keyword. We‚Äôll cover use by itself first, and then we‚Äôll show how to combine pub and use.","breadcrumbs":"Packages, Crates, and Modules ¬ª Paths for Referring to an Item in the Module Tree ¬ª Making Structs and Enums Public","id":"120","title":"Making Structs and Enums Public"},"121":{"body":"Having to write out the paths to call functions can feel inconvenient and repetitive. In Listing 7-7, whether we chose the absolute or relative path to the add_to_waitlist function, every time we wanted to call add_to_waitlist we had to specify front_of_house and hosting too. Fortunately, there‚Äôs a way to simplify this process: We can create a shortcut to a path with the use keyword once and then use the shorter name everywhere else in the scope. In Listing 7-11, we bring the crate::front_of_house::hosting module into the scope of the eat_at_restaurant function so that we only have to specify hosting::add_to_waitlist to call the add_to_waitlist function in eat_at_restaurant. Filename: src/lib.rs mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} }\\n} use crate::front_of_house::hosting; pub fn eat_at_restaurant() { hosting::add_to_waitlist();\\n} Listing 7-11: Bringing a module into scope with use Adding use and a path in a scope is similar to creating a symbolic link in the filesystem. By adding use crate::front_of_house::hosting in the crate root, hosting is now a valid name in that scope, just as though the hosting module had been defined in the crate root. Paths brought into scope with use also check privacy, like any other paths. Note that use only creates the shortcut for the particular scope in which the use occurs. Listing 7-12 moves the eat_at_restaurant function into a new child module named customer, which is then a different scope than the use statement, so the function body won‚Äôt compile. Filename: src/lib.rs mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} }\\n} use crate::front_of_house::hosting; mod customer { pub fn eat_at_restaurant() { hosting::add_to_waitlist(); }\\n} Listing 7-12: A use statement only applies in the scope it‚Äôs in. The compiler error shows that the shortcut no longer applies within the customer module: $ cargo build Compiling restaurant v0.1.0 (file:///projects/restaurant)\\nerror[E0433]: failed to resolve: use of undeclared crate or module `hosting` --> src/lib.rs:11:9 |\\n11 | hosting::add_to_waitlist(); | ^^^^^^^ use of undeclared crate or module `hosting` |\\nhelp: consider importing this module through its public re-export |\\n10 + use crate::hosting; | warning: unused import: `crate::front_of_house::hosting` --> src/lib.rs:7:5 |\\n7 | use crate::front_of_house::hosting; | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ | = note: `#[warn(unused_imports)]` on by default For more information about this error, try `rustc --explain E0433`.\\nwarning: `restaurant` (lib) generated 1 warning\\nerror: could not compile `restaurant` (lib) due to 1 previous error; 1 warning emitted Notice there‚Äôs also a warning that the use is no longer used in its scope! To fix this problem, move the use within the customer module too, or reference the shortcut in the parent module with super::hosting within the child customer module.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Bringing Paths into Scope with the use Keyword","id":"121","title":"Bringing Paths into Scope with the use Keyword"},"122":{"body":"In Listing 7-11, you might have wondered why we specified use crate::front_of_house::hosting and then called hosting::add_to_waitlist in eat_at_restaurant, rather than specifying the use path all the way out to the add_to_waitlist function to achieve the same result, as in Listing 7-13. Filename: src/lib.rs mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} }\\n} use crate::front_of_house::hosting::add_to_waitlist; pub fn eat_at_restaurant() { add_to_waitlist();\\n} Listing 7-13: Bringing the add_to_waitlist function into scope with use, which is unidiomatic Although both Listing 7-11 and Listing 7-13 accomplish the same task, Listing 7-11 is the idiomatic way to bring a function into scope with use. Bringing the function‚Äôs parent module into scope with use means we have to specify the parent module when calling the function. Specifying the parent module when calling the function makes it clear that the function isn‚Äôt locally defined while still minimizing repetition of the full path. The code in Listing 7-13 is unclear as to where add_to_waitlist is defined. On the other hand, when bringing in structs, enums, and other items with use, it‚Äôs idiomatic to specify the full path. Listing 7-14 shows the idiomatic way to bring the standard library‚Äôs HashMap struct into the scope of a binary crate. Filename: src/main.rs use std::collections::HashMap; fn main() { let mut map = HashMap::new(); map.insert(1, 2);\\n} Listing 7-14: Bringing HashMap into scope in an idiomatic way There‚Äôs no strong reason behind this idiom: It‚Äôs just the convention that has emerged, and folks have gotten used to reading and writing Rust code this way. The exception to this idiom is if we‚Äôre bringing two items with the same name into scope with use statements, because Rust doesn‚Äôt allow that. Listing 7-15 shows how to bring two Result types into scope that have the same name but different parent modules, and how to refer to them. Filename: src/lib.rs use std::fmt;\\nuse std::io; fn function1() -> fmt::Result { // --snip--\\n# Ok(())\\n} fn function2() -> io::Result<()> { // --snip--\\n# Ok(())\\n} Listing 7-15: Bringing two types with the same name into the same scope requires using their parent modules. As you can see, using the parent modules distinguishes the two Result types. If instead we specified use std::fmt::Result and use std::io::Result, we‚Äôd have two Result types in the same scope, and Rust wouldn‚Äôt know which one we meant when we used Result.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Creating Idiomatic use Paths","id":"122","title":"Creating Idiomatic use Paths"},"123":{"body":"There‚Äôs another solution to the problem of bringing two types of the same name into the same scope with use: After the path, we can specify as and a new local name, or alias , for the type. Listing 7-16 shows another way to write the code in Listing 7-15 by renaming one of the two Result types using as. Filename: src/lib.rs use std::fmt::Result;\\nuse std::io::Result as IoResult; fn function1() -> Result { // --snip--\\n# Ok(())\\n} fn function2() -> IoResult<()> { // --snip--\\n# Ok(())\\n} Listing 7-16: Renaming a type when it‚Äôs brought into scope with the as keyword In the second use statement, we chose the new name IoResult for the std::io::Result type, which won‚Äôt conflict with the Result from std::fmt that we‚Äôve also brought into scope. Listing 7-15 and Listing 7-16 are considered idiomatic, so the choice is up to you!","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Providing New Names with the as Keyword","id":"123","title":"Providing New Names with the as Keyword"},"124":{"body":"When we bring a name into scope with the use keyword, the name is private to the scope into which we imported it. To enable code outside that scope to refer to that name as if it had been defined in that scope, we can combine pub and use. This technique is called re-exporting because we‚Äôre bringing an item into scope but also making that item available for others to bring into their scope. Listing 7-17 shows the code in Listing 7-11 with use in the root module changed to pub use. Filename: src/lib.rs mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} }\\n} pub use crate::front_of_house::hosting; pub fn eat_at_restaurant() { hosting::add_to_waitlist();\\n} Listing 7-17: Making a name available for any code to use from a new scope with pub use Before this change, external code would have to call the add_to_waitlist function by using the path restaurant::front_of_house::hosting::add_to_waitlist(), which also would have required the front_of_house module to be marked as pub. Now that this pub use has re-exported the hosting module from the root module, external code can use the path restaurant::hosting::add_to_waitlist() instead. Re-exporting is useful when the internal structure of your code is different from how programmers calling your code would think about the domain. For example, in this restaurant metaphor, the people running the restaurant think about ‚Äúfront of house‚Äù and ‚Äúback of house.‚Äù But customers visiting a restaurant probably won‚Äôt think about the parts of the restaurant in those terms. With pub use, we can write our code with one structure but expose a different structure. Doing so makes our library well organized for programmers working on the library and programmers calling the library. We‚Äôll look at another example of pub use and how it affects your crate‚Äôs documentation in ‚ÄúExporting a Convenient Public API‚Äù in Chapter 14.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Re-exporting Names with pub use","id":"124","title":"Re-exporting Names with pub use"},"125":{"body":"In Chapter 2, we programmed a guessing game project that used an external package called rand to get random numbers. To use rand in our project, we added this line to Cargo.toml : Filename: Cargo.toml rand = \\"0.8.5\\" Adding rand as a dependency in Cargo.toml tells Cargo to download the rand package and any dependencies from crates.io and make rand available to our project. Then, to bring rand definitions into the scope of our package, we added a use line starting with the name of the crate, rand, and listed the items we wanted to bring into scope. Recall that in ‚ÄúGenerating a Random Number‚Äù in Chapter 2, we brought the Rng trait into scope and called the rand::thread_rng function: # use std::io;\\n# use rand::Rng; fn main() {\\n# println!(\\"Guess the number!\\");\\n# let secret_number = rand::thread_rng().gen_range(1..=100);\\n# # println!(\\"The secret number is: {secret_number}\\");\\n# # println!(\\"Please input your guess.\\");\\n# # let mut guess = String::new();\\n# # io::stdin()\\n# .read_line(&mut guess)\\n# .expect(\\"Failed to read line\\");\\n# # println!(\\"You guessed: {guess}\\");\\n} Members of the Rust community have made many packages available at crates.io , and pulling any of them into your package involves these same steps: listing them in your package‚Äôs Cargo.toml file and using use to bring items from their crates into scope. Note that the standard std library is also a crate that‚Äôs external to our package. Because the standard library is shipped with the Rust language, we don‚Äôt need to change Cargo.toml to include std. But we do need to refer to it with use to bring items from there into our package‚Äôs scope. For example, with HashMap we would use this line: use std::collections::HashMap; This is an absolute path starting with std, the name of the standard library crate.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Using External Packages","id":"125","title":"Using External Packages"},"126":{"body":"If we‚Äôre using multiple items defined in the same crate or same module, listing each item on its own line can take up a lot of vertical space in our files. For example, these two use statements we had in the guessing game in Listing 2-4 bring items from std into scope: Filename: src/main.rs # use rand::Rng;\\n// --snip--\\nuse std::cmp::Ordering;\\nuse std::io;\\n// --snip--\\n# # fn main() {\\n# println!(\\"Guess the number!\\");\\n# # let secret_number = rand::thread_rng().gen_range(1..=100);\\n# # println!(\\"The secret number is: {secret_number}\\");\\n# # println!(\\"Please input your guess.\\");\\n# # let mut guess = String::new();\\n# # io::stdin()\\n# .read_line(&mut guess)\\n# .expect(\\"Failed to read line\\");\\n# # println!(\\"You guessed: {guess}\\");\\n# # match guess.cmp(&secret_number) {\\n# Ordering::Less => println!(\\"Too small!\\"),\\n# Ordering::Greater => println!(\\"Too big!\\"),\\n# Ordering::Equal => println!(\\"You win!\\"),\\n# }\\n# } Instead, we can use nested paths to bring the same items into scope in one line. We do this by specifying the common part of the path, followed by two colons, and then curly brackets around a list of the parts of the paths that differ, as shown in Listing 7-18. Filename: src/main.rs # use rand::Rng;\\n// --snip--\\nuse std::{cmp::Ordering, io};\\n// --snip--\\n# # fn main() {\\n# println!(\\"Guess the number!\\");\\n# # let secret_number = rand::thread_rng().gen_range(1..=100);\\n# # println!(\\"The secret number is: {secret_number}\\");\\n# # println!(\\"Please input your guess.\\");\\n# # let mut guess = String::new();\\n# # io::stdin()\\n# .read_line(&mut guess)\\n# .expect(\\"Failed to read line\\");\\n# # let guess: u32 = guess.trim().parse().expect(\\"Please type a number!\\");\\n# # println!(\\"You guessed: {guess}\\");\\n# # match guess.cmp(&secret_number) {\\n# Ordering::Less => println!(\\"Too small!\\"),\\n# Ordering::Greater => println!(\\"Too big!\\"),\\n# Ordering::Equal => println!(\\"You win!\\"),\\n# }\\n# } Listing 7-18: Specifying a nested path to bring multiple items with the same prefix into scope In bigger programs, bringing many items into scope from the same crate or module using nested paths can reduce the number of separate use statements needed by a lot! We can use a nested path at any level in a path, which is useful when combining two use statements that share a subpath. For example, Listing 7-19 shows two use statements: one that brings std::io into scope and one that brings std::io::Write into scope. Filename: src/lib.rs use std::io;\\nuse std::io::Write; Listing 7-19: Two use statements where one is a subpath of the other The common part of these two paths is std::io, and that‚Äôs the complete first path. To merge these two paths into one use statement, we can use self in the nested path, as shown in Listing 7-20. Filename: src/lib.rs use std::io::{self, Write}; Listing 7-20: Combining the paths in Listing 7-19 into one use statement This line brings std::io and std::io::Write into scope.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Using Nested Paths to Clean Up use Lists","id":"126","title":"Using Nested Paths to Clean Up use Lists"},"127":{"body":"If we want to bring all public items defined in a path into scope, we can specify that path followed by the * glob operator: use std::collections::*; This use statement brings all public items defined in std::collections into the current scope. Be careful when using the glob operator! Glob can make it harder to tell what names are in scope and where a name used in your program was defined. Additionally, if the dependency changes its definitions, what you‚Äôve imported changes as well, which may lead to compiler errors when you upgrade the dependency if the dependency adds a definition with the same name as a definition of yours in the same scope, for example. The glob operator is often used when testing to bring everything under test into the tests module; we‚Äôll talk about that in ‚ÄúHow to Write Tests‚Äù in Chapter 11. The glob operator is also sometimes used as part of the prelude pattern: See the standard library documentation for more information on that pattern.","breadcrumbs":"Packages, Crates, and Modules ¬ª Bringing Paths Into Scope with the use Keyword ¬ª Importing Items with the Glob Operator","id":"127","title":"Importing Items with the Glob Operator"},"128":{"body":"So far, all the examples in this chapter defined multiple modules in one file. When modules get large, you might want to move their definitions to a separate file to make the code easier to navigate. For example, let‚Äôs start from the code in Listing 7-17 that had multiple restaurant modules. We‚Äôll extract modules into files instead of having all the modules defined in the crate root file. In this case, the crate root file is src/lib.rs , but this procedure also works with binary crates whose crate root file is src/main.rs . First, we‚Äôll extract the front_of_house module to its own file. Remove the code inside the curly brackets for the front_of_house module, leaving only the mod front_of_house; declaration, so that src/lib.rs contains the code shown in Listing 7-21. Note that this won‚Äôt compile until we create the src/front_of_house.rs file in Listing 7-22. Filename: src/lib.rs mod front_of_house; pub use crate::front_of_house::hosting; pub fn eat_at_restaurant() { hosting::add_to_waitlist();\\n} Listing 7-21: Declaring the front_of_house module whose body will be in src/front_of_house.rs Next, place the code that was in the curly brackets into a new file named src/front_of_house.rs , as shown in Listing 7-22. The compiler knows to look in this file because it came across the module declaration in the crate root with the name front_of_house. Filename: src/front_of_house.rs pub mod hosting { pub fn add_to_waitlist() {}\\n} Listing 7-22: Definitions inside the front_of_house module in src/front_of_house.rs Note that you only need to load a file using a mod declaration once in your module tree. Once the compiler knows the file is part of the project (and knows where in the module tree the code resides because of where you‚Äôve put the mod statement), other files in your project should refer to the loaded file‚Äôs code using a path to where it was declared, as covered in the ‚ÄúPaths for Referring to an Item in the Module Tree‚Äù section. In other words, mod is not an ‚Äúinclude‚Äù operation that you may have seen in other programming languages. Next, we‚Äôll extract the hosting module to its own file. The process is a bit different because hosting is a child module of front_of_house, not of the root module. We‚Äôll place the file for hosting in a new directory that will be named for its ancestors in the module tree, in this case src/front_of_house . To start moving hosting, we change src/front_of_house.rs to contain only the declaration of the hosting module: Filename: src/front_of_house.rs pub mod hosting; Then, we create a src/front_of_house directory and a hosting.rs file to contain the definitions made in the hosting module: Filename: src/front_of_house/hosting.rs pub fn add_to_waitlist() {} If we instead put hosting.rs in the src directory, the compiler would expect the hosting.rs code to be in a hosting module declared in the crate root and not declared as a child of the front_of_house module. The compiler‚Äôs rules for which files to check for which modules‚Äô code mean the directories and files more closely match the module tree.","breadcrumbs":"Packages, Crates, and Modules ¬ª Separating Modules into Different Files ¬ª Separating Modules into Different Files","id":"128","title":"Separating Modules into Different Files"},"129":{"body":"So far we‚Äôve covered the most idiomatic file paths the Rust compiler uses, but Rust also supports an older style of file path. For a module named front_of_house declared in the crate root, the compiler will look for the module‚Äôs code in: src/front_of_house.rs (what we covered) src/front_of_house/mod.rs (older style, still supported path) For a module named hosting that is a submodule of front_of_house, the compiler will look for the module‚Äôs code in: src/front_of_house/hosting.rs (what we covered) src/front_of_house/hosting/mod.rs (older style, still supported path) If you use both styles for the same module, you‚Äôll get a compiler error. Using a mix of both styles for different modules in the same project is allowed but might be confusing for people navigating your project. The main downside to the style that uses files named mod.rs is that your project can end up with many files named mod.rs , which can get confusing when you have them open in your editor at the same time. We‚Äôve moved each module‚Äôs code to a separate file, and the module tree remains the same. The function calls in eat_at_restaurant will work without any modification, even though the definitions live in different files. This technique lets you move modules to new files as they grow in size. Note that the pub use crate::front_of_house::hosting statement in src/lib.rs also hasn‚Äôt changed, nor does use have any impact on what files are compiled as part of the crate. The mod keyword declares modules, and Rust looks in a file with the same name as the module for the code that goes into that module.","breadcrumbs":"Packages, Crates, and Modules ¬ª Separating Modules into Different Files ¬ª Alternate File Paths","id":"129","title":"Alternate File Paths"},"13":{"body":"The first step is to install Rust. We‚Äôll download Rust through rustup, a command line tool for managing Rust versions and associated tools. You‚Äôll need an internet connection for the download. Note: If you prefer not to use rustup for some reason, please see the Other Rust Installation Methods page for more options. The following steps install the latest stable version of the Rust compiler. Rust‚Äôs stability guarantees ensure that all the examples in the book that compile will continue to compile with newer Rust versions. The output might differ slightly between versions because Rust often improves error messages and warnings. In other words, any newer, stable version of Rust you install using these steps should work as expected with the content of this book.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Installation","id":"13","title":"Installation"},"130":{"body":"Rust lets you split a package into multiple crates and a crate into modules so that you can refer to items defined in one module from another module. You can do this by specifying absolute or relative paths. These paths can be brought into scope with a use statement so that you can use a shorter path for multiple uses of the item in that scope. Module code is private by default, but you can make definitions public by adding the pub keyword. In the next chapter, we‚Äôll look at some collection data structures in the standard library that you can use in your neatly organized code.","breadcrumbs":"Packages, Crates, and Modules ¬ª Separating Modules into Different Files ¬ª Summary","id":"130","title":"Summary"},"131":{"body":"Rust‚Äôs standard library includes a number of very useful data structures called collections . Most other data types represent one specific value, but collections can contain multiple values. Unlike the built-in array and tuple types, the data that these collections point to is stored on the heap, which means the amount of data does not need to be known at compile time and can grow or shrink as the program runs. Each kind of collection has different capabilities and costs, and choosing an appropriate one for your current situation is a skill you‚Äôll develop over time. In this chapter, we‚Äôll discuss three collections that are used very often in Rust programs: A vector allows you to store a variable number of values next to each other. A string is a collection of characters. We‚Äôve mentioned the String type previously, but in this chapter, we‚Äôll talk about it in depth. A hash map allows you to associate a value with a specific key. It‚Äôs a particular implementation of the more general data structure called a map . To learn about the other kinds of collections provided by the standard library, see the documentation . We‚Äôll discuss how to create and update vectors, strings, and hash maps, as well as what makes each special.","breadcrumbs":"Common Collections ¬ª Common Collections","id":"131","title":"Common Collections"},"132":{"body":"The first collection type we‚Äôll look at is Vec<T>, also known as a vector. Vectors allow you to store more than one value in a single data structure that puts all the values next to each other in memory. Vectors can only store values of the same type. They are useful when you have a list of items, such as the lines of text in a file or the prices of items in a shopping cart.","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Storing Lists of Values with Vectors","id":"132","title":"Storing Lists of Values with Vectors"},"133":{"body":"To create a new, empty vector, we call the Vec::new function, as shown in Listing 8-1. # fn main() { let v: Vec<i32> = Vec::new();\\n# } Listing 8-1: Creating a new, empty vector to hold values of type i32 Note that we added a type annotation here. Because we aren‚Äôt inserting any values into this vector, Rust doesn‚Äôt know what kind of elements we intend to store. This is an important point. Vectors are implemented using generics; we‚Äôll cover how to use generics with your own types in Chapter 10. For now, know that the Vec<T> type provided by the standard library can hold any type. When we create a vector to hold a specific type, we can specify the type within angle brackets. In Listing 8-1, we‚Äôve told Rust that the Vec<T> in v will hold elements of the i32 type. More often, you‚Äôll create a Vec<T> with initial values, and Rust will infer the type of value you want to store, so you rarely need to do this type annotation. Rust conveniently provides the vec! macro, which will create a new vector that holds the values you give it. Listing 8-2 creates a new Vec<i32> that holds the values 1, 2, and 3. The integer type is i32 because that‚Äôs the default integer type, as we discussed in the ‚ÄúData Types‚Äù section of Chapter 3. # fn main() { let v = vec![1, 2, 3];\\n# } Listing 8-2: Creating a new vector containing values Because we‚Äôve given initial i32 values, Rust can infer that the type of v is Vec<i32>, and the type annotation isn‚Äôt necessary. Next, we‚Äôll look at how to modify a vector.","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Creating a New Vector","id":"133","title":"Creating a New Vector"},"134":{"body":"To create a vector and then add elements to it, we can use the push method, as shown in Listing 8-3. # fn main() { let mut v = Vec::new(); v.push(5); v.push(6); v.push(7); v.push(8);\\n# } Listing 8-3: Using the push method to add values to a vector As with any variable, if we want to be able to change its value, we need to make it mutable using the mut keyword, as discussed in Chapter 3. The numbers we place inside are all of type i32, and Rust infers this from the data, so we don‚Äôt need the Vec<i32> annotation.","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Updating a Vector","id":"134","title":"Updating a Vector"},"135":{"body":"There are two ways to reference a value stored in a vector: via indexing or by using the get method. In the following examples, we‚Äôve annotated the types of the values that are returned from these functions for extra clarity. Listing 8-4 shows both methods of accessing a value in a vector, with indexing syntax and the get method. # fn main() { let v = vec![1, 2, 3, 4, 5]; let third: &i32 = &v[2]; println!(\\"The third element is {third}\\"); let third: Option<&i32> = v.get(2); match third { Some(third) => println!(\\"The third element is {third}\\"), None => println!(\\"There is no third element.\\"), }\\n# } Listing 8-4: Using indexing syntax and using the get method to access an item in a vector Note a few details here. We use the index value of 2 to get the third element because vectors are indexed by number, starting at zero. Using & and [] gives us a reference to the element at the index value. When we use the get method with the index passed as an argument, we get an Option<&T> that we can use with match. Rust provides these two ways to reference an element so that you can choose how the program behaves when you try to use an index value outside the range of existing elements. As an example, let‚Äôs see what happens when we have a vector of five elements and then we try to access an element at index 100 with each technique, as shown in Listing 8-5. # fn main() { let v = vec![1, 2, 3, 4, 5]; let does_not_exist = &v[100]; let does_not_exist = v.get(100);\\n# } Listing 8-5: Attempting to access the element at index 100 in a vector containing five elements When we run this code, the first [] method will cause the program to panic because it references a nonexistent element. This method is best used when you want your program to crash if there‚Äôs an attempt to access an element past the end of the vector. When the get method is passed an index that is outside the vector, it returns None without panicking. You would use this method if accessing an element beyond the range of the vector may happen occasionally under normal circumstances. Your code will then have logic to handle having either Some(&element) or None, as discussed in Chapter 6. For example, the index could be coming from a person entering a number. If they accidentally enter a number that‚Äôs too large and the program gets a None value, you could tell the user how many items are in the current vector and give them another chance to enter a valid value. That would be more user-friendly than crashing the program due to a typo! When the program has a valid reference, the borrow checker enforces the ownership and borrowing rules (covered in Chapter 4) to ensure that this reference and any other references to the contents of the vector remain valid. Recall the rule that states you can‚Äôt have mutable and immutable references in the same scope. That rule applies in Listing 8-6, where we hold an immutable reference to the first element in a vector and try to add an element to the end. This program won‚Äôt work if we also try to refer to that element later in the function. # fn main() { let mut v = vec![1, 2, 3, 4, 5]; let first = &v[0]; v.push(6); println!(\\"The first element is: {first}\\");\\n# } Listing 8-6: Attempting to add an element to a vector while holding a reference to an item Compiling this code will result in this error: $ cargo run Compiling collections v0.1.0 (file:///projects/collections)\\nerror[E0502]: cannot borrow `v` as mutable because it is also borrowed as immutable --> src/main.rs:6:5 |\\n4 | let first = &v[0]; | - immutable borrow occurs here\\n5 |\\n6 | v.push(6); | ^^^^^^^^^ mutable borrow occurs here\\n7 |\\n8 | println!(\\"The first element is: {first}\\"); | ------- immutable borrow later used here For more information about this error, try `rustc --explain E0502`.\\nerror: could not compile `collections` (bin \\"collections\\") due to 1 previous error The code in Listing 8-6 might look like it should work: Why should a reference to the first element care about changes at the end of the vector? This error is due to the way vectors work: Because vectors put the values next to each other in memory, adding a new element onto the end of the vector might require allocating new memory and copying the old elements to the new space, if there isn‚Äôt enough room to put all the elements next to each other where the vector is currently stored. In that case, the reference to the first element would be pointing to deallocated memory. The borrowing rules prevent programs from ending up in that situation. Note: For more on the implementation details of the Vec<T> type, see ‚ÄúThe Rustonomicon‚Äù .","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Reading Elements of Vectors","id":"135","title":"Reading Elements of Vectors"},"136":{"body":"To access each element in a vector in turn, we would iterate through all of the elements rather than use indices to access one at a time. Listing 8-7 shows how to use a for loop to get immutable references to each element in a vector of i32 values and print them. # fn main() { let v = vec![100, 32, 57]; for i in &v { println!(\\"{i}\\"); }\\n# } Listing 8-7: Printing each element in a vector by iterating over the elements using a for loop We can also iterate over mutable references to each element in a mutable vector in order to make changes to all the elements. The for loop in Listing 8-8 will add 50 to each element. # fn main() { let mut v = vec![100, 32, 57]; for i in &mut v { *i += 50; }\\n# } Listing 8-8: Iterating over mutable references to elements in a vector To change the value that the mutable reference refers to, we have to use the * dereference operator to get to the value in i before we can use the += operator. We‚Äôll talk more about the dereference operator in the ‚ÄúFollowing the Reference to the Value‚Äù section of Chapter 15. Iterating over a vector, whether immutably or mutably, is safe because of the borrow checker‚Äôs rules. If we attempted to insert or remove items in the for loop bodies in Listing 8-7 and Listing 8-8, we would get a compiler error similar to the one we got with the code in Listing 8-6. The reference to the vector that the for loop holds prevents simultaneous modification of the whole vector.","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Iterating Over the Values in a Vector","id":"136","title":"Iterating Over the Values in a Vector"},"137":{"body":"Vectors can only store values that are of the same type. This can be inconvenient; there are definitely use cases for needing to store a list of items of different types. Fortunately, the variants of an enum are defined under the same enum type, so when we need one type to represent elements of different types, we can define and use an enum! For example, say we want to get values from a row in a spreadsheet in which some of the columns in the row contain integers, some floating-point numbers, and some strings. We can define an enum whose variants will hold the different value types, and all the enum variants will be considered the same type: that of the enum. Then, we can create a vector to hold that enum and so, ultimately, hold different types. We‚Äôve demonstrated this in Listing 8-9. # fn main() { enum SpreadsheetCell { Int(i32), Float(f64), Text(String), } let row = vec![ SpreadsheetCell::Int(3), SpreadsheetCell::Text(String::from(\\"blue\\")), SpreadsheetCell::Float(10.12), ];\\n# } Listing 8-9: Defining an enum to store values of different types in one vector Rust needs to know what types will be in the vector at compile time so that it knows exactly how much memory on the heap will be needed to store each element. We must also be explicit about what types are allowed in this vector. If Rust allowed a vector to hold any type, there would be a chance that one or more of the types would cause errors with the operations performed on the elements of the vector. Using an enum plus a match expression means that Rust will ensure at compile time that every possible case is handled, as discussed in Chapter 6. If you don‚Äôt know the exhaustive set of types a program will get at runtime to store in a vector, the enum technique won‚Äôt work. Instead, you can use a trait object, which we‚Äôll cover in Chapter 18. Now that we‚Äôve discussed some of the most common ways to use vectors, be sure to review the API documentation for all of the many useful methods defined on Vec<T> by the standard library. For example, in addition to push, a pop method removes and returns the last element.","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Using an Enum to Store Multiple Types","id":"137","title":"Using an Enum to Store Multiple Types"},"138":{"body":"Like any other struct, a vector is freed when it goes out of scope, as annotated in Listing 8-10. # fn main() { { let v = vec![1, 2, 3, 4]; // do stuff with v } // <- v goes out of scope and is freed here\\n# } Listing 8-10: Showing where the vector and its elements are dropped When the vector gets dropped, all of its contents are also dropped, meaning the integers it holds will be cleaned up. The borrow checker ensures that any references to contents of a vector are only used while the vector itself is valid. Let‚Äôs move on to the next collection type: String!","breadcrumbs":"Common Collections ¬ª Storing Lists of Values with Vectors ¬ª Dropping a Vector Drops Its Elements","id":"138","title":"Dropping a Vector Drops Its Elements"},"139":{"body":"We talked about strings in Chapter 4, but we‚Äôll look at them in more depth now. New Rustaceans commonly get stuck on strings for a combination of three reasons: Rust‚Äôs propensity for exposing possible errors, strings being a more complicated data structure than many programmers give them credit for, and UTF-8. These factors combine in a way that can seem difficult when you‚Äôre coming from other programming languages. We discuss strings in the context of collections because strings are implemented as a collection of bytes, plus some methods to provide useful functionality when those bytes are interpreted as text. In this section, we‚Äôll talk about the operations on String that every collection type has, such as creating, updating, and reading. We‚Äôll also discuss the ways in which String is different from the other collections, namely, how indexing into a String is complicated by the differences between how people and computers interpret String data.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Storing UTF-8 Encoded Text with Strings","id":"139","title":"Storing UTF-8 Encoded Text with Strings"},"14":{"body":"In this chapter and throughout the book, we‚Äôll show some commands used in the terminal. Lines that you should enter in a terminal all start with $. You don‚Äôt need to type the $ character; it‚Äôs the command line prompt shown to indicate the start of each command. Lines that don‚Äôt start with $ typically show the output of the previous command. Additionally, PowerShell-specific examples will use > rather than $.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Command Line Notation","id":"14","title":"Command Line Notation"},"140":{"body":"We‚Äôll first define what we mean by the term string . Rust has only one string type in the core language, which is the string slice str that is usually seen in its borrowed form, &str. In Chapter 4, we talked about string slices, which are references to some UTF-8 encoded string data stored elsewhere. String literals, for example, are stored in the program‚Äôs binary and are therefore string slices. The String type, which is provided by Rust‚Äôs standard library rather than coded into the core language, is a growable, mutable, owned, UTF-8 encoded string type. When Rustaceans refer to ‚Äústrings‚Äù in Rust, they might be referring to either the String or the string slice &str types, not just one of those types. Although this section is largely about String, both types are used heavily in Rust‚Äôs standard library, and both String and string slices are UTF-8 encoded.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Defining Strings","id":"140","title":"Defining Strings"},"141":{"body":"Many of the same operations available with Vec<T> are available with String as well because String is actually implemented as a wrapper around a vector of bytes with some extra guarantees, restrictions, and capabilities. An example of a function that works the same way with Vec<T> and String is the new function to create an instance, shown in Listing 8-11. # fn main() { let mut s = String::new();\\n# } Listing 8-11: Creating a new, empty String This line creates a new, empty string called s, into which we can then load data. Often, we‚Äôll have some initial data with which we want to start the string. For that, we use the to_string method, which is available on any type that implements the Display trait, as string literals do. Listing 8-12 shows two examples. # fn main() { let data = \\"initial contents\\"; let s = data.to_string(); // The method also works on a literal directly: let s = \\"initial contents\\".to_string();\\n# } Listing 8-12: Using the to_string method to create a String from a string literal This code creates a string containing initial contents. We can also use the function String::from to create a String from a string literal. The code in Listing 8-13 is equivalent to the code in Listing 8-12 that uses to_string. # fn main() { let s = String::from(\\"initial contents\\");\\n# } Listing 8-13: Using the String::from function to create a String from a string literal Because strings are used for so many things, we can use many different generic APIs for strings, providing us with a lot of options. Some of them can seem redundant, but they all have their place! In this case, String::from and to_string do the same thing, so which one you choose is a matter of style and readability. Remember that strings are UTF-8 encoded, so we can include any properly encoded data in them, as shown in Listing 8-14. # fn main() { let hello = String::from(\\"ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ\\"); let hello = String::from(\\"Dobr√Ω den\\"); let hello = String::from(\\"Hello\\"); let hello = String::from(\\"◊©◊ú◊ï◊ù\\"); let hello = String::from(\\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\\"); let hello = String::from(\\"„Åì„Çì„Å´„Å°„ÅØ\\"); let hello = String::from(\\"ÏïàÎÖïÌïòÏÑ∏Ïöî\\"); let hello = String::from(\\"‰Ω†Â•Ω\\"); let hello = String::from(\\"Ol√°\\"); let hello = String::from(\\"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\"); let hello = String::from(\\"Hola\\");\\n# } Listing 8-14: Storing greetings in different languages in strings All of these are valid String values.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Creating a New String","id":"141","title":"Creating a New String"},"142":{"body":"A String can grow in size and its contents can change, just like the contents of a Vec<T>, if you push more data into it. In addition, you can conveniently use the + operator or the format! macro to concatenate String values. Appending with push_str or push We can grow a String by using the push_str method to append a string slice, as shown in Listing 8-15. # fn main() { let mut s = String::from(\\"foo\\"); s.push_str(\\"bar\\");\\n# } Listing 8-15: Appending a string slice to a String using the push_str method After these two lines, s will contain foobar. The push_str method takes a string slice because we don‚Äôt necessarily want to take ownership of the parameter. For example, in the code in Listing 8-16, we want to be able to use s2 after appending its contents to s1. # fn main() { let mut s1 = String::from(\\"foo\\"); let s2 = \\"bar\\"; s1.push_str(s2); println!(\\"s2 is {s2}\\");\\n# } Listing 8-16: Using a string slice after appending its contents to a String If the push_str method took ownership of s2, we wouldn‚Äôt be able to print its value on the last line. However, this code works as we‚Äôd expect! The push method takes a single character as a parameter and adds it to the String. Listing 8-17 adds the letter l to a String using the push method. # fn main() { let mut s = String::from(\\"lo\\"); s.push(\'l\');\\n# } Listing 8-17: Adding one character to a String value using push As a result, s will contain lol. Concatenating with + or format! Often, you‚Äôll want to combine two existing strings. One way to do so is to use the + operator, as shown in Listing 8-18. # fn main() { let s1 = String::from(\\"Hello, \\"); let s2 = String::from(\\"world!\\"); let s3 = s1 + &s2; // note s1 has been moved here and can no longer be used\\n# } Listing 8-18: Using the + operator to combine two String values into a new String value The string s3 will contain Hello, world!. The reason s1 is no longer valid after the addition, and the reason we used a reference to s2, has to do with the signature of the method that‚Äôs called when we use the + operator. The + operator uses the add method, whose signature looks something like this: fn add(self, s: &str) -> String { In the standard library, you‚Äôll see add defined using generics and associated types. Here, we‚Äôve substituted in concrete types, which is what happens when we call this method with String values. We‚Äôll discuss generics in Chapter 10. This signature gives us the clues we need in order to understand the tricky bits of the + operator. First, s2 has an &, meaning that we‚Äôre adding a reference of the second string to the first string. This is because of the s parameter in the add function: We can only add a string slice to a String; we can‚Äôt add two String values together. But wait‚Äîthe type of &s2 is &String, not &str, as specified in the second parameter to add. So, why does Listing 8-18 compile? The reason we‚Äôre able to use &s2 in the call to add is that the compiler can coerce the &String argument into a &str. When we call the add method, Rust uses a deref coercion, which here turns &s2 into &s2[..]. We‚Äôll discuss deref coercion in more depth in Chapter 15. Because add does not take ownership of the s parameter, s2 will still be a valid String after this operation. Second, we can see in the signature that add takes ownership of self because self does not have an &. This means s1 in Listing 8-18 will be moved into the add call and will no longer be valid after that. So, although let s3 = s1 + &s2; looks like it will copy both strings and create a new one, this statement actually takes ownership of s1, appends a copy of the contents of s2, and then returns ownership of the result. In other words, it looks like it‚Äôs making a lot of copies, but it isn‚Äôt; the implementation is more efficient than copying. If we need to concatenate multiple strings, the behavior of the + operator gets unwieldy: # fn main() { let s1 = String::from(\\"tic\\"); let s2 = String::from(\\"tac\\"); let s3 = String::from(\\"toe\\"); let s = s1 + \\"-\\" + &s2 + \\"-\\" + &s3;\\n# } At this point, s will be tic-tac-toe. With all of the + and \\" characters, it‚Äôs difficult to see what‚Äôs going on. For combining strings in more complicated ways, we can instead use the format! macro: # fn main() { let s1 = String::from(\\"tic\\"); let s2 = String::from(\\"tac\\"); let s3 = String::from(\\"toe\\"); let s = format!(\\"{s1}-{s2}-{s3}\\");\\n# } This code also sets s to tic-tac-toe. The format! macro works like println!, but instead of printing the output to the screen, it returns a String with the contents. The version of the code using format! is much easier to read, and the code generated by the format! macro uses references so that this call doesn‚Äôt take ownership of any of its parameters.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Updating a String","id":"142","title":"Updating a String"},"143":{"body":"In many other programming languages, accessing individual characters in a string by referencing them by index is a valid and common operation. However, if you try to access parts of a String using indexing syntax in Rust, you‚Äôll get an error. Consider the invalid code in Listing 8-19. # fn main() { let s1 = String::from(\\"hi\\"); let h = s1[0];\\n# } Listing 8-19: Attempting to use indexing syntax with a String This code will result in the following error: $ cargo run Compiling collections v0.1.0 (file:///projects/collections)\\nerror[E0277]: the type `str` cannot be indexed by `{integer}` --> src/main.rs:3:16 |\\n3 | let h = s1[0]; | ^ string indices are ranges of `usize` | = note: you can use `.chars().nth()` or `.bytes().nth()` for more information, see chapter 8 in The Book: <https://doc.rust-lang.org/book/ch08-02-strings.html#indexing-into-strings> = help: the trait `SliceIndex<str>` is not implemented for `{integer}` but trait `SliceIndex<[_]>` is implemented for `usize` = help: for that trait implementation, expected `[_]`, found `str` = note: required for `String` to implement `Index<{integer}>` For more information about this error, try `rustc --explain E0277`.\\nerror: could not compile `collections` (bin \\"collections\\") due to 1 previous error The error tells the story: Rust strings don‚Äôt support indexing. But why not? To answer that question, we need to discuss how Rust stores strings in memory. Internal Representation A String is a wrapper over a Vec<u8>. Let‚Äôs look at some of our properly encoded UTF-8 example strings from Listing 8-14. First, this one: # fn main() {\\n# let hello = String::from(\\"ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ\\");\\n# let hello = String::from(\\"Dobr√Ω den\\");\\n# let hello = String::from(\\"Hello\\");\\n# let hello = String::from(\\"◊©◊ú◊ï◊ù\\");\\n# let hello = String::from(\\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\\");\\n# let hello = String::from(\\"„Åì„Çì„Å´„Å°„ÅØ\\");\\n# let hello = String::from(\\"ÏïàÎÖïÌïòÏÑ∏Ïöî\\");\\n# let hello = String::from(\\"‰Ω†Â•Ω\\");\\n# let hello = String::from(\\"Ol√°\\");\\n# let hello = String::from(\\"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\"); let hello = String::from(\\"Hola\\");\\n# } In this case, len will be 4, which means the vector storing the string \\"Hola\\" is 4 bytes long. Each of these letters takes 1 byte when encoded in UTF-8. The following line, however, may surprise you (note that this string begins with the capital Cyrillic letter Ze , not the number 3): # fn main() {\\n# let hello = String::from(\\"ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ\\");\\n# let hello = String::from(\\"Dobr√Ω den\\");\\n# let hello = String::from(\\"Hello\\");\\n# let hello = String::from(\\"◊©◊ú◊ï◊ù\\");\\n# let hello = String::from(\\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á\\");\\n# let hello = String::from(\\"„Åì„Çì„Å´„Å°„ÅØ\\");\\n# let hello = String::from(\\"ÏïàÎÖïÌïòÏÑ∏Ïöî\\");\\n# let hello = String::from(\\"‰Ω†Â•Ω\\");\\n# let hello = String::from(\\"Ol√°\\"); let hello = String::from(\\"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\");\\n# let hello = String::from(\\"Hola\\");\\n# } If you were asked how long the string is, you might say 12. In fact, Rust‚Äôs answer is 24: That‚Äôs the number of bytes it takes to encode ‚Äú–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ‚Äù in UTF-8, because each Unicode scalar value in that string takes 2 bytes of storage. Therefore, an index into the string‚Äôs bytes will not always correlate to a valid Unicode scalar value. To demonstrate, consider this invalid Rust code: let hello = \\"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\";\\nlet answer = &hello[0]; You already know that answer will not be –ó, the first letter. When encoded in UTF-8, the first byte of –ó is 208 and the second is 151, so it would seem that answer should in fact be 208, but 208 is not a valid character on its own. Returning 208 is likely not what a user would want if they asked for the first letter of this string; however, that‚Äôs the only data that Rust has at byte index 0. Users generally don‚Äôt want the byte value returned, even if the string contains only Latin letters: If &\\"hi\\"[0] were valid code that returned the byte value, it would return 104, not h. The answer, then, is that to avoid returning an unexpected value and causing bugs that might not be discovered immediately, Rust doesn‚Äôt compile this code at all and prevents misunderstandings early in the development process. Bytes, Scalar Values, and Grapheme Clusters Another point about UTF-8 is that there are actually three relevant ways to look at strings from Rust‚Äôs perspective: as bytes, scalar values, and grapheme clusters (the closest thing to what we would call letters ). If we look at the Hindi word ‚Äú‡§®‡§Æ‡§∏‡•ç‡§§‡•á‚Äù written in the Devanagari script, it is stored as a vector of u8 values that looks like this: [224, 164, 168, 224, 164, 174, 224, 164, 184, 224, 165, 141, 224, 164, 164,\\n224, 165, 135] That‚Äôs 18 bytes and is how computers ultimately store this data. If we look at them as Unicode scalar values, which are what Rust‚Äôs char type is, those bytes look like this: [\'‡§®\', \'‡§Æ\', \'‡§∏\', \'‡•ç\', \'‡§§\', \'‡•á\'] There are six char values here, but the fourth and sixth are not letters: They‚Äôre diacritics that don‚Äôt make sense on their own. Finally, if we look at them as grapheme clusters, we‚Äôd get what a person would call the four letters that make up the Hindi word: [\\"‡§®\\", \\"‡§Æ\\", \\"‡§∏‡•ç\\", \\"‡§§‡•á\\"] Rust provides different ways of interpreting the raw string data that computers store so that each program can choose the interpretation it needs, no matter what human language the data is in. A final reason Rust doesn‚Äôt allow us to index into a String to get a character is that indexing operations are expected to always take constant time (O(1)). But it isn‚Äôt possible to guarantee that performance with a String, because Rust would have to walk through the contents from the beginning to the index to determine how many valid characters there were.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Indexing into Strings","id":"143","title":"Indexing into Strings"},"144":{"body":"Indexing into a string is often a bad idea because it‚Äôs not clear what the return type of the string-indexing operation should be: a byte value, a character, a grapheme cluster, or a string slice. If you really need to use indices to create string slices, therefore, Rust asks you to be more specific. Rather than indexing using [] with a single number, you can use [] with a range to create a string slice containing particular bytes: let hello = \\"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ\\"; let s = &hello[0..4]; Here, s will be a &str that contains the first 4 bytes of the string. Earlier, we mentioned that each of these characters was 2 bytes, which means s will be –ó–¥. If we were to try to slice only part of a character‚Äôs bytes with something like &hello[0..1], Rust would panic at runtime in the same way as if an invalid index were accessed in a vector: $ cargo run Compiling collections v0.1.0 (file:///projects/collections) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.43s Running `target/debug/collections` thread \'main\' panicked at src/main.rs:4:19:\\nbyte index 1 is not a char boundary; it is inside \'–ó\' (bytes 0..2) of `–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ`\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace You should use caution when creating string slices with ranges, because doing so can crash your program.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Slicing Strings","id":"144","title":"Slicing Strings"},"145":{"body":"The best way to operate on pieces of strings is to be explicit about whether you want characters or bytes. For individual Unicode scalar values, use the chars method. Calling chars on ‚Äú–ó–¥‚Äù separates out and returns two values of type char, and you can iterate over the result to access each element: for c in \\"–ó–¥\\".chars() { println!(\\"{c}\\");\\n} This code will print the following: –ó\\n–¥ Alternatively, the bytes method returns each raw byte, which might be appropriate for your domain: for b in \\"–ó–¥\\".bytes() { println!(\\"{b}\\");\\n} This code will print the 4 bytes that make up this string: 208\\n151\\n208\\n180 But be sure to remember that valid Unicode scalar values may be made up of more than 1 byte. Getting grapheme clusters from strings, as with the Devanagari script, is complex, so this functionality is not provided by the standard library. Crates are available on crates.io if this is the functionality you need.","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Iterating Over Strings","id":"145","title":"Iterating Over Strings"},"146":{"body":"To summarize, strings are complicated. Different programming languages make different choices about how to present this complexity to the programmer. Rust has chosen to make the correct handling of String data the default behavior for all Rust programs, which means programmers have to put more thought into handling UTF-8 data up front. This trade-off exposes more of the complexity of strings than is apparent in other programming languages, but it prevents you from having to handle errors involving non-ASCII characters later in your development life cycle. The good news is that the standard library offers a lot of functionality built off the String and &str types to help handle these complex situations correctly. Be sure to check out the documentation for useful methods like contains for searching in a string and replace for substituting parts of a string with another string. Let‚Äôs switch to something a bit less complex: hash maps!","breadcrumbs":"Common Collections ¬ª Storing UTF-8 Encoded Text with Strings ¬ª Handling the Complexities of Strings","id":"146","title":"Handling the Complexities of Strings"},"147":{"body":"The last of our common collections is the hash map. The type HashMap<K, V> stores a mapping of keys of type K to values of type V using a hashing function , which determines how it places these keys and values into memory. Many programming languages support this kind of data structure, but they often use a different name, such as hash , map , object , hash table , dictionary , or associative array , just to name a few. Hash maps are useful when you want to look up data not by using an index, as you can with vectors, but by using a key that can be of any type. For example, in a game, you could keep track of each team‚Äôs score in a hash map in which each key is a team‚Äôs name and the values are each team‚Äôs score. Given a team name, you can retrieve its score. We‚Äôll go over the basic API of hash maps in this section, but many more goodies are hiding in the functions defined on HashMap<K, V> by the standard library. As always, check the standard library documentation for more information.","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Storing Keys with Associated Values in Hash Maps","id":"147","title":"Storing Keys with Associated Values in Hash Maps"},"148":{"body":"One way to create an empty hash map is to use new and to add elements with insert. In Listing 8-20, we‚Äôre keeping track of the scores of two teams whose names are Blue and Yellow . The Blue team starts with 10 points, and the Yellow team starts with 50. # fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\\"Blue\\"), 10); scores.insert(String::from(\\"Yellow\\"), 50);\\n# } Listing 8-20: Creating a new hash map and inserting some keys and values Note that we need to first use the HashMap from the collections portion of the standard library. Of our three common collections, this one is the least often used, so it‚Äôs not included in the features brought into scope automatically in the prelude. Hash maps also have less support from the standard library; there‚Äôs no built-in macro to construct them, for example. Just like vectors, hash maps store their data on the heap. This HashMap has keys of type String and values of type i32. Like vectors, hash maps are homogeneous: All of the keys must have the same type, and all of the values must have the same type.","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Creating a New Hash Map","id":"148","title":"Creating a New Hash Map"},"149":{"body":"We can get a value out of the hash map by providing its key to the get method, as shown in Listing 8-21. # fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\\"Blue\\"), 10); scores.insert(String::from(\\"Yellow\\"), 50); let team_name = String::from(\\"Blue\\"); let score = scores.get(&team_name).copied().unwrap_or(0);\\n# } Listing 8-21: Accessing the score for the Blue team stored in the hash map Here, score will have the value that‚Äôs associated with the Blue team, and the result will be 10. The get method returns an Option<&V>; if there‚Äôs no value for that key in the hash map, get will return None. This program handles the Option by calling copied to get an Option<i32> rather than an Option<&i32>, then unwrap_or to set score to zero if scores doesn‚Äôt have an entry for the key. We can iterate over each key-value pair in a hash map in a similar manner as we do with vectors, using a for loop: # fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\\"Blue\\"), 10); scores.insert(String::from(\\"Yellow\\"), 50); for (key, value) in &scores { println!(\\"{key}: {value}\\"); }\\n# } This code will print each pair in an arbitrary order: Yellow: 50\\nBlue: 10","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Accessing Values in a Hash Map","id":"149","title":"Accessing Values in a Hash Map"},"15":{"body":"If you‚Äôre using Linux or macOS, open a terminal and enter the following command: $ curl --proto \'=https\' --tlsv1.2 https://sh.rustup.rs -sSf | sh The command downloads a script and starts the installation of the rustup tool, which installs the latest stable version of Rust. You might be prompted for your password. If the install is successful, the following line will appear: Rust is installed now. Great! You will also need a linker , which is a program that Rust uses to join its compiled outputs into one file. It is likely you already have one. If you get linker errors, you should install a C compiler, which will typically include a linker. A C compiler is also useful because some common Rust packages depend on C code and will need a C compiler. On macOS, you can get a C compiler by running: $ xcode-select --install Linux users should generally install GCC or Clang, according to their distribution‚Äôs documentation. For example, if you use Ubuntu, you can install the build-essential package.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Installing rustup on Linux or macOS","id":"15","title":"Installing rustup on Linux or macOS"},"150":{"body":"For types that implement the Copy trait, like i32, the values are copied into the hash map. For owned values like String, the values will be moved and the hash map will be the owner of those values, as demonstrated in Listing 8-22. # fn main() { use std::collections::HashMap; let field_name = String::from(\\"Favorite color\\"); let field_value = String::from(\\"Blue\\"); let mut map = HashMap::new(); map.insert(field_name, field_value); // field_name and field_value are invalid at this point, try using them and // see what compiler error you get!\\n# } Listing 8-22: Showing that keys and values are owned by the hash map once they‚Äôre inserted We aren‚Äôt able to use the variables field_name and field_value after they‚Äôve been moved into the hash map with the call to insert. If we insert references to values into the hash map, the values won‚Äôt be moved into the hash map. The values that the references point to must be valid for at least as long as the hash map is valid. We‚Äôll talk more about these issues in ‚ÄúValidating References with Lifetimes‚Äù in Chapter 10.","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Managing Ownership in Hash Maps","id":"150","title":"Managing Ownership in Hash Maps"},"151":{"body":"Although the number of key and value pairs is growable, each unique key can only have one value associated with it at a time (but not vice versa: For example, both the Blue team and the Yellow team could have the value 10 stored in the scores hash map). When you want to change the data in a hash map, you have to decide how to handle the case when a key already has a value assigned. You could replace the old value with the new value, completely disregarding the old value. You could keep the old value and ignore the new value, only adding the new value if the key doesn‚Äôt already have a value. Or you could combine the old value and the new value. Let‚Äôs look at how to do each of these! Overwriting a Value If we insert a key and a value into a hash map and then insert that same key with a different value, the value associated with that key will be replaced. Even though the code in Listing 8-23 calls insert twice, the hash map will only contain one key-value pair because we‚Äôre inserting the value for the Blue team‚Äôs key both times. # fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\\"Blue\\"), 10); scores.insert(String::from(\\"Blue\\"), 25); println!(\\"{scores:?}\\");\\n# } Listing 8-23: Replacing a value stored with a particular key This code will print {\\"Blue\\": 25}. The original value of 10 has been overwritten. Adding a Key and Value Only If a Key Isn‚Äôt Present It‚Äôs common to check whether a particular key already exists in the hash map with a value and then to take the following actions: If the key does exist in the hash map, the existing value should remain the way it is; if the key doesn‚Äôt exist, insert it and a value for it. Hash maps have a special API for this called entry that takes the key you want to check as a parameter. The return value of the entry method is an enum called Entry that represents a value that might or might not exist. Let‚Äôs say we want to check whether the key for the Yellow team has a value associated with it. If it doesn‚Äôt, we want to insert the value 50, and the same for the Blue team. Using the entry API, the code looks like Listing 8-24. # fn main() { use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\\"Blue\\"), 10); scores.entry(String::from(\\"Yellow\\")).or_insert(50); scores.entry(String::from(\\"Blue\\")).or_insert(50); println!(\\"{scores:?}\\");\\n# } Listing 8-24: Using the entry method to only insert if the key does not already have a value The or_insert method on Entry is defined to return a mutable reference to the value for the corresponding Entry key if that key exists, and if not, it inserts the parameter as the new value for this key and returns a mutable reference to the new value. This technique is much cleaner than writing the logic ourselves and, in addition, plays more nicely with the borrow checker. Running the code in Listing 8-24 will print {\\"Yellow\\": 50, \\"Blue\\": 10}. The first call to entry will insert the key for the Yellow team with the value 50 because the Yellow team doesn‚Äôt have a value already. The second call to entry will not change the hash map, because the Blue team already has the value 10. Updating a Value Based on the Old Value Another common use case for hash maps is to look up a key‚Äôs value and then update it based on the old value. For instance, Listing 8-25 shows code that counts how many times each word appears in some text. We use a hash map with the words as keys and increment the value to keep track of how many times we‚Äôve seen that word. If it‚Äôs the first time we‚Äôve seen a word, we‚Äôll first insert the value 0. # fn main() { use std::collections::HashMap; let text = \\"hello world wonderful world\\"; let mut map = HashMap::new(); for word in text.split_whitespace() { let count = map.entry(word).or_insert(0); *count += 1; } println!(\\"{map:?}\\");\\n# } Listing 8-25: Counting occurrences of words using a hash map that stores words and counts This code will print {\\"world\\": 2, \\"hello\\": 1, \\"wonderful\\": 1}. You might see the same key-value pairs printed in a different order: Recall from ‚ÄúAccessing Values in a Hash Map‚Äù that iterating over a hash map happens in an arbitrary order. The split_whitespace method returns an iterator over subslices, separated by whitespace, of the value in text. The or_insert method returns a mutable reference (&mut V) to the value for the specified key. Here, we store that mutable reference in the count variable, so in order to assign to that value, we must first dereference count using the asterisk (*). The mutable reference goes out of scope at the end of the for loop, so all of these changes are safe and allowed by the borrowing rules.","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Updating a Hash Map","id":"151","title":"Updating a Hash Map"},"152":{"body":"By default, HashMap uses a hashing function called SipHash that can provide resistance to denial-of-service (DoS) attacks involving hash tables [1] . This is not the fastest hashing algorithm available, but the trade-off for better security that comes with the drop in performance is worth it. If you profile your code and find that the default hash function is too slow for your purposes, you can switch to another function by specifying a different hasher. A hasher is a type that implements the BuildHasher trait. We‚Äôll talk about traits and how to implement them in Chapter 10 . You don‚Äôt necessarily have to implement your own hasher from scratch; crates.io has libraries shared by other Rust users that provide hashers implementing many common hashing algorithms. https://en.wikipedia.org/wiki/SipHash","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Hashing Functions","id":"152","title":"Hashing Functions"},"153":{"body":"Vectors, strings, and hash maps will provide a large amount of functionality necessary in programs when you need to store, access, and modify data. Here are some exercises you should now be equipped to solve: Given a list of integers, use a vector and return the median (when sorted, the value in the middle position) and mode (the value that occurs most often; a hash map will be helpful here) of the list. Convert strings to Pig Latin. The first consonant of each word is moved to the end of the word and ay is added, so first becomes irst-fay . Words that start with a vowel have hay added to the end instead ( apple becomes apple-hay ). Keep in mind the details about UTF-8 encoding! Using a hash map and vectors, create a text interface to allow a user to add employee names to a department in a company; for example, ‚ÄúAdd Sally to Engineering‚Äù or ‚ÄúAdd Amir to Sales.‚Äù Then, let the user retrieve a list of all people in a department or all people in the company by department, sorted alphabetically. The standard library API documentation describes methods that vectors, strings, and hash maps have that will be helpful for these exercises! We‚Äôre getting into more complex programs in which operations can fail, so it‚Äôs a perfect time to discuss error handling. We‚Äôll do that next!","breadcrumbs":"Common Collections ¬ª Storing Keys with Associated Values in Hash Maps ¬ª Summary","id":"153","title":"Summary"},"154":{"body":"Errors are a fact of life in software, so Rust has a number of features for handling situations in which something goes wrong. In many cases, Rust requires you to acknowledge the possibility of an error and take some action before your code will compile. This requirement makes your program more robust by ensuring that you‚Äôll discover errors and handle them appropriately before deploying your code to production! Rust groups errors into two major categories: recoverable and unrecoverable errors. For a recoverable error , such as a file not found error, we most likely just want to report the problem to the user and retry the operation. Unrecoverable errors are always symptoms of bugs, such as trying to access a location beyond the end of an array, and so we want to immediately stop the program. Most languages don‚Äôt distinguish between these two kinds of errors and handle both in the same way, using mechanisms such as exceptions. Rust doesn‚Äôt have exceptions. Instead, it has the type Result<T, E> for recoverable errors and the panic! macro that stops execution when the program encounters an unrecoverable error. This chapter covers calling panic! first and then talks about returning Result<T, E> values. Additionally, we‚Äôll explore considerations when deciding whether to try to recover from an error or to stop execution.","breadcrumbs":"Error Handling ¬ª Error Handling","id":"154","title":"Error Handling"},"155":{"body":"Sometimes bad things happen in your code, and there‚Äôs nothing you can do about it. In these cases, Rust has the panic! macro. There are two ways to cause a panic in practice: by taking an action that causes our code to panic (such as accessing an array past the end) or by explicitly calling the panic! macro. In both cases, we cause a panic in our program. By default, these panics will print a failure message, unwind, clean up the stack, and quit. Via an environment variable, you can also have Rust display the call stack when a panic occurs to make it easier to track down the source of the panic.","breadcrumbs":"Error Handling ¬ª Unrecoverable Errors with panic! ¬ª Unrecoverable Errors with panic!","id":"155","title":"Unrecoverable Errors with panic!"},"156":{"body":"By default, when a panic occurs, the program starts unwinding , which means Rust walks back up the stack and cleans up the data from each function it encounters. However, walking back and cleaning up is a lot of work. Rust therefore allows you to choose the alternative of immediately aborting , which ends the program without cleaning up. Memory that the program was using will then need to be cleaned up by the operating system. If in your project you need to make the resultant binary as small as possible, you can switch from unwinding to aborting upon a panic by adding panic = \'abort\' to the appropriate [profile] sections in your Cargo.toml file. For example, if you want to abort on panic in release mode, add this: [profile.release]\\npanic = \'abort\' Let‚Äôs try calling panic! in a simple program: Filename: src/main.rs fn main() { panic!(\\"crash and burn\\");\\n} When you run the program, you‚Äôll see something like this: $ cargo run Compiling panic v0.1.0 (file:///projects/panic) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.25s Running `target/debug/panic` thread \'main\' panicked at src/main.rs:2:5:\\ncrash and burn\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace The call to panic! causes the error message contained in the last two lines. The first line shows our panic message and the place in our source code where the panic occurred: src/main.rs:2:5 indicates that it‚Äôs the second line, fifth character of our src/main.rs file. In this case, the line indicated is part of our code, and if we go to that line, we see the panic! macro call. In other cases, the panic! call might be in code that our code calls, and the filename and line number reported by the error message will be someone else‚Äôs code where the panic! macro is called, not the line of our code that eventually led to the panic! call. We can use the backtrace of the functions the panic! call came from to figure out the part of our code that is causing the problem. To understand how to use a panic! backtrace, let‚Äôs look at another example and see what it‚Äôs like when a panic! call comes from a library because of a bug in our code instead of from our code calling the macro directly. Listing 9-1 has some code that attempts to access an index in a vector beyond the range of valid indexes. Filename: src/main.rs fn main() { let v = vec![1, 2, 3]; v[99];\\n} Listing 9-1: Attempting to access an element beyond the end of a vector, which will cause a call to panic! Here, we‚Äôre attempting to access the 100th element of our vector (which is at index 99 because indexing starts at zero), but the vector has only three elements. In this situation, Rust will panic. Using [] is supposed to return an element, but if you pass an invalid index, there‚Äôs no element that Rust could return here that would be correct. In C, attempting to read beyond the end of a data structure is undefined behavior. You might get whatever is at the location in memory that would correspond to that element in the data structure, even though the memory doesn‚Äôt belong to that structure. This is called a buffer overread and can lead to security vulnerabilities if an attacker is able to manipulate the index in such a way as to read data they shouldn‚Äôt be allowed to that is stored after the data structure. To protect your program from this sort of vulnerability, if you try to read an element at an index that doesn‚Äôt exist, Rust will stop execution and refuse to continue. Let‚Äôs try it and see: $ cargo run Compiling panic v0.1.0 (file:///projects/panic) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.27s Running `target/debug/panic` thread \'main\' panicked at src/main.rs:4:6:\\nindex out of bounds: the len is 3 but the index is 99\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace This error points at line 4 of our main.rs where we attempt to access index 99 of the vector in v. The note: line tells us that we can set the RUST_BACKTRACE environment variable to get a backtrace of exactly what happened to cause the error. A backtrace is a list of all the functions that have been called to get to this point. Backtraces in Rust work as they do in other languages: The key to reading the backtrace is to start from the top and read until you see files you wrote. That‚Äôs the spot where the problem originated. The lines above that spot are code that your code has called; the lines below are code that called your code. These before-and-after lines might include core Rust code, standard library code, or crates that you‚Äôre using. Let‚Äôs try to get a backtrace by setting the RUST_BACKTRACE environment variable to any value except 0. Listing 9-2 shows output similar to what you‚Äôll see. $ RUST_BACKTRACE=1 cargo run\\nthread \'main\' panicked at src/main.rs:4:6:\\nindex out of bounds: the len is 3 but the index is 99\\nstack backtrace: 0: rust_begin_unwind at /rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/std/src/panicking.rs:692:5 1: core::panicking::panic_fmt at /rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:75:14 2: core::panicking::panic_bounds_check at /rustc/4d91de4e48198da2e33413efdcd9cd2cc0c46688/library/core/src/panicking.rs:273:5 3: <usize as core::slice::index::SliceIndex<[T]>>::index at file:///home/.rustup/toolchains/1.85/lib/rustlib/src/rust/library/core/src/slice/index.rs:274:10 4: core::slice::index::<impl core::ops::index::Index<I> for [T]>::index at file:///home/.rustup/toolchains/1.85/lib/rustlib/src/rust/library/core/src/slice/index.rs:16:9 5: <alloc::vec::Vec<T,A> as core::ops::index::Index<I>>::index at file:///home/.rustup/toolchains/1.85/lib/rustlib/src/rust/library/alloc/src/vec/mod.rs:3361:9 6: panic::main at ./src/main.rs:4:6 7: core::ops::function::FnOnce::call_once at file:///home/.rustup/toolchains/1.85/lib/rustlib/src/rust/library/core/src/ops/function.rs:250:5\\nnote: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace. Listing 9-2: The backtrace generated by a call to panic! displayed when the environment variable RUST_BACKTRACE is set That‚Äôs a lot of output! The exact output you see might be different depending on your operating system and Rust version. In order to get backtraces with this information, debug symbols must be enabled. Debug symbols are enabled by default when using cargo build or cargo run without the --release flag, as we have here. In the output in Listing 9-2, line 6 of the backtrace points to the line in our project that‚Äôs causing the problem: line 4 of src/main.rs . If we don‚Äôt want our program to panic, we should start our investigation at the location pointed to by the first line mentioning a file we wrote. In Listing 9-1, where we deliberately wrote code that would panic, the way to fix the panic is to not request an element beyond the range of the vector indexes. When your code panics in the future, you‚Äôll need to figure out what action the code is taking with what values to cause the panic and what the code should do instead. We‚Äôll come back to panic! and when we should and should not use panic! to handle error conditions in the ‚ÄúTo panic! or Not to panic!‚Äù section later in this chapter. Next, we‚Äôll look at how to recover from an error using Result.","breadcrumbs":"Error Handling ¬ª Unrecoverable Errors with panic! ¬ª Unwinding the Stack or Aborting in Response to a Panic","id":"156","title":"Unwinding the Stack or Aborting in Response to a Panic"},"157":{"body":"Most errors aren‚Äôt serious enough to require the program to stop entirely. Sometimes when a function fails, it‚Äôs for a reason that you can easily interpret and respond to. For example, if you try to open a file and that operation fails because the file doesn‚Äôt exist, you might want to create the file instead of terminating the process. Recall from ‚ÄúHandling Potential Failure with Result‚Äù in Chapter 2 that the Result enum is defined as having two variants, Ok and Err, as follows: enum Result<T, E> { Ok(T), Err(E),\\n} The T and E are generic type parameters: We‚Äôll discuss generics in more detail in Chapter 10. What you need to know right now is that T represents the type of the value that will be returned in a success case within the Ok variant, and E represents the type of the error that will be returned in a failure case within the Err variant. Because Result has these generic type parameters, we can use the Result type and the functions defined on it in many different situations where the success value and error value we want to return may differ. Let‚Äôs call a function that returns a Result value because the function could fail. In Listing 9-3, we try to open a file. Filename: src/main.rs use std::fs::File; fn main() { let greeting_file_result = File::open(\\"hello.txt\\");\\n} Listing 9-3: Opening a file The return type of File::open is a Result<T, E>. The generic parameter T has been filled in by the implementation of File::open with the type of the success value, std::fs::File, which is a file handle. The type of E used in the error value is std::io::Error. This return type means the call to File::open might succeed and return a file handle that we can read from or write to. The function call also might fail: For example, the file might not exist, or we might not have permission to access the file. The File::open function needs to have a way to tell us whether it succeeded or failed and at the same time give us either the file handle or error information. This information is exactly what the Result enum conveys. In the case where File::open succeeds, the value in the variable greeting_file_result will be an instance of Ok that contains a file handle. In the case where it fails, the value in greeting_file_result will be an instance of Err that contains more information about the kind of error that occurred. We need to add to the code in Listing 9-3 to take different actions depending on the value File::open returns. Listing 9-4 shows one way to handle the Result using a basic tool, the match expression that we discussed in Chapter 6. Filename: src/main.rs use std::fs::File; fn main() { let greeting_file_result = File::open(\\"hello.txt\\"); let greeting_file = match greeting_file_result { Ok(file) => file, Err(error) => panic!(\\"Problem opening the file: {error:?}\\"), };\\n} Listing 9-4: Using a match expression to handle the Result variants that might be returned Note that, like the Option enum, the Result enum and its variants have been brought into scope by the prelude, so we don‚Äôt need to specify Result:: before the Ok and Err variants in the match arms. When the result is Ok, this code will return the inner file value out of the Ok variant, and we then assign that file handle value to the variable greeting_file. After the match, we can use the file handle for reading or writing. The other arm of the match handles the case where we get an Err value from File::open. In this example, we‚Äôve chosen to call the panic! macro. If there‚Äôs no file named hello.txt in our current directory and we run this code, we‚Äôll see the following output from the panic! macro: $ cargo run Compiling error-handling v0.1.0 (file:///projects/error-handling) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.73s Running `target/debug/error-handling` thread \'main\' panicked at src/main.rs:8:23:\\nProblem opening the file: Os { code: 2, kind: NotFound, message: \\"No such file or directory\\" }\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace As usual, this output tells us exactly what has gone wrong.","breadcrumbs":"Error Handling ¬ª Recoverable Errors with Result ¬ª Recoverable Errors with Result","id":"157","title":"Recoverable Errors with Result"},"158":{"body":"The code in Listing 9-4 will panic! no matter why File::open failed. However, we want to take different actions for different failure reasons. If File::open failed because the file doesn‚Äôt exist, we want to create the file and return the handle to the new file. If File::open failed for any other reason‚Äîfor example, because we didn‚Äôt have permission to open the file‚Äîwe still want the code to panic! in the same way it did in Listing 9-4. For this, we add an inner match expression, shown in Listing 9-5. Filename: src/main.rs use std::fs::File;\\nuse std::io::ErrorKind; fn main() { let greeting_file_result = File::open(\\"hello.txt\\"); let greeting_file = match greeting_file_result { Ok(file) => file, Err(error) => match error.kind() { ErrorKind::NotFound => match File::create(\\"hello.txt\\") { Ok(fc) => fc, Err(e) => panic!(\\"Problem creating the file: {e:?}\\"), }, _ => { panic!(\\"Problem opening the file: {error:?}\\"); } }, };\\n} Listing 9-5: Handling different kinds of errors in different ways The type of the value that File::open returns inside the Err variant is io::Error, which is a struct provided by the standard library. This struct has a method, kind, that we can call to get an io::ErrorKind value. The enum io::ErrorKind is provided by the standard library and has variants representing the different kinds of errors that might result from an io operation. The variant we want to use is ErrorKind::NotFound, which indicates the file we‚Äôre trying to open doesn‚Äôt exist yet. So, we match on greeting_file_result, but we also have an inner match on error.kind(). The condition we want to check in the inner match is whether the value returned by error.kind() is the NotFound variant of the ErrorKind enum. If it is, we try to create the file with File::create. However, because File::create could also fail, we need a second arm in the inner match expression. When the file can‚Äôt be created, a different error message is printed. The second arm of the outer match stays the same, so the program panics on any error besides the missing file error. Alternatives to Using match with Result<T, E> That‚Äôs a lot of match! The match expression is very useful but also very much a primitive. In Chapter 13, you‚Äôll learn about closures, which are used with many of the methods defined on Result<T, E>. These methods can be more concise than using match when handling Result<T, E> values in your code. For example, here‚Äôs another way to write the same logic as shown in Listing 9-5, this time using closures and the unwrap_or_else method: use std::fs::File;\\nuse std::io::ErrorKind; fn main() { let greeting_file = File::open(\\"hello.txt\\").unwrap_or_else(|error| { if error.kind() == ErrorKind::NotFound { File::create(\\"hello.txt\\").unwrap_or_else(|error| { panic!(\\"Problem creating the file: {error:?}\\"); }) } else { panic!(\\"Problem opening the file: {error:?}\\"); } });\\n} Although this code has the same behavior as Listing 9-5, it doesn‚Äôt contain any match expressions and is cleaner to read. Come back to this example after you‚Äôve read Chapter 13 and look up the unwrap_or_else method in the standard library documentation. Many more of these methods can clean up huge, nested match expressions when you‚Äôre dealing with errors. Shortcuts for Panic on Error Using match works well enough, but it can be a bit verbose and doesn‚Äôt always communicate intent well. The Result<T, E> type has many helper methods defined on it to do various, more specific tasks. The unwrap method is a shortcut method implemented just like the match expression we wrote in Listing 9-4. If the Result value is the Ok variant, unwrap will return the value inside the Ok. If the Result is the Err variant, unwrap will call the panic! macro for us. Here is an example of unwrap in action: Filename: src/main.rs use std::fs::File; fn main() { let greeting_file = File::open(\\"hello.txt\\").unwrap();\\n} If we run this code without a hello.txt file, we‚Äôll see an error message from the panic! call that the unwrap method makes: thread \'main\' panicked at src/main.rs:4:49:\\ncalled `Result::unwrap()` on an `Err` value: Os { code: 2, kind: NotFound, message: \\"No such file or directory\\" } Similarly, the expect method lets us also choose the panic! error message. Using expect instead of unwrap and providing good error messages can convey your intent and make tracking down the source of a panic easier. The syntax of expect looks like this: Filename: src/main.rs use std::fs::File; fn main() { let greeting_file = File::open(\\"hello.txt\\") .expect(\\"hello.txt should be included in this project\\");\\n} We use expect in the same way as unwrap: to return the file handle or call the panic! macro. The error message used by expect in its call to panic! will be the parameter that we pass to expect, rather than the default panic! message that unwrap uses. Here‚Äôs what it looks like: thread \'main\' panicked at src/main.rs:5:10:\\nhello.txt should be included in this project: Os { code: 2, kind: NotFound, message: \\"No such file or directory\\" } In production-quality code, most Rustaceans choose expect rather than unwrap and give more context about why the operation is expected to always succeed. That way, if your assumptions are ever proven wrong, you have more information to use in debugging.","breadcrumbs":"Error Handling ¬ª Recoverable Errors with Result ¬ª Matching on Different Errors","id":"158","title":"Matching on Different Errors"},"159":{"body":"When a function‚Äôs implementation calls something that might fail, instead of handling the error within the function itself, you can return the error to the calling code so that it can decide what to do. This is known as propagating the error and gives more control to the calling code, where there might be more information or logic that dictates how the error should be handled than what you have available in the context of your code. For example, Listing 9-6 shows a function that reads a username from a file. If the file doesn‚Äôt exist or can‚Äôt be read, this function will return those errors to the code that called the function. Filename: src/main.rs use std::fs::File;\\nuse std::io::{self, Read}; fn read_username_from_file() -> Result<String, io::Error> { let username_file_result = File::open(\\"hello.txt\\"); let mut username_file = match username_file_result { Ok(file) => file, Err(e) => return Err(e), }; let mut username = String::new(); match username_file.read_to_string(&mut username) { Ok(_) => Ok(username), Err(e) => Err(e), }\\n} Listing 9-6: A function that returns errors to the calling code using match This function can be written in a much shorter way, but we‚Äôre going to start by doing a lot of it manually in order to explore error handling; at the end, we‚Äôll show the shorter way. Let‚Äôs look at the return type of the function first: Result<String, io::Error>. This means the function is returning a value of the type Result<T, E>, where the generic parameter T has been filled in with the concrete type String and the generic type E has been filled in with the concrete type io::Error. If this function succeeds without any problems, the code that calls this function will receive an Ok value that holds a String‚Äîthe username that this function read from the file. If this function encounters any problems, the calling code will receive an Err value that holds an instance of io::Error that contains more information about what the problems were. We chose io::Error as the return type of this function because that happens to be the type of the error value returned from both of the operations we‚Äôre calling in this function‚Äôs body that might fail: the File::open function and the read_to_string method. The body of the function starts by calling the File::open function. Then, we handle the Result value with a match similar to the match in Listing 9-4. If File::open succeeds, the file handle in the pattern variable file becomes the value in the mutable variable username_file and the function continues. In the Err case, instead of calling panic!, we use the return keyword to return early out of the function entirely and pass the error value from File::open, now in the pattern variable e, back to the calling code as this function‚Äôs error value. So, if we have a file handle in username_file, the function then creates a new String in variable username and calls the read_to_string method on the file handle in username_file to read the contents of the file into username. The read_to_string method also returns a Result because it might fail, even though File::open succeeded. So, we need another match to handle that Result: If read_to_string succeeds, then our function has succeeded, and we return the username from the file that‚Äôs now in username wrapped in an Ok. If read_to_string fails, we return the error value in the same way that we returned the error value in the match that handled the return value of File::open. However, we don‚Äôt need to explicitly say return, because this is the last expression in the function. The code that calls this code will then handle getting either an Ok value that contains a username or an Err value that contains an io::Error. It‚Äôs up to the calling code to decide what to do with those values. If the calling code gets an Err value, it could call panic! and crash the program, use a default username, or look up the username from somewhere other than a file, for example. We don‚Äôt have enough information on what the calling code is actually trying to do, so we propagate all the success or error information upward for it to handle appropriately. This pattern of propagating errors is so common in Rust that Rust provides the question mark operator ? to make this easier. The ? Operator Shortcut Listing 9-7 shows an implementation of read_username_from_file that has the same functionality as in Listing 9-6, but this implementation uses the ? operator. Filename: src/main.rs use std::fs::File;\\nuse std::io::{self, Read}; fn read_username_from_file() -> Result<String, io::Error> { let mut username_file = File::open(\\"hello.txt\\")?; let mut username = String::new(); username_file.read_to_string(&mut username)?; Ok(username)\\n} Listing 9-7: A function that returns errors to the calling code using the ? operator The ? placed after a Result value is defined to work in almost the same way as the match expressions that we defined to handle the Result values in Listing 9-6. If the value of the Result is an Ok, the value inside the Ok will get returned from this expression, and the program will continue. If the value is an Err, the Err will be returned from the whole function as if we had used the return keyword so that the error value gets propagated to the calling code. There is a difference between what the match expression from Listing 9-6 does and what the ? operator does: Error values that have the ? operator called on them go through the from function, defined in the From trait in the standard library, which is used to convert values from one type into another. When the ? operator calls the from function, the error type received is converted into the error type defined in the return type of the current function. This is useful when a function returns one error type to represent all the ways a function might fail, even if parts might fail for many different reasons. For example, we could change the read_username_from_file function in Listing 9-7 to return a custom error type named OurError that we define. If we also define impl From<io::Error> for OurError to construct an instance of OurError from an io::Error, then the ? operator calls in the body of read_username_from_file will call from and convert the error types without needing to add any more code to the function. In the context of Listing 9-7, the ? at the end of the File::open call will return the value inside an Ok to the variable username_file. If an error occurs, the ? operator will return early out of the whole function and give any Err value to the calling code. The same thing applies to the ? at the end of the read_to_string call. The ? operator eliminates a lot of boilerplate and makes this function‚Äôs implementation simpler. We could even shorten this code further by chaining method calls immediately after the ?, as shown in Listing 9-8. Filename: src/main.rs use std::fs::File;\\nuse std::io::{self, Read}; fn read_username_from_file() -> Result<String, io::Error> { let mut username = String::new(); File::open(\\"hello.txt\\")?.read_to_string(&mut username)?; Ok(username)\\n} Listing 9-8: Chaining method calls after the ? operator We‚Äôve moved the creation of the new String in username to the beginning of the function; that part hasn‚Äôt changed. Instead of creating a variable username_file, we‚Äôve chained the call to read_to_string directly onto the result of File::open(\\"hello.txt\\")?. We still have a ? at the end of the read_to_string call, and we still return an Ok value containing username when both File::open and read_to_string succeed rather than returning errors. The functionality is again the same as in Listing 9-6 and Listing 9-7; this is just a different, more ergonomic way to write it. Listing 9-9 shows a way to make this even shorter using fs::read_to_string. Filename: src/main.rs use std::fs;\\nuse std::io; fn read_username_from_file() -> Result<String, io::Error> { fs::read_to_string(\\"hello.txt\\")\\n} Listing 9-9: Using fs::read_to_string instead of opening and then reading the file Reading a file into a string is a fairly common operation, so the standard library provides the convenient fs::read_to_string function that opens the file, creates a new String, reads the contents of the file, puts the contents into that String, and returns it. Of course, using fs::read_to_string doesn‚Äôt give us the opportunity to explain all the error handling, so we did it the longer way first. Where to Use the ? Operator The ? operator can only be used in functions whose return type is compatible with the value the ? is used on. This is because the ? operator is defined to perform an early return of a value out of the function, in the same manner as the match expression we defined in Listing 9-6. In Listing 9-6, the match was using a Result value, and the early return arm returned an Err(e) value. The return type of the function has to be a Result so that it‚Äôs compatible with this return. In Listing 9-10, let‚Äôs look at the error we‚Äôll get if we use the ? operator in a main function with a return type that is incompatible with the type of the value we use ? on. Filename: src/main.rs use std::fs::File; fn main() { let greeting_file = File::open(\\"hello.txt\\")?;\\n} Listing 9-10: Attempting to use the ? in the main function that returns () won‚Äôt compile. This code opens a file, which might fail. The ? operator follows the Result value returned by File::open, but this main function has the return type of (), not Result. When we compile this code, we get the following error message: $ cargo run Compiling error-handling v0.1.0 (file:///projects/error-handling)\\nerror[E0277]: the `?` operator can only be used in a function that returns `Result` or `Option` (or another type that implements `FromResidual`) --> src/main.rs:4:48 |\\n3 | fn main() { | --------- this function should return `Result` or `Option` to accept `?`\\n4 | let greeting_file = File::open(\\"hello.txt\\")?; | ^ cannot use the `?` operator in a function that returns `()` | = help: the trait `FromResidual<Result<Infallible, std::io::Error>>` is not implemented for `()`\\nhelp: consider adding return type |\\n3 ~ fn main() -> Result<(), Box<dyn std::error::Error>> {\\n4 | let greeting_file = File::open(\\"hello.txt\\")?;\\n5 + Ok(()) | For more information about this error, try `rustc --explain E0277`.\\nerror: could not compile `error-handling` (bin \\"error-handling\\") due to 1 previous error This error points out that we‚Äôre only allowed to use the ? operator in a function that returns Result, Option, or another type that implements FromResidual. To fix the error, you have two choices. One choice is to change the return type of your function to be compatible with the value you‚Äôre using the ? operator on as long as you have no restrictions preventing that. The other choice is to use a match or one of the Result<T, E> methods to handle the Result<T, E> in whatever way is appropriate. The error message also mentioned that ? can be used with Option<T> values as well. As with using ? on Result, you can only use ? on Option in a function that returns an Option. The behavior of the ? operator when called on an Option<T> is similar to its behavior when called on a Result<T, E>: If the value is None, the None will be returned early from the function at that point. If the value is Some, the value inside the Some is the resultant value of the expression, and the function continues. Listing 9-11 has an example of a function that finds the last character of the first line in the given text. fn last_char_of_first_line(text: &str) -> Option<char> { text.lines().next()?.chars().last()\\n}\\n# # fn main() {\\n# assert_eq!(\\n# last_char_of_first_line(\\"Hello, world\\\\nHow are you today?\\"),\\n# Some(\'d\')\\n# );\\n# # assert_eq!(last_char_of_first_line(\\"\\"), None);\\n# assert_eq!(last_char_of_first_line(\\"\\\\nhi\\"), None);\\n# } Listing 9-11: Using the ? operator on an Option&lt;T&gt; value This function returns Option<char> because it‚Äôs possible that there is a character there, but it‚Äôs also possible that there isn‚Äôt. This code takes the text string slice argument and calls the lines method on it, which returns an iterator over the lines in the string. Because this function wants to examine the first line, it calls next on the iterator to get the first value from the iterator. If text is the empty string, this call to next will return None, in which case we use ? to stop and return None from last_char_of_first_line. If text is not the empty string, next will return a Some value containing a string slice of the first line in text. The ? extracts the string slice, and we can call chars on that string slice to get an iterator of its characters. We‚Äôre interested in the last character in this first line, so we call last to return the last item in the iterator. This is an Option because it‚Äôs possible that the first line is the empty string; for example, if text starts with a blank line but has characters on other lines, as in \\"\\\\nhi\\". However, if there is a last character on the first line, it will be returned in the Some variant. The ? operator in the middle gives us a concise way to express this logic, allowing us to implement the function in one line. If we couldn‚Äôt use the ? operator on Option, we‚Äôd have to implement this logic using more method calls or a match expression. Note that you can use the ? operator on a Result in a function that returns Result, and you can use the ? operator on an Option in a function that returns Option, but you can‚Äôt mix and match. The ? operator won‚Äôt automatically convert a Result to an Option or vice versa; in those cases, you can use methods like the ok method on Result or the ok_or method on Option to do the conversion explicitly. So far, all the main functions we‚Äôve used return (). The main function is special because it‚Äôs the entry point and exit point of an executable program, and there are restrictions on what its return type can be for the program to behave as expected. Luckily, main can also return a Result<(), E>. Listing 9-12 has the code from Listing 9-10, but we‚Äôve changed the return type of main to be Result<(), Box<dyn Error>> and added a return value Ok(()) to the end. This code will now compile. Filename: src/main.rs use std::error::Error;\\nuse std::fs::File; fn main() -> Result<(), Box<dyn Error>> { let greeting_file = File::open(\\"hello.txt\\")?; Ok(())\\n} Listing 9-12: Changing main to return Result&lt;(), E&gt; allows the use of the ? operator on Result values. The Box<dyn Error> type is a trait object, which we‚Äôll talk about in ‚ÄúUsing Trait Objects to Abstract over Shared Behavior‚Äù in Chapter 18. For now, you can read Box<dyn Error> to mean ‚Äúany kind of error.‚Äù Using ? on a Result value in a main function with the error type Box<dyn Error> is allowed because it allows any Err value to be returned early. Even though the body of this main function will only ever return errors of type std::io::Error, by specifying Box<dyn Error>, this signature will continue to be correct even if more code that returns other errors is added to the body of main. When a main function returns a Result<(), E>, the executable will exit with a value of 0 if main returns Ok(()) and will exit with a nonzero value if main returns an Err value. Executables written in C return integers when they exit: Programs that exit successfully return the integer 0, and programs that error return some integer other than 0. Rust also returns integers from executables to be compatible with this convention. The main function may return any types that implement the std::process::Termination trait , which contains a function report that returns an ExitCode. Consult the standard library documentation for more information on implementing the Termination trait for your own types. Now that we‚Äôve discussed the details of calling panic! or returning Result, let‚Äôs return to the topic of how to decide which is appropriate to use in which cases.","breadcrumbs":"Error Handling ¬ª Recoverable Errors with Result ¬ª Propagating Errors","id":"159","title":"Propagating Errors"},"16":{"body":"On Windows, go to https://www.rust-lang.org/tools/install and follow the instructions for installing Rust. At some point in the installation, you‚Äôll be prompted to install Visual Studio. This provides a linker and the native libraries needed to compile programs. If you need more help with this step, see https://rust-lang.github.io/rustup/installation/windows-msvc.html . The rest of this book uses commands that work in both cmd.exe and PowerShell. If there are specific differences, we‚Äôll explain which to use.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Installing rustup on Windows","id":"16","title":"Installing rustup on Windows"},"160":{"body":"So, how do you decide when you should call panic! and when you should return Result? When code panics, there‚Äôs no way to recover. You could call panic! for any error situation, whether there‚Äôs a possible way to recover or not, but then you‚Äôre making the decision that a situation is unrecoverable on behalf of the calling code. When you choose to return a Result value, you give the calling code options. The calling code could choose to attempt to recover in a way that‚Äôs appropriate for its situation, or it could decide that an Err value in this case is unrecoverable, so it can call panic! and turn your recoverable error into an unrecoverable one. Therefore, returning Result is a good default choice when you‚Äôre defining a function that might fail. In situations such as examples, prototype code, and tests, it‚Äôs more appropriate to write code that panics instead of returning a Result. Let‚Äôs explore why, then discuss situations in which the compiler can‚Äôt tell that failure is impossible, but you as a human can. The chapter will conclude with some general guidelines on how to decide whether to panic in library code.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª To panic! or Not to panic!","id":"160","title":"To panic! or Not to panic!"},"161":{"body":"When you‚Äôre writing an example to illustrate some concept, also including robust error-handling code can make the example less clear. In examples, it‚Äôs understood that a call to a method like unwrap that could panic is meant as a placeholder for the way you‚Äôd want your application to handle errors, which can differ based on what the rest of your code is doing. Similarly, the unwrap and expect methods are very handy when you‚Äôre prototyping and you‚Äôre not yet ready to decide how to handle errors. They leave clear markers in your code for when you‚Äôre ready to make your program more robust. If a method call fails in a test, you‚Äôd want the whole test to fail, even if that method isn‚Äôt the functionality under test. Because panic! is how a test is marked as a failure, calling unwrap or expect is exactly what should happen.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª Examples, Prototype Code, and Tests","id":"161","title":"Examples, Prototype Code, and Tests"},"162":{"body":"It would also be appropriate to call expect when you have some other logic that ensures that the Result will have an Ok value, but the logic isn‚Äôt something the compiler understands. You‚Äôll still have a Result value that you need to handle: Whatever operation you‚Äôre calling still has the possibility of failing in general, even though it‚Äôs logically impossible in your particular situation. If you can ensure by manually inspecting the code that you‚Äôll never have an Err variant, it‚Äôs perfectly acceptable to call expect and document the reason you think you‚Äôll never have an Err variant in the argument text. Here‚Äôs an example: # fn main() { use std::net::IpAddr; let home: IpAddr = \\"127.0.0.1\\" .parse() .expect(\\"Hardcoded IP address should be valid\\");\\n# } We‚Äôre creating an IpAddr instance by parsing a hardcoded string. We can see that 127.0.0.1 is a valid IP address, so it‚Äôs acceptable to use expect here. However, having a hardcoded, valid string doesn‚Äôt change the return type of the parse method: We still get a Result value, and the compiler will still make us handle the Result as if the Err variant is a possibility because the compiler isn‚Äôt smart enough to see that this string is always a valid IP address. If the IP address string came from a user rather than being hardcoded into the program and therefore did have a possibility of failure, we‚Äôd definitely want to handle the Result in a more robust way instead. Mentioning the assumption that this IP address is hardcoded will prompt us to change expect to better error-handling code if, in the future, we need to get the IP address from some other source instead.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª When You Have More Information Than the Compiler","id":"162","title":"When You Have More Information Than the Compiler"},"163":{"body":"It‚Äôs advisable to have your code panic when it‚Äôs possible that your code could end up in a bad state. In this context, a bad state is when some assumption, guarantee, contract, or invariant has been broken, such as when invalid values, contradictory values, or missing values are passed to your code‚Äîplus one or more of the following: The bad state is something that is unexpected, as opposed to something that will likely happen occasionally, like a user entering data in the wrong format. Your code after this point needs to rely on not being in this bad state, rather than checking for the problem at every step. There‚Äôs not a good way to encode this information in the types you use. We‚Äôll work through an example of what we mean in ‚ÄúEncoding States and Behavior as Types‚Äù in Chapter 18. If someone calls your code and passes in values that don‚Äôt make sense, it‚Äôs best to return an error if you can so that the user of the library can decide what they want to do in that case. However, in cases where continuing could be insecure or harmful, the best choice might be to call panic! and alert the person using your library to the bug in their code so that they can fix it during development. Similarly, panic! is often appropriate if you‚Äôre calling external code that is out of your control and returns an invalid state that you have no way of fixing. However, when failure is expected, it‚Äôs more appropriate to return a Result than to make a panic! call. Examples include a parser being given malformed data or an HTTP request returning a status that indicates you have hit a rate limit. In these cases, returning a Result indicates that failure is an expected possibility that the calling code must decide how to handle. When your code performs an operation that could put a user at risk if it‚Äôs called using invalid values, your code should verify the values are valid first and panic if the values aren‚Äôt valid. This is mostly for safety reasons: Attempting to operate on invalid data can expose your code to vulnerabilities. This is the main reason the standard library will call panic! if you attempt an out-of-bounds memory access: Trying to access memory that doesn‚Äôt belong to the current data structure is a common security problem. Functions often have contracts : Their behavior is only guaranteed if the inputs meet particular requirements. Panicking when the contract is violated makes sense because a contract violation always indicates a caller-side bug, and it‚Äôs not a kind of error you want the calling code to have to explicitly handle. In fact, there‚Äôs no reasonable way for calling code to recover; the calling programmers need to fix the code. Contracts for a function, especially when a violation will cause a panic, should be explained in the API documentation for the function. However, having lots of error checks in all of your functions would be verbose and annoying. Fortunately, you can use Rust‚Äôs type system (and thus the type checking done by the compiler) to do many of the checks for you. If your function has a particular type as a parameter, you can proceed with your code‚Äôs logic knowing that the compiler has already ensured that you have a valid value. For example, if you have a type rather than an Option, your program expects to have something rather than nothing . Your code then doesn‚Äôt have to handle two cases for the Some and None variants: It will only have one case for definitely having a value. Code trying to pass nothing to your function won‚Äôt even compile, so your function doesn‚Äôt have to check for that case at runtime. Another example is using an unsigned integer type such as u32, which ensures that the parameter is never negative.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª Guidelines for Error Handling","id":"163","title":"Guidelines for Error Handling"},"164":{"body":"Let‚Äôs take the idea of using Rust‚Äôs type system to ensure that we have a valid value one step further and look at creating a custom type for validation. Recall the guessing game in Chapter 2 in which our code asked the user to guess a number between 1 and 100. We never validated that the user‚Äôs guess was between those numbers before checking it against our secret number; we only validated that the guess was positive. In this case, the consequences were not very dire: Our output of ‚ÄúToo high‚Äù or ‚ÄúToo low‚Äù would still be correct. But it would be a useful enhancement to guide the user toward valid guesses and have different behavior when the user guesses a number that‚Äôs out of range versus when the user types, for example, letters instead. One way to do this would be to parse the guess as an i32 instead of only a u32 to allow potentially negative numbers, and then add a check for the number being in range, like so: Filename: src/main.rs # use rand::Rng;\\n# use std::cmp::Ordering;\\n# use std::io;\\n# # fn main() {\\n# println!(\\"Guess the number!\\");\\n# # let secret_number = rand::thread_rng().gen_range(1..=100);\\n# loop { // --snip-- # println!(\\"Please input your guess.\\");\\n# # let mut guess = String::new();\\n# # io::stdin()\\n# .read_line(&mut guess)\\n# .expect(\\"Failed to read line\\");\\n# let guess: i32 = match guess.trim().parse() { Ok(num) => num, Err(_) => continue, }; if guess < 1 || guess > 100 { println!(\\"The secret number will be between 1 and 100.\\"); continue; } match guess.cmp(&secret_number) { // --snip--\\n# Ordering::Less => println!(\\"Too small!\\"),\\n# Ordering::Greater => println!(\\"Too big!\\"),\\n# Ordering::Equal => {\\n# println!(\\"You win!\\");\\n# break;\\n# }\\n# } }\\n# } The if expression checks whether our value is out of range, tells the user about the problem, and calls continue to start the next iteration of the loop and ask for another guess. After the if expression, we can proceed with the comparisons between guess and the secret number knowing that guess is between 1 and 100. However, this is not an ideal solution: If it were absolutely critical that the program only operated on values between 1 and 100, and it had many functions with this requirement, having a check like this in every function would be tedious (and might impact performance). Instead, we can make a new type in a dedicated module and put the validations in a function to create an instance of the type rather than repeating the validations everywhere. That way, it‚Äôs safe for functions to use the new type in their signatures and confidently use the values they receive. Listing 9-13 shows one way to define a Guess type that will only create an instance of Guess if the new function receives a value between 1 and 100. Filename: src/guessing_game.rs pub struct Guess { value: i32,\\n} impl Guess { pub fn new(value: i32) -> Guess { if value < 1 || value > 100 { panic!(\\"Guess value must be between 1 and 100, got {value}.\\"); } Guess { value } } pub fn value(&self) -> i32 { self.value }\\n} Listing 9-13: A Guess type that will only continue with values between 1 and 100 Note that this code in src/guessing_game.rs depends on adding a module declaration mod guessing_game; in src/lib.rs that we haven‚Äôt shown here. Within this new module‚Äôs file, we define a struct named Guess that has a field named value that holds an i32. This is where the number will be stored. Then, we implement an associated function named new on Guess that creates instances of Guess values. The new function is defined to have one parameter named value of type i32 and to return a Guess. The code in the body of the new function tests value to make sure it‚Äôs between 1 and 100. If value doesn‚Äôt pass this test, we make a panic! call, which will alert the programmer who is writing the calling code that they have a bug they need to fix, because creating a Guess with a value outside this range would violate the contract that Guess::new is relying on. The conditions in which Guess::new might panic should be discussed in its public-facing API documentation; we‚Äôll cover documentation conventions indicating the possibility of a panic! in the API documentation that you create in Chapter 14. If value does pass the test, we create a new Guess with its value field set to the value parameter and return the Guess. Next, we implement a method named value that borrows self, doesn‚Äôt have any other parameters, and returns an i32. This kind of method is sometimes called a getter because its purpose is to get some data from its fields and return it. This public method is necessary because the value field of the Guess struct is private. It‚Äôs important that the value field be private so that code using the Guess struct is not allowed to set value directly: Code outside the guessing_game module must use the Guess::new function to create an instance of Guess, thereby ensuring that there‚Äôs no way for a Guess to have a value that hasn‚Äôt been checked by the conditions in the Guess::new function. A function that has a parameter or returns only numbers between 1 and 100 could then declare in its signature that it takes or returns a Guess rather than an i32 and wouldn‚Äôt need to do any additional checks in its body.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª Custom Types for Validation","id":"164","title":"Custom Types for Validation"},"165":{"body":"Rust‚Äôs error-handling features are designed to help you write more robust code. The panic! macro signals that your program is in a state it can‚Äôt handle and lets you tell the process to stop instead of trying to proceed with invalid or incorrect values. The Result enum uses Rust‚Äôs type system to indicate that operations might fail in a way that your code could recover from. You can use Result to tell code that calls your code that it needs to handle potential success or failure as well. Using panic! and Result in the appropriate situations will make your code more reliable in the face of inevitable problems. Now that you‚Äôve seen useful ways that the standard library uses generics with the Option and Result enums, we‚Äôll talk about how generics work and how you can use them in your code.","breadcrumbs":"Error Handling ¬ª To panic! or Not to panic! ¬ª Summary","id":"165","title":"Summary"},"166":{"body":"Every programming language has tools for effectively handling the duplication of concepts. In Rust, one such tool is generics : abstract stand-ins for concrete types or other properties. We can express the behavior of generics or how they relate to other generics without knowing what will be in their place when compiling and running the code. Functions can take parameters of some generic type, instead of a concrete type like i32 or String, in the same way they take parameters with unknown values to run the same code on multiple concrete values. In fact, we already used generics in Chapter 6 with Option<T>, in Chapter 8 with Vec<T> and HashMap<K, V>, and in Chapter 9 with Result<T, E>. In this chapter, you‚Äôll explore how to define your own types, functions, and methods with generics! First, we‚Äôll review how to extract a function to reduce code duplication. We‚Äôll then use the same technique to make a generic function from two functions that differ only in the types of their parameters. We‚Äôll also explain how to use generic types in struct and enum definitions. Then, you‚Äôll learn how to use traits to define behavior in a generic way. You can combine traits with generic types to constrain a generic type to accept only those types that have a particular behavior, as opposed to just any type. Finally, we‚Äôll discuss lifetimes : a variety of generics that give the compiler information about how references relate to each other. Lifetimes allow us to give the compiler enough information about borrowed values so that it can ensure that references will be valid in more situations than it could without our help.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Types, Traits, and Lifetimes","id":"166","title":"Generic Types, Traits, and Lifetimes"},"167":{"body":"Generics allow us to replace specific types with a placeholder that represents multiple types to remove code duplication. Before diving into generics syntax, let‚Äôs first look at how to remove duplication in a way that doesn‚Äôt involve generic types by extracting a function that replaces specific values with a placeholder that represents multiple values. Then, we‚Äôll apply the same technique to extract a generic function! By looking at how to recognize duplicated code you can extract into a function, you‚Äôll start to recognize duplicated code that can use generics. We‚Äôll begin with the short program in Listing 10-1 that finds the largest number in a list. Filename: src/main.rs fn main() { let number_list = vec![34, 50, 25, 100, 65]; let mut largest = &number_list[0]; for number in &number_list { if number > largest { largest = number; } } println!(\\"The largest number is {largest}\\");\\n# assert_eq!(*largest, 100);\\n} Listing 10-1: Finding the largest number in a list of numbers We store a list of integers in the variable number_list and place a reference to the first number in the list in a variable named largest. We then iterate through all the numbers in the list, and if the current number is greater than the number stored in largest, we replace the reference in that variable. However, if the current number is less than or equal to the largest number seen so far, the variable doesn‚Äôt change, and the code moves on to the next number in the list. After considering all the numbers in the list, largest should refer to the largest number, which in this case is 100. We‚Äôve now been tasked with finding the largest number in two different lists of numbers. To do so, we can choose to duplicate the code in Listing 10-1 and use the same logic at two different places in the program, as shown in Listing 10-2. Filename: src/main.rs fn main() { let number_list = vec![34, 50, 25, 100, 65]; let mut largest = &number_list[0]; for number in &number_list { if number > largest { largest = number; } } println!(\\"The largest number is {largest}\\"); let number_list = vec![102, 34, 6000, 89, 54, 2, 43, 8]; let mut largest = &number_list[0]; for number in &number_list { if number > largest { largest = number; } } println!(\\"The largest number is {largest}\\");\\n} Listing 10-2: Code to find the largest number in two lists of numbers Although this code works, duplicating code is tedious and error-prone. We also have to remember to update the code in multiple places when we want to change it. To eliminate this duplication, we‚Äôll create an abstraction by defining a function that operates on any list of integers passed in as a parameter. This solution makes our code clearer and lets us express the concept of finding the largest number in a list abstractly. In Listing 10-3, we extract the code that finds the largest number into a function named largest. Then, we call the function to find the largest number in the two lists from Listing 10-2. We could also use the function on any other list of i32 values we might have in the future. Filename: src/main.rs fn largest(list: &[i32]) -> &i32 { let mut largest = &list[0]; for item in list { if item > largest { largest = item; } } largest\\n} fn main() { let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&number_list); println!(\\"The largest number is {result}\\");\\n# assert_eq!(*result, 100); let number_list = vec![102, 34, 6000, 89, 54, 2, 43, 8]; let result = largest(&number_list); println!(\\"The largest number is {result}\\");\\n# assert_eq!(*result, 6000);\\n} Listing 10-3: Abstracted code to find the largest number in two lists The largest function has a parameter called list, which represents any concrete slice of i32 values we might pass into the function. As a result, when we call the function, the code runs on the specific values that we pass in. In summary, here are the steps we took to change the code from Listing 10-2 to Listing 10-3: Identify duplicate code. Extract the duplicate code into the body of the function, and specify the inputs and return values of that code in the function signature. Update the two instances of duplicated code to call the function instead. Next, we‚Äôll use these same steps with generics to reduce code duplication. In the same way that the function body can operate on an abstract list instead of specific values, generics allow code to operate on abstract types. For example, say we had two functions: one that finds the largest item in a slice of i32 values and one that finds the largest item in a slice of char values. How would we eliminate that duplication? Let‚Äôs find out!","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Removing Duplication by Extracting a Function","id":"167","title":"Removing Duplication by Extracting a Function"},"168":{"body":"We use generics to create definitions for items like function signatures or structs, which we can then use with many different concrete data types. Let‚Äôs first look at how to define functions, structs, enums, and methods using generics. Then, we‚Äôll discuss how generics affect code performance.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª Generic Data Types","id":"168","title":"Generic Data Types"},"169":{"body":"When defining a function that uses generics, we place the generics in the signature of the function where we would usually specify the data types of the parameters and return value. Doing so makes our code more flexible and provides more functionality to callers of our function while preventing code duplication. Continuing with our largest function, Listing 10-4 shows two functions that both find the largest value in a slice. We‚Äôll then combine these into a single function that uses generics. Filename: src/main.rs fn largest_i32(list: &[i32]) -> &i32 { let mut largest = &list[0]; for item in list { if item > largest { largest = item; } } largest\\n} fn largest_char(list: &[char]) -> &char { let mut largest = &list[0]; for item in list { if item > largest { largest = item; } } largest\\n} fn main() { let number_list = vec![34, 50, 25, 100, 65]; let result = largest_i32(&number_list); println!(\\"The largest number is {result}\\");\\n# assert_eq!(*result, 100); let char_list = vec![\'y\', \'m\', \'a\', \'q\']; let result = largest_char(&char_list); println!(\\"The largest char is {result}\\");\\n# assert_eq!(*result, \'y\');\\n} Listing 10-4: Two functions that differ only in their names and in the types in their signatures The largest_i32 function is the one we extracted in Listing 10-3 that finds the largest i32 in a slice. The largest_char function finds the largest char in a slice. The function bodies have the same code, so let‚Äôs eliminate the duplication by introducing a generic type parameter in a single function. To parameterize the types in a new single function, we need to name the type parameter, just as we do for the value parameters to a function. You can use any identifier as a type parameter name. But we‚Äôll use T because, by convention, type parameter names in Rust are short, often just one letter, and Rust‚Äôs type-naming convention is UpperCamelCase. Short for type , T is the default choice of most Rust programmers. When we use a parameter in the body of the function, we have to declare the parameter name in the signature so that the compiler knows what that name means. Similarly, when we use a type parameter name in a function signature, we have to declare the type parameter name before we use it. To define the generic largest function, we place type name declarations inside angle brackets, <>, between the name of the function and the parameter list, like this: fn largest<T>(list: &[T]) -> &T { We read this definition as ‚ÄúThe function largest is generic over some type T.‚Äù This function has one parameter named list, which is a slice of values of type T. The largest function will return a reference to a value of the same type T. Listing 10-5 shows the combined largest function definition using the generic data type in its signature. The listing also shows how we can call the function with either a slice of i32 values or char values. Note that this code won‚Äôt compile yet. Filename: src/main.rs fn largest<T>(list: &[T]) -> &T { let mut largest = &list[0]; for item in list { if item > largest { largest = item; } } largest\\n} fn main() { let number_list = vec![34, 50, 25, 100, 65]; let result = largest(&number_list); println!(\\"The largest number is {result}\\"); let char_list = vec![\'y\', \'m\', \'a\', \'q\']; let result = largest(&char_list); println!(\\"The largest char is {result}\\");\\n} Listing 10-5: The largest function using generic type parameters; this doesn‚Äôt compile yet If we compile this code right now, we‚Äôll get this error: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0369]: binary operation `>` cannot be applied to type `&T` --> src/main.rs:5:17 |\\n5 | if item > largest { | ---- ^ ------- &T | | | &T |\\nhelp: consider restricting type parameter `T` with trait `PartialOrd` |\\n1 | fn largest<T: std::cmp::PartialOrd>(list: &[T]) -> &T { | ++++++++++++++++++++++ For more information about this error, try `rustc --explain E0369`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error The help text mentions std::cmp::PartialOrd, which is a trait, and we‚Äôre going to talk about traits in the next section. For now, know that this error states that the body of largest won‚Äôt work for all possible types that T could be. Because we want to compare values of type T in the body, we can only use types whose values can be ordered. To enable comparisons, the standard library has the std::cmp::PartialOrd trait that you can implement on types (see Appendix C for more on this trait). To fix Listing 10-5, we can follow the help text‚Äôs suggestion and restrict the types valid for T to only those that implement PartialOrd. The listing will then compile, because the standard library implements PartialOrd on both i32 and char.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª In Function Definitions","id":"169","title":"In Function Definitions"},"17":{"body":"To check whether you have Rust installed correctly, open a shell and enter this line: $ rustc --version You should see the version number, commit hash, and commit date for the latest stable version that has been released, in the following format: rustc x.y.z (abcabcabc yyyy-mm-dd) If you see this information, you have installed Rust successfully! If you don‚Äôt see this information, check that Rust is in your %PATH% system variable as follows. In Windows CMD, use: > echo %PATH% In PowerShell, use: > echo $env:Path In Linux and macOS, use: $ echo $PATH If that‚Äôs all correct and Rust still isn‚Äôt working, there are a number of places you can get help. Find out how to get in touch with other Rustaceans (a silly nickname we call ourselves) on the community page .","breadcrumbs":"Getting Started ¬ª Installation ¬ª Troubleshooting","id":"17","title":"Troubleshooting"},"170":{"body":"We can also define structs to use a generic type parameter in one or more fields using the <> syntax. Listing 10-6 defines a Point<T> struct to hold x and y coordinate values of any type. Filename: src/main.rs struct Point<T> { x: T, y: T,\\n} fn main() { let integer = Point { x: 5, y: 10 }; let float = Point { x: 1.0, y: 4.0 };\\n} Listing 10-6: A Point&lt;T&gt; struct that holds x and y values of type T The syntax for using generics in struct definitions is similar to that used in function definitions. First, we declare the name of the type parameter inside angle brackets just after the name of the struct. Then, we use the generic type in the struct definition where we would otherwise specify concrete data types. Note that because we‚Äôve used only one generic type to define Point<T>, this definition says that the Point<T> struct is generic over some type T, and the fields x and y are both that same type, whatever that type may be. If we create an instance of a Point<T> that has values of different types, as in Listing 10-7, our code won‚Äôt compile. Filename: src/main.rs struct Point<T> { x: T, y: T,\\n} fn main() { let wont_work = Point { x: 5, y: 4.0 };\\n} Listing 10-7: The fields x and y must be the same type because both have the same generic data type T. In this example, when we assign the integer value 5 to x, we let the compiler know that the generic type T will be an integer for this instance of Point<T>. Then, when we specify 4.0 for y, which we‚Äôve defined to have the same type as x, we‚Äôll get a type mismatch error like this: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0308]: mismatched types --> src/main.rs:7:38 |\\n7 | let wont_work = Point { x: 5, y: 4.0 }; | ^^^ expected integer, found floating-point number For more information about this error, try `rustc --explain E0308`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error To define a Point struct where x and y are both generics but could have different types, we can use multiple generic type parameters. For example, in Listing 10-8, we change the definition of Point to be generic over types T and U where x is of type T and y is of type U. Filename: src/main.rs struct Point<T, U> { x: T, y: U,\\n} fn main() { let both_integer = Point { x: 5, y: 10 }; let both_float = Point { x: 1.0, y: 4.0 }; let integer_and_float = Point { x: 5, y: 4.0 };\\n} Listing 10-8: A Point&lt;T, U&gt; generic over two types so that x and y can be values of different types Now all the instances of Point shown are allowed! You can use as many generic type parameters in a definition as you want, but using more than a few makes your code hard to read. If you‚Äôre finding you need lots of generic types in your code, it could indicate that your code needs restructuring into smaller pieces.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª In Struct Definitions","id":"170","title":"In Struct Definitions"},"171":{"body":"As we did with structs, we can define enums to hold generic data types in their variants. Let‚Äôs take another look at the Option<T> enum that the standard library provides, which we used in Chapter 6: enum Option<T> { Some(T), None,\\n} This definition should now make more sense to you. As you can see, the Option<T> enum is generic over type T and has two variants: Some, which holds one value of type T, and a None variant that doesn‚Äôt hold any value. By using the Option<T> enum, we can express the abstract concept of an optional value, and because Option<T> is generic, we can use this abstraction no matter what the type of the optional value is. Enums can use multiple generic types as well. The definition of the Result enum that we used in Chapter 9 is one example: enum Result<T, E> { Ok(T), Err(E),\\n} The Result enum is generic over two types, T and E, and has two variants: Ok, which holds a value of type T, and Err, which holds a value of type E. This definition makes it convenient to use the Result enum anywhere we have an operation that might succeed (return a value of some type T) or fail (return an error of some type E). In fact, this is what we used to open a file in Listing 9-3, where T was filled in with the type std::fs::File when the file was opened successfully and E was filled in with the type std::io::Error when there were problems opening the file. When you recognize situations in your code with multiple struct or enum definitions that differ only in the types of the values they hold, you can avoid duplication by using generic types instead.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª In Enum Definitions","id":"171","title":"In Enum Definitions"},"172":{"body":"We can implement methods on structs and enums (as we did in Chapter 5) and use generic types in their definitions too. Listing 10-9 shows the Point<T> struct we defined in Listing 10-6 with a method named x implemented on it. Filename: src/main.rs struct Point<T> { x: T, y: T,\\n} impl<T> Point<T> { fn x(&self) -> &T { &self.x }\\n} fn main() { let p = Point { x: 5, y: 10 }; println!(\\"p.x = {}\\", p.x());\\n} Listing 10-9: Implementing a method named x on the Point&lt;T&gt; struct that will return a reference to the x field of type T Here, we‚Äôve defined a method named x on Point<T> that returns a reference to the data in the field x. Note that we have to declare T just after impl so that we can use T to specify that we‚Äôre implementing methods on the type Point<T>. By declaring T as a generic type after impl, Rust can identify that the type in the angle brackets in Point is a generic type rather than a concrete type. We could have chosen a different name for this generic parameter than the generic parameter declared in the struct definition, but using the same name is conventional. If you write a method within an impl that declares a generic type, that method will be defined on any instance of the type, no matter what concrete type ends up substituting for the generic type. We can also specify constraints on generic types when defining methods on the type. We could, for example, implement methods only on Point<f32> instances rather than on Point<T> instances with any generic type. In Listing 10-10, we use the concrete type f32, meaning we don‚Äôt declare any types after impl. Filename: src/main.rs # struct Point<T> {\\n# x: T,\\n# y: T,\\n# }\\n# # impl<T> Point<T> {\\n# fn x(&self) -> &T {\\n# &self.x\\n# }\\n# }\\n# impl Point<f32> { fn distance_from_origin(&self) -> f32 { (self.x.powi(2) + self.y.powi(2)).sqrt() }\\n}\\n# # fn main() {\\n# let p = Point { x: 5, y: 10 };\\n# # println!(\\"p.x = {}\\", p.x());\\n# } Listing 10-10: An impl block that only applies to a struct with a particular concrete type for the generic type parameter T This code means the type Point<f32> will have a distance_from_origin method; other instances of Point<T> where T is not of type f32 will not have this method defined. The method measures how far our point is from the point at coordinates (0.0, 0.0) and uses mathematical operations that are available only for floating-point types. Generic type parameters in a struct definition aren‚Äôt always the same as those you use in that same struct‚Äôs method signatures. Listing 10-11 uses the generic types X1 and Y1 for the Point struct and X2 and Y2 for the mixup method signature to make the example clearer. The method creates a new Point instance with the x value from the self Point (of type X1) and the y value from the passed-in Point (of type Y2). Filename: src/main.rs struct Point<X1, Y1> { x: X1, y: Y1,\\n} impl<X1, Y1> Point<X1, Y1> { fn mixup<X2, Y2>(self, other: Point<X2, Y2>) -> Point<X1, Y2> { Point { x: self.x, y: other.y, } }\\n} fn main() { let p1 = Point { x: 5, y: 10.4 }; let p2 = Point { x: \\"Hello\\", y: \'c\' }; let p3 = p1.mixup(p2); println!(\\"p3.x = {}, p3.y = {}\\", p3.x, p3.y);\\n} Listing 10-11: A method that uses generic types that are different from its struct‚Äôs definition In main, we‚Äôve defined a Point that has an i32 for x (with value 5) and an f64 for y (with value 10.4). The p2 variable is a Point struct that has a string slice for x (with value \\"Hello\\") and a char for y (with value c). Calling mixup on p1 with the argument p2 gives us p3, which will have an i32 for x because x came from p1. The p3 variable will have a char for y because y came from p2. The println! macro call will print p3.x = 5, p3.y = c. The purpose of this example is to demonstrate a situation in which some generic parameters are declared with impl and some are declared with the method definition. Here, the generic parameters X1 and Y1 are declared after impl because they go with the struct definition. The generic parameters X2 and Y2 are declared after fn mixup because they‚Äôre only relevant to the method.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª In Method Definitions","id":"172","title":"In Method Definitions"},"173":{"body":"You might be wondering whether there is a runtime cost when using generic type parameters. The good news is that using generic types won‚Äôt make your program run any slower than it would with concrete types. Rust accomplishes this by performing monomorphization of the code using generics at compile time. Monomorphization is the process of turning generic code into specific code by filling in the concrete types that are used when compiled. In this process, the compiler does the opposite of the steps we used to create the generic function in Listing 10-5: The compiler looks at all the places where generic code is called and generates code for the concrete types the generic code is called with. Let‚Äôs look at how this works by using the standard library‚Äôs generic Option<T> enum: let integer = Some(5);\\nlet float = Some(5.0); When Rust compiles this code, it performs monomorphization. During that process, the compiler reads the values that have been used in Option<T> instances and identifies two kinds of Option<T>: One is i32 and the other is f64. As such, it expands the generic definition of Option<T> into two definitions specialized to i32 and f64, thereby replacing the generic definition with the specific ones. The monomorphized version of the code looks similar to the following (the compiler uses different names than what we‚Äôre using here for illustration): Filename: src/main.rs enum Option_i32 { Some(i32), None,\\n} enum Option_f64 { Some(f64), None,\\n} fn main() { let integer = Option_i32::Some(5); let float = Option_f64::Some(5.0);\\n} The generic Option<T> is replaced with the specific definitions created by the compiler. Because Rust compiles generic code into code that specifies the type in each instance, we pay no runtime cost for using generics. When the code runs, it performs just as it would if we had duplicated each definition by hand. The process of monomorphization makes Rust‚Äôs generics extremely efficient at runtime.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Generic Data Types ¬ª Performance of Code Using Generics","id":"173","title":"Performance of Code Using Generics"},"174":{"body":"A trait defines the functionality a particular type has and can share with other types. We can use traits to define shared behavior in an abstract way. We can use trait bounds to specify that a generic type can be any type that has certain behavior. Note: Traits are similar to a feature often called interfaces in other languages, although with some differences.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Defining Shared Behavior with Traits","id":"174","title":"Defining Shared Behavior with Traits"},"175":{"body":"A type‚Äôs behavior consists of the methods we can call on that type. Different types share the same behavior if we can call the same methods on all of those types. Trait definitions are a way to group method signatures together to define a set of behaviors necessary to accomplish some purpose. For example, let‚Äôs say we have multiple structs that hold various kinds and amounts of text: a NewsArticle struct that holds a news story filed in a particular location and a SocialPost that can have, at most, 280 characters along with metadata that indicates whether it was a new post, a repost, or a reply to another post. We want to make a media aggregator library crate named aggregator that can display summaries of data that might be stored in a NewsArticle or SocialPost instance. To do this, we need a summary from each type, and we‚Äôll request that summary by calling a summarize method on an instance. Listing 10-12 shows the definition of a public Summary trait that expresses this behavior. Filename: src/lib.rs pub trait Summary { fn summarize(&self) -> String;\\n} Listing 10-12: A Summary trait that consists of the behavior provided by a summarize method Here, we declare a trait using the trait keyword and then the trait‚Äôs name, which is Summary in this case. We also declare the trait as pub so that crates depending on this crate can make use of this trait too, as we‚Äôll see in a few examples. Inside the curly brackets, we declare the method signatures that describe the behaviors of the types that implement this trait, which in this case is fn summarize(&self) -> String. After the method signature, instead of providing an implementation within curly brackets, we use a semicolon. Each type implementing this trait must provide its own custom behavior for the body of the method. The compiler will enforce that any type that has the Summary trait will have the method summarize defined with this signature exactly. A trait can have multiple methods in its body: The method signatures are listed one per line, and each line ends in a semicolon.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Defining a Trait","id":"175","title":"Defining a Trait"},"176":{"body":"Now that we‚Äôve defined the desired signatures of the Summary trait‚Äôs methods, we can implement it on the types in our media aggregator. Listing 10-13 shows an implementation of the Summary trait on the NewsArticle struct that uses the headline, the author, and the location to create the return value of summarize. For the SocialPost struct, we define summarize as the username followed by the entire text of the post, assuming that the post content is already limited to 280 characters. Filename: src/lib.rs # pub trait Summary {\\n# fn summarize(&self) -> String;\\n# }\\n# pub struct NewsArticle { pub headline: String, pub location: String, pub author: String, pub content: String,\\n} impl Summary for NewsArticle { fn summarize(&self) -> String { format!(\\"{}, by {} ({})\\", self.headline, self.author, self.location) }\\n} pub struct SocialPost { pub username: String, pub content: String, pub reply: bool, pub repost: bool,\\n} impl Summary for SocialPost { fn summarize(&self) -> String { format!(\\"{}: {}\\", self.username, self.content) }\\n} Listing 10-13: Implementing the Summary trait on the NewsArticle and SocialPost types Implementing a trait on a type is similar to implementing regular methods. The difference is that after impl, we put the trait name we want to implement, then use the for keyword, and then specify the name of the type we want to implement the trait for. Within the impl block, we put the method signatures that the trait definition has defined. Instead of adding a semicolon after each signature, we use curly brackets and fill in the method body with the specific behavior that we want the methods of the trait to have for the particular type. Now that the library has implemented the Summary trait on NewsArticle and SocialPost, users of the crate can call the trait methods on instances of NewsArticle and SocialPost in the same way we call regular methods. The only difference is that the user must bring the trait into scope as well as the types. Here‚Äôs an example of how a binary crate could use our aggregator library crate: use aggregator::{SocialPost, Summary}; fn main() { let post = SocialPost { username: String::from(\\"horse_ebooks\\"), content: String::from( \\"of course, as you probably already know, people\\", ), reply: false, repost: false, }; println!(\\"1 new post: {}\\", post.summarize());\\n} This code prints 1 new post: horse_ebooks: of course, as you probably already know, people. Other crates that depend on the aggregator crate can also bring the Summary trait into scope to implement Summary on their own types. One restriction to note is that we can implement a trait on a type only if either the trait or the type, or both, are local to our crate. For example, we can implement standard library traits like Display on a custom type like SocialPost as part of our aggregator crate functionality because the type SocialPost is local to our aggregator crate. We can also implement Summary on Vec<T> in our aggregator crate because the trait Summary is local to our aggregator crate. But we can‚Äôt implement external traits on external types. For example, we can‚Äôt implement the Display trait on Vec<T> within our aggregator crate, because Display and Vec<T> are both defined in the standard library and aren‚Äôt local to our aggregator crate. This restriction is part of a property called coherence , and more specifically the orphan rule , so named because the parent type is not present. This rule ensures that other people‚Äôs code can‚Äôt break your code and vice versa. Without the rule, two crates could implement the same trait for the same type, and Rust wouldn‚Äôt know which implementation to use.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Implementing a Trait on a Type","id":"176","title":"Implementing a Trait on a Type"},"177":{"body":"Sometimes it‚Äôs useful to have default behavior for some or all of the methods in a trait instead of requiring implementations for all methods on every type. Then, as we implement the trait on a particular type, we can keep or override each method‚Äôs default behavior. In Listing 10-14, we specify a default string for the summarize method of the Summary trait instead of only defining the method signature, as we did in Listing 10-12. Filename: src/lib.rs pub trait Summary { fn summarize(&self) -> String { String::from(\\"(Read more...)\\") }\\n}\\n# # pub struct NewsArticle {\\n# pub headline: String,\\n# pub location: String,\\n# pub author: String,\\n# pub content: String,\\n# }\\n# # impl Summary for NewsArticle {}\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# # impl Summary for SocialPost {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}: {}\\", self.username, self.content)\\n# }\\n# } Listing 10-14: Defining a Summary trait with a default implementation of the summarize method To use a default implementation to summarize instances of NewsArticle, we specify an empty impl block with impl Summary for NewsArticle {}. Even though we‚Äôre no longer defining the summarize method on NewsArticle directly, we‚Äôve provided a default implementation and specified that NewsArticle implements the Summary trait. As a result, we can still call the summarize method on an instance of NewsArticle, like this: # use aggregator::{self, NewsArticle, Summary};\\n# # fn main() { let article = NewsArticle { headline: String::from(\\"Penguins win the Stanley Cup Championship!\\"), location: String::from(\\"Pittsburgh, PA, USA\\"), author: String::from(\\"Iceburgh\\"), content: String::from( \\"The Pittsburgh Penguins once again are the best \\\\ hockey team in the NHL.\\", ), }; println!(\\"New article available! {}\\", article.summarize());\\n# } This code prints New article available! (Read more...). Creating a default implementation doesn‚Äôt require us to change anything about the implementation of Summary on SocialPost in Listing 10-13. The reason is that the syntax for overriding a default implementation is the same as the syntax for implementing a trait method that doesn‚Äôt have a default implementation. Default implementations can call other methods in the same trait, even if those other methods don‚Äôt have a default implementation. In this way, a trait can provide a lot of useful functionality and only require implementors to specify a small part of it. For example, we could define the Summary trait to have a summarize_author method whose implementation is required, and then define a summarize method that has a default implementation that calls the summarize_author method: pub trait Summary { fn summarize_author(&self) -> String; fn summarize(&self) -> String { format!(\\"(Read more from {}...)\\", self.summarize_author()) }\\n}\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# # impl Summary for SocialPost {\\n# fn summarize_author(&self) -> String {\\n# format!(\\"@{}\\", self.username)\\n# }\\n# } To use this version of Summary, we only need to define summarize_author when we implement the trait on a type: # pub trait Summary {\\n# fn summarize_author(&self) -> String;\\n# # fn summarize(&self) -> String {\\n# format!(\\"(Read more from {}...)\\", self.summarize_author())\\n# }\\n# }\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# impl Summary for SocialPost { fn summarize_author(&self) -> String { format!(\\"@{}\\", self.username) }\\n} After we define summarize_author, we can call summarize on instances of the SocialPost struct, and the default implementation of summarize will call the definition of summarize_author that we‚Äôve provided. Because we‚Äôve implemented summarize_author, the Summary trait has given us the behavior of the summarize method without requiring us to write any more code. Here‚Äôs what that looks like: # use aggregator::{self, SocialPost, Summary};\\n# # fn main() { let post = SocialPost { username: String::from(\\"horse_ebooks\\"), content: String::from( \\"of course, as you probably already know, people\\", ), reply: false, repost: false, }; println!(\\"1 new post: {}\\", post.summarize());\\n# } This code prints 1 new post: (Read more from @horse_ebooks...). Note that it isn‚Äôt possible to call the default implementation from an overriding implementation of that same method.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Using Default Implementations","id":"177","title":"Using Default Implementations"},"178":{"body":"Now that you know how to define and implement traits, we can explore how to use traits to define functions that accept many different types. We‚Äôll use the Summary trait we implemented on the NewsArticle and SocialPost types in Listing 10-13 to define a notify function that calls the summarize method on its item parameter, which is of some type that implements the Summary trait. To do this, we use the impl Trait syntax, like this: # pub trait Summary {\\n# fn summarize(&self) -> String;\\n# }\\n# # pub struct NewsArticle {\\n# pub headline: String,\\n# pub location: String,\\n# pub author: String,\\n# pub content: String,\\n# }\\n# # impl Summary for NewsArticle {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}, by {} ({})\\", self.headline, self.author, self.location)\\n# }\\n# }\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# # impl Summary for SocialPost {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}: {}\\", self.username, self.content)\\n# }\\n# }\\n# pub fn notify(item: &impl Summary) { println!(\\"Breaking news! {}\\", item.summarize());\\n} Instead of a concrete type for the item parameter, we specify the impl keyword and the trait name. This parameter accepts any type that implements the specified trait. In the body of notify, we can call any methods on item that come from the Summary trait, such as summarize. We can call notify and pass in any instance of NewsArticle or SocialPost. Code that calls the function with any other type, such as a String or an i32, won‚Äôt compile, because those types don‚Äôt implement Summary. Trait Bound Syntax The impl Trait syntax works for straightforward cases but is actually syntax sugar for a longer form known as a trait bound ; it looks like this: pub fn notify<T: Summary>(item: &T) { println!(\\"Breaking news! {}\\", item.summarize());\\n} This longer form is equivalent to the example in the previous section but is more verbose. We place trait bounds with the declaration of the generic type parameter after a colon and inside angle brackets. The impl Trait syntax is convenient and makes for more concise code in simple cases, while the fuller trait bound syntax can express more complexity in other cases. For example, we can have two parameters that implement Summary. Doing so with the impl Trait syntax looks like this: pub fn notify(item1: &impl Summary, item2: &impl Summary) { Using impl Trait is appropriate if we want this function to allow item1 and item2 to have different types (as long as both types implement Summary). If we want to force both parameters to have the same type, however, we must use a trait bound, like this: pub fn notify<T: Summary>(item1: &T, item2: &T) { The generic type T specified as the type of the item1 and item2 parameters constrains the function such that the concrete type of the value passed as an argument for item1 and item2 must be the same. Multiple Trait Bounds with the + Syntax We can also specify more than one trait bound. Say we wanted notify to use display formatting as well as summarize on item: We specify in the notify definition that item must implement both Display and Summary. We can do so using the + syntax: pub fn notify(item: &(impl Summary + Display)) { The + syntax is also valid with trait bounds on generic types: pub fn notify<T: Summary + Display>(item: &T) { With the two trait bounds specified, the body of notify can call summarize and use {} to format item. Clearer Trait Bounds with where Clauses Using too many trait bounds has its downsides. Each generic has its own trait bounds, so functions with multiple generic type parameters can contain lots of trait bound information between the function‚Äôs name and its parameter list, making the function signature hard to read. For this reason, Rust has alternate syntax for specifying trait bounds inside a where clause after the function signature. So, instead of writing this: fn some_function<T: Display + Clone, U: Clone + Debug>(t: &T, u: &U) -> i32 { we can use a where clause, like this: fn some_function<T, U>(t: &T, u: &U) -> i32\\nwhere T: Display + Clone, U: Clone + Debug,\\n{\\n# unimplemented!()\\n# } This function‚Äôs signature is less cluttered: The function name, parameter list, and return type are close together, similar to a function without lots of trait bounds.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Using Traits as Parameters","id":"178","title":"Using Traits as Parameters"},"179":{"body":"We can also use the impl Trait syntax in the return position to return a value of some type that implements a trait, as shown here: # pub trait Summary {\\n# fn summarize(&self) -> String;\\n# }\\n# # pub struct NewsArticle {\\n# pub headline: String,\\n# pub location: String,\\n# pub author: String,\\n# pub content: String,\\n# }\\n# # impl Summary for NewsArticle {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}, by {} ({})\\", self.headline, self.author, self.location)\\n# }\\n# }\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# # impl Summary for SocialPost {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}: {}\\", self.username, self.content)\\n# }\\n# }\\n# fn returns_summarizable() -> impl Summary { SocialPost { username: String::from(\\"horse_ebooks\\"), content: String::from( \\"of course, as you probably already know, people\\", ), reply: false, repost: false, }\\n} By using impl Summary for the return type, we specify that the returns_summarizable function returns some type that implements the Summary trait without naming the concrete type. In this case, returns_summarizable returns a SocialPost, but the code calling this function doesn‚Äôt need to know that. The ability to specify a return type only by the trait it implements is especially useful in the context of closures and iterators, which we cover in Chapter 13. Closures and iterators create types that only the compiler knows or types that are very long to specify. The impl Trait syntax lets you concisely specify that a function returns some type that implements the Iterator trait without needing to write out a very long type. However, you can only use impl Trait if you‚Äôre returning a single type. For example, this code that returns either a NewsArticle or a SocialPost with the return type specified as impl Summary wouldn‚Äôt work: # pub trait Summary {\\n# fn summarize(&self) -> String;\\n# }\\n# # pub struct NewsArticle {\\n# pub headline: String,\\n# pub location: String,\\n# pub author: String,\\n# pub content: String,\\n# }\\n# # impl Summary for NewsArticle {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}, by {} ({})\\", self.headline, self.author, self.location)\\n# }\\n# }\\n# # pub struct SocialPost {\\n# pub username: String,\\n# pub content: String,\\n# pub reply: bool,\\n# pub repost: bool,\\n# }\\n# # impl Summary for SocialPost {\\n# fn summarize(&self) -> String {\\n# format!(\\"{}: {}\\", self.username, self.content)\\n# }\\n# }\\n# fn returns_summarizable(switch: bool) -> impl Summary { if switch { NewsArticle { headline: String::from( \\"Penguins win the Stanley Cup Championship!\\", ), location: String::from(\\"Pittsburgh, PA, USA\\"), author: String::from(\\"Iceburgh\\"), content: String::from( \\"The Pittsburgh Penguins once again are the best \\\\ hockey team in the NHL.\\", ), } } else { SocialPost { username: String::from(\\"horse_ebooks\\"), content: String::from( \\"of course, as you probably already know, people\\", ), reply: false, repost: false, } }\\n} Returning either a NewsArticle or a SocialPost isn‚Äôt allowed due to restrictions around how the impl Trait syntax is implemented in the compiler. We‚Äôll cover how to write a function with this behavior in the ‚ÄúUsing Trait Objects to Abstract over Shared Behavior‚Äù section of Chapter 18.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Returning Types That Implement Traits","id":"179","title":"Returning Types That Implement Traits"},"18":{"body":"Once Rust is installed via rustup, updating to a newly released version is easy. From your shell, run the following update script: $ rustup update To uninstall Rust and rustup, run the following uninstall script from your shell: $ rustup self uninstall","breadcrumbs":"Getting Started ¬ª Installation ¬ª Updating and Uninstalling","id":"18","title":"Updating and Uninstalling"},"180":{"body":"By using a trait bound with an impl block that uses generic type parameters, we can implement methods conditionally for types that implement the specified traits. For example, the type Pair<T> in Listing 10-15 always implements the new function to return a new instance of Pair<T> (recall from the ‚ÄúMethod Syntax‚Äù section of Chapter 5 that Self is a type alias for the type of the impl block, which in this case is Pair<T>). But in the next impl block, Pair<T> only implements the cmp_display method if its inner type T implements the PartialOrd trait that enables comparison and the Display trait that enables printing. Filename: src/lib.rs use std::fmt::Display; struct Pair<T> { x: T, y: T,\\n} impl<T> Pair<T> { fn new(x: T, y: T) -> Self { Self { x, y } }\\n} impl<T: Display + PartialOrd> Pair<T> { fn cmp_display(&self) { if self.x >= self.y { println!(\\"The largest member is x = {}\\", self.x); } else { println!(\\"The largest member is y = {}\\", self.y); } }\\n} Listing 10-15: Conditionally implementing methods on a generic type depending on trait bounds We can also conditionally implement a trait for any type that implements another trait. Implementations of a trait on any type that satisfies the trait bounds are called blanket implementations and are used extensively in the Rust standard library. For example, the standard library implements the ToString trait on any type that implements the Display trait. The impl block in the standard library looks similar to this code: impl<T: Display> ToString for T { // --snip--\\n} Because the standard library has this blanket implementation, we can call the to_string method defined by the ToString trait on any type that implements the Display trait. For example, we can turn integers into their corresponding String values like this because integers implement Display: let s = 3.to_string(); Blanket implementations appear in the documentation for the trait in the ‚ÄúImplementors‚Äù section. Traits and trait bounds let us write code that uses generic type parameters to reduce duplication but also specify to the compiler that we want the generic type to have particular behavior. The compiler can then use the trait bound information to check that all the concrete types used with our code provide the correct behavior. In dynamically typed languages, we would get an error at runtime if we called a method on a type that didn‚Äôt define the method. But Rust moves these errors to compile time so that we‚Äôre forced to fix the problems before our code is even able to run. Additionally, we don‚Äôt have to write code that checks for behavior at runtime, because we‚Äôve already checked at compile time. Doing so improves performance without having to give up the flexibility of generics.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Defining Shared Behavior with Traits ¬ª Using Trait Bounds to Conditionally Implement Methods","id":"180","title":"Using Trait Bounds to Conditionally Implement Methods"},"181":{"body":"Lifetimes are another kind of generic that we‚Äôve already been using. Rather than ensuring that a type has the behavior we want, lifetimes ensure that references are valid as long as we need them to be. One detail we didn‚Äôt discuss in the ‚ÄúReferences and Borrowing‚Äù section in Chapter 4 is that every reference in Rust has a lifetime, which is the scope for which that reference is valid. Most of the time, lifetimes are implicit and inferred, just like most of the time, types are inferred. We are only required to annotate types when multiple types are possible. In a similar way, we must annotate lifetimes when the lifetimes of references could be related in a few different ways. Rust requires us to annotate the relationships using generic lifetime parameters to ensure that the actual references used at runtime will definitely be valid. Annotating lifetimes is not even a concept most other programming languages have, so this is going to feel unfamiliar. Although we won‚Äôt cover lifetimes in their entirety in this chapter, we‚Äôll discuss common ways you might encounter lifetime syntax so that you can get comfortable with the concept.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Validating References with Lifetimes","id":"181","title":"Validating References with Lifetimes"},"182":{"body":"The main aim of lifetimes is to prevent dangling references, which, if they were allowed to exist, would cause a program to reference data other than the data it‚Äôs intended to reference. Consider the program in Listing 10-16, which has an outer scope and an inner scope. fn main() { let r; { let x = 5; r = &x; } println!(\\"r: {r}\\");\\n} Listing 10-16: An attempt to use a reference whose value has gone out of scope Note: The examples in Listings 10-16, 10-17, and 10-23 declare variables without giving them an initial value, so the variable name exists in the outer scope. At first glance, this might appear to be in conflict with Rust having no null values. However, if we try to use a variable before giving it a value, we‚Äôll get a compile-time error, which shows that indeed Rust does not allow null values. The outer scope declares a variable named r with no initial value, and the inner scope declares a variable named x with the initial value of 5. Inside the inner scope, we attempt to set the value of r as a reference to x. Then, the inner scope ends, and we attempt to print the value in r. This code won‚Äôt compile, because the value that r is referring to has gone out of scope before we try to use it. Here is the error message: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0597]: `x` does not live long enough --> src/main.rs:6:13 |\\n5 | let x = 5; | - binding `x` declared here\\n6 | r = &x; | ^^ borrowed value does not live long enough\\n7 | } | - `x` dropped here while still borrowed\\n8 |\\n9 | println!(\\"r: {r}\\"); | --- borrow later used here For more information about this error, try `rustc --explain E0597`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error The error message says that the variable x ‚Äúdoes not live long enough.‚Äù The reason is that x will be out of scope when the inner scope ends on line 7. But r is still valid for the outer scope; because its scope is larger, we say that it ‚Äúlives longer.‚Äù If Rust allowed this code to work, r would be referencing memory that was deallocated when x went out of scope, and anything we tried to do with r wouldn‚Äôt work correctly. So, how does Rust determine that this code is invalid? It uses a borrow checker.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Dangling References","id":"182","title":"Dangling References"},"183":{"body":"The Rust compiler has a borrow checker that compares scopes to determine whether all borrows are valid. Listing 10-17 shows the same code as Listing 10-16 but with annotations showing the lifetimes of the variables. fn main() { let r; // ---------+-- \'a // | { // | let x = 5; // -+-- \'b | r = &x; // | | } // -+ | // | println!(\\"r: {r}\\"); // |\\n} // ---------+ Listing 10-17: Annotations of the lifetimes of r and x, named \'a and \'b, respectively Here, we‚Äôve annotated the lifetime of r with \'a and the lifetime of x with \'b. As you can see, the inner \'b block is much smaller than the outer \'a lifetime block. At compile time, Rust compares the size of the two lifetimes and sees that r has a lifetime of \'a but that it refers to memory with a lifetime of \'b. The program is rejected because \'b is shorter than \'a: The subject of the reference doesn‚Äôt live as long as the reference. Listing 10-18 fixes the code so that it doesn‚Äôt have a dangling reference and it compiles without any errors. fn main() { let x = 5; // ----------+-- \'b // | let r = &x; // --+-- \'a | // | | println!(\\"r: {r}\\"); // | | // --+ |\\n} // ----------+ Listing 10-18: A valid reference because the data has a longer lifetime than the reference Here, x has the lifetime \'b, which in this case is larger than \'a. This means r can reference x because Rust knows that the reference in r will always be valid while x is valid. Now that you know where the lifetimes of references are and how Rust analyzes lifetimes to ensure that references will always be valid, let‚Äôs explore generic lifetimes in function parameters and return values.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª The Borrow Checker","id":"183","title":"The Borrow Checker"},"184":{"body":"We‚Äôll write a function that returns the longer of two string slices. This function will take two string slices and return a single string slice. After we‚Äôve implemented the longest function, the code in Listing 10-19 should print The longest string is abcd. Filename: src/main.rs fn main() { let string1 = String::from(\\"abcd\\"); let string2 = \\"xyz\\"; let result = longest(string1.as_str(), string2); println!(\\"The longest string is {result}\\");\\n} Listing 10-19: A main function that calls the longest function to find the longer of two string slices Note that we want the function to take string slices, which are references, rather than strings, because we don‚Äôt want the longest function to take ownership of its parameters. Refer to ‚ÄúString Slices as Parameters‚Äù in Chapter 4 for more discussion about why the parameters we use in Listing 10-19 are the ones we want. If we try to implement the longest function as shown in Listing 10-20, it won‚Äôt compile. Filename: src/main.rs # fn main() {\\n# let string1 = String::from(\\"abcd\\");\\n# let string2 = \\"xyz\\";\\n# # let result = longest(string1.as_str(), string2);\\n# println!(\\"The longest string is {result}\\");\\n# }\\n# fn longest(x: &str, y: &str) -> &str { if x.len() > y.len() { x } else { y }\\n} Listing 10-20: An implementation of the longest function that returns the longer of two string slices but does not yet compile Instead, we get the following error that talks about lifetimes: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0106]: missing lifetime specifier --> src/main.rs:9:33 |\\n9 | fn longest(x: &str, y: &str) -> &str { | ---- ---- ^ expected named lifetime parameter | = help: this function\'s return type contains a borrowed value, but the signature does not say whether it is borrowed from `x` or `y`\\nhelp: consider introducing a named lifetime parameter |\\n9 | fn longest<\'a>(x: &\'a str, y: &\'a str) -> &\'a str { | ++++ ++ ++ ++ For more information about this error, try `rustc --explain E0106`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error The help text reveals that the return type needs a generic lifetime parameter on it because Rust can‚Äôt tell whether the reference being returned refers to x or y. Actually, we don‚Äôt know either, because the if block in the body of this function returns a reference to x and the else block returns a reference to y! When we‚Äôre defining this function, we don‚Äôt know the concrete values that will be passed into this function, so we don‚Äôt know whether the if case or the else case will execute. We also don‚Äôt know the concrete lifetimes of the references that will be passed in, so we can‚Äôt look at the scopes as we did in Listings 10-17 and 10-18 to determine whether the reference we return will always be valid. The borrow checker can‚Äôt determine this either, because it doesn‚Äôt know how the lifetimes of x and y relate to the lifetime of the return value. To fix this error, we‚Äôll add generic lifetime parameters that define the relationship between the references so that the borrow checker can perform its analysis.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Generic Lifetimes in Functions","id":"184","title":"Generic Lifetimes in Functions"},"185":{"body":"Lifetime annotations don‚Äôt change how long any of the references live. Rather, they describe the relationships of the lifetimes of multiple references to each other without affecting the lifetimes. Just as functions can accept any type when the signature specifies a generic type parameter, functions can accept references with any lifetime by specifying a generic lifetime parameter. Lifetime annotations have a slightly unusual syntax: The names of lifetime parameters must start with an apostrophe (\') and are usually all lowercase and very short, like generic types. Most people use the name \'a for the first lifetime annotation. We place lifetime parameter annotations after the & of a reference, using a space to separate the annotation from the reference‚Äôs type. Here are some examples‚Äîa reference to an i32 without a lifetime parameter, a reference to an i32 that has a lifetime parameter named \'a, and a mutable reference to an i32 that also has the lifetime \'a: &i32 // a reference\\n&\'a i32 // a reference with an explicit lifetime\\n&\'a mut i32 // a mutable reference with an explicit lifetime One lifetime annotation by itself doesn‚Äôt have much meaning, because the annotations are meant to tell Rust how generic lifetime parameters of multiple references relate to each other. Let‚Äôs examine how the lifetime annotations relate to each other in the context of the longest function.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Lifetime Annotation Syntax","id":"185","title":"Lifetime Annotation Syntax"},"186":{"body":"To use lifetime annotations in function signatures, we need to declare the generic lifetime parameters inside angle brackets between the function name and the parameter list, just as we did with generic type parameters. We want the signature to express the following constraint: The returned reference will be valid as long as both of the parameters are valid. This is the relationship between lifetimes of the parameters and the return value. We‚Äôll name the lifetime \'a and then add it to each reference, as shown in Listing 10-21. Filename: src/main.rs # fn main() {\\n# let string1 = String::from(\\"abcd\\");\\n# let string2 = \\"xyz\\";\\n# # let result = longest(string1.as_str(), string2);\\n# println!(\\"The longest string is {result}\\");\\n# }\\n# fn longest<\'a>(x: &\'a str, y: &\'a str) -> &\'a str { if x.len() > y.len() { x } else { y }\\n} Listing 10-21: The longest function definition specifying that all the references in the signature must have the same lifetime \'a This code should compile and produce the result we want when we use it with the main function in Listing 10-19. The function signature now tells Rust that for some lifetime \'a, the function takes two parameters, both of which are string slices that live at least as long as lifetime \'a. The function signature also tells Rust that the string slice returned from the function will live at least as long as lifetime \'a. In practice, it means that the lifetime of the reference returned by the longest function is the same as the smaller of the lifetimes of the values referred to by the function arguments. These relationships are what we want Rust to use when analyzing this code. Remember, when we specify the lifetime parameters in this function signature, we‚Äôre not changing the lifetimes of any values passed in or returned. Rather, we‚Äôre specifying that the borrow checker should reject any values that don‚Äôt adhere to these constraints. Note that the longest function doesn‚Äôt need to know exactly how long x and y will live, only that some scope can be substituted for \'a that will satisfy this signature. When annotating lifetimes in functions, the annotations go in the function signature, not in the function body. The lifetime annotations become part of the contract of the function, much like the types in the signature. Having function signatures contain the lifetime contract means the analysis the Rust compiler does can be simpler. If there‚Äôs a problem with the way a function is annotated or the way it is called, the compiler errors can point to the part of our code and the constraints more precisely. If, instead, the Rust compiler made more inferences about what we intended the relationships of the lifetimes to be, the compiler might only be able to point to a use of our code many steps away from the cause of the problem. When we pass concrete references to longest, the concrete lifetime that is substituted for \'a is the part of the scope of x that overlaps with the scope of y. In other words, the generic lifetime \'a will get the concrete lifetime that is equal to the smaller of the lifetimes of x and y. Because we‚Äôve annotated the returned reference with the same lifetime parameter \'a, the returned reference will also be valid for the length of the smaller of the lifetimes of x and y. Let‚Äôs look at how the lifetime annotations restrict the longest function by passing in references that have different concrete lifetimes. Listing 10-22 is a straightforward example. Filename: src/main.rs fn main() { let string1 = String::from(\\"long string is long\\"); { let string2 = String::from(\\"xyz\\"); let result = longest(string1.as_str(), string2.as_str()); println!(\\"The longest string is {result}\\"); }\\n}\\n# # fn longest<\'a>(x: &\'a str, y: &\'a str) -> &\'a str {\\n# if x.len() > y.len() { x } else { y }\\n# } Listing 10-22: Using the longest function with references to String values that have different concrete lifetimes In this example, string1 is valid until the end of the outer scope, string2 is valid until the end of the inner scope, and result references something that is valid until the end of the inner scope. Run this code and you‚Äôll see that the borrow checker approves; it will compile and print The longest string is long string is long. Next, let‚Äôs try an example that shows that the lifetime of the reference in result must be the smaller lifetime of the two arguments. We‚Äôll move the declaration of the result variable outside the inner scope but leave the assignment of the value to the result variable inside the scope with string2. Then, we‚Äôll move the println! that uses result to outside the inner scope, after the inner scope has ended. The code in Listing 10-23 will not compile. Filename: src/main.rs fn main() { let string1 = String::from(\\"long string is long\\"); let result; { let string2 = String::from(\\"xyz\\"); result = longest(string1.as_str(), string2.as_str()); } println!(\\"The longest string is {result}\\");\\n}\\n# # fn longest<\'a>(x: &\'a str, y: &\'a str) -> &\'a str {\\n# if x.len() > y.len() { x } else { y }\\n# } Listing 10-23: Attempting to use result after string2 has gone out of scope When we try to compile this code, we get this error: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0597]: `string2` does not live long enough --> src/main.rs:6:44 |\\n5 | let string2 = String::from(\\"xyz\\"); | ------- binding `string2` declared here\\n6 | result = longest(string1.as_str(), string2.as_str()); | ^^^^^^^ borrowed value does not live long enough\\n7 | } | - `string2` dropped here while still borrowed\\n8 | println!(\\"The longest string is {result}\\"); | -------- borrow later used here For more information about this error, try `rustc --explain E0597`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error The error shows that for result to be valid for the println! statement, string2 would need to be valid until the end of the outer scope. Rust knows this because we annotated the lifetimes of the function parameters and return values using the same lifetime parameter \'a. As humans, we can look at this code and see that string1 is longer than string2, and therefore, result will contain a reference to string1. Because string1 has not gone out of scope yet, a reference to string1 will still be valid for the println! statement. However, the compiler can‚Äôt see that the reference is valid in this case. We‚Äôve told Rust that the lifetime of the reference returned by the longest function is the same as the smaller of the lifetimes of the references passed in. Therefore, the borrow checker disallows the code in Listing 10-23 as possibly having an invalid reference. Try designing more experiments that vary the values and lifetimes of the references passed in to the longest function and how the returned reference is used. Make hypotheses about whether or not your experiments will pass the borrow checker before you compile; then, check to see if you‚Äôre right!","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª In Function Signatures","id":"186","title":"In Function Signatures"},"187":{"body":"The way in which you need to specify lifetime parameters depends on what your function is doing. For example, if we changed the implementation of the longest function to always return the first parameter rather than the longest string slice, we wouldn‚Äôt need to specify a lifetime on the y parameter. The following code will compile: Filename: src/main.rs # fn main() {\\n# let string1 = String::from(\\"abcd\\");\\n# let string2 = \\"efghijklmnopqrstuvwxyz\\";\\n# # let result = longest(string1.as_str(), string2);\\n# println!(\\"The longest string is {result}\\");\\n# }\\n# fn longest<\'a>(x: &\'a str, y: &str) -> &\'a str { x\\n} We‚Äôve specified a lifetime parameter \'a for the parameter x and the return type, but not for the parameter y, because the lifetime of y does not have any relationship with the lifetime of x or the return value. When returning a reference from a function, the lifetime parameter for the return type needs to match the lifetime parameter for one of the parameters. If the reference returned does not refer to one of the parameters, it must refer to a value created within this function. However, this would be a dangling reference because the value will go out of scope at the end of the function. Consider this attempted implementation of the longest function that won‚Äôt compile: Filename: src/main.rs # fn main() {\\n# let string1 = String::from(\\"abcd\\");\\n# let string2 = \\"xyz\\";\\n# # let result = longest(string1.as_str(), string2);\\n# println!(\\"The longest string is {result}\\");\\n# }\\n# fn longest<\'a>(x: &str, y: &str) -> &\'a str { let result = String::from(\\"really long string\\"); result.as_str()\\n} Here, even though we‚Äôve specified a lifetime parameter \'a for the return type, this implementation will fail to compile because the return value lifetime is not related to the lifetime of the parameters at all. Here is the error message we get: $ cargo run Compiling chapter10 v0.1.0 (file:///projects/chapter10)\\nerror[E0515]: cannot return value referencing local variable `result` --> src/main.rs:11:5 |\\n11 | result.as_str() | ------^^^^^^^^^ | | | returns a value referencing data owned by the current function | `result` is borrowed here For more information about this error, try `rustc --explain E0515`.\\nerror: could not compile `chapter10` (bin \\"chapter10\\") due to 1 previous error The problem is that result goes out of scope and gets cleaned up at the end of the longest function. We‚Äôre also trying to return a reference to result from the function. There is no way we can specify lifetime parameters that would change the dangling reference, and Rust won‚Äôt let us create a dangling reference. In this case, the best fix would be to return an owned data type rather than a reference so that the calling function is then responsible for cleaning up the value. Ultimately, lifetime syntax is about connecting the lifetimes of various parameters and return values of functions. Once they‚Äôre connected, Rust has enough information to allow memory-safe operations and disallow operations that would create dangling pointers or otherwise violate memory safety.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Relationships","id":"187","title":"Relationships"},"188":{"body":"So far, the structs we‚Äôve defined all hold owned types. We can define structs to hold references, but in that case, we would need to add a lifetime annotation on every reference in the struct‚Äôs definition. Listing 10-24 has a struct named ImportantExcerpt that holds a string slice. Filename: src/main.rs struct ImportantExcerpt<\'a> { part: &\'a str,\\n} fn main() { let novel = String::from(\\"Call me Ishmael. Some years ago...\\"); let first_sentence = novel.split(\'.\').next().unwrap(); let i = ImportantExcerpt { part: first_sentence, };\\n} Listing 10-24: A struct that holds a reference, requiring a lifetime annotation This struct has the single field part that holds a string slice, which is a reference. As with generic data types, we declare the name of the generic lifetime parameter inside angle brackets after the name of the struct so that we can use the lifetime parameter in the body of the struct definition. This annotation means an instance of ImportantExcerpt can‚Äôt outlive the reference it holds in its part field. The main function here creates an instance of the ImportantExcerpt struct that holds a reference to the first sentence of the String owned by the variable novel. The data in novel exists before the ImportantExcerpt instance is created. In addition, novel doesn‚Äôt go out of scope until after the ImportantExcerpt goes out of scope, so the reference in the ImportantExcerpt instance is valid.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª In Struct Definitions","id":"188","title":"In Struct Definitions"},"189":{"body":"You‚Äôve learned that every reference has a lifetime and that you need to specify lifetime parameters for functions or structs that use references. However, we had a function in Listing 4-9, shown again in Listing 10-25, that compiled without lifetime annotations. Filename: src/lib.rs fn first_word(s: &str) -> &str { let bytes = s.as_bytes(); for (i, &item) in bytes.iter().enumerate() { if item == b\' \' { return &s[0..i]; } } &s[..]\\n}\\n# # fn main() {\\n# let my_string = String::from(\\"hello world\\");\\n# # // first_word works on slices of `String`s\\n# let word = first_word(&my_string[..]);\\n# # let my_string_literal = \\"hello world\\";\\n# # // first_word works on slices of string literals\\n# let word = first_word(&my_string_literal[..]);\\n# # // Because string literals *are* string slices already,\\n# // this works too, without the slice syntax!\\n# let word = first_word(my_string_literal);\\n# } Listing 10-25: A function we defined in Listing 4-9 that compiled without lifetime annotations, even though the parameter and return type are references The reason this function compiles without lifetime annotations is historical: In early versions (pre-1.0) of Rust, this code wouldn‚Äôt have compiled, because every reference needed an explicit lifetime. At that time, the function signature would have been written like this: fn first_word<\'a>(s: &\'a str) -> &\'a str { After writing a lot of Rust code, the Rust team found that Rust programmers were entering the same lifetime annotations over and over in particular situations. These situations were predictable and followed a few deterministic patterns. The developers programmed these patterns into the compiler‚Äôs code so that the borrow checker could infer the lifetimes in these situations and wouldn‚Äôt need explicit annotations. This piece of Rust history is relevant because it‚Äôs possible that more deterministic patterns will emerge and be added to the compiler. In the future, even fewer lifetime annotations might be required. The patterns programmed into Rust‚Äôs analysis of references are called the lifetime elision rules . These aren‚Äôt rules for programmers to follow; they‚Äôre a set of particular cases that the compiler will consider, and if your code fits these cases, you don‚Äôt need to write the lifetimes explicitly. The elision rules don‚Äôt provide full inference. If there is still ambiguity about what lifetimes the references have after Rust applies the rules, the compiler won‚Äôt guess what the lifetime of the remaining references should be. Instead of guessing, the compiler will give you an error that you can resolve by adding the lifetime annotations. Lifetimes on function or method parameters are called input lifetimes , and lifetimes on return values are called output lifetimes . The compiler uses three rules to figure out the lifetimes of the references when there aren‚Äôt explicit annotations. The first rule applies to input lifetimes, and the second and third rules apply to output lifetimes. If the compiler gets to the end of the three rules and there are still references for which it can‚Äôt figure out lifetimes, the compiler will stop with an error. These rules apply to fn definitions as well as impl blocks. The first rule is that the compiler assigns a lifetime parameter to each parameter that‚Äôs a reference. In other words, a function with one parameter gets one lifetime parameter: fn foo<\'a>(x: &\'a i32); a function with two parameters gets two separate lifetime parameters: fn foo<\'a, \'b>(x: &\'a i32, y: &\'b i32); and so on. The second rule is that, if there is exactly one input lifetime parameter, that lifetime is assigned to all output lifetime parameters: fn foo<\'a>(x: &\'a i32) -> &\'a i32. The third rule is that, if there are multiple input lifetime parameters, but one of them is &self or &mut self because this is a method, the lifetime of self is assigned to all output lifetime parameters. This third rule makes methods much nicer to read and write because fewer symbols are necessary. Let‚Äôs pretend we‚Äôre the compiler. We‚Äôll apply these rules to figure out the lifetimes of the references in the signature of the first_word function in Listing 10-25. The signature starts without any lifetimes associated with the references: fn first_word(s: &str) -> &str { Then, the compiler applies the first rule, which specifies that each parameter gets its own lifetime. We‚Äôll call it \'a as usual, so now the signature is this: fn first_word<\'a>(s: &\'a str) -> &str { The second rule applies because there is exactly one input lifetime. The second rule specifies that the lifetime of the one input parameter gets assigned to the output lifetime, so the signature is now this: fn first_word<\'a>(s: &\'a str) -> &\'a str { Now all the references in this function signature have lifetimes, and the compiler can continue its analysis without needing the programmer to annotate the lifetimes in this function signature. Let‚Äôs look at another example, this time using the longest function that had no lifetime parameters when we started working with it in Listing 10-20: fn longest(x: &str, y: &str) -> &str { Let‚Äôs apply the first rule: Each parameter gets its own lifetime. This time we have two parameters instead of one, so we have two lifetimes: fn longest<\'a, \'b>(x: &\'a str, y: &\'b str) -> &str { You can see that the second rule doesn‚Äôt apply, because there is more than one input lifetime. The third rule doesn‚Äôt apply either, because longest is a function rather than a method, so none of the parameters are self. After working through all three rules, we still haven‚Äôt figured out what the return type‚Äôs lifetime is. This is why we got an error trying to compile the code in Listing 10-20: The compiler worked through the lifetime elision rules but still couldn‚Äôt figure out all the lifetimes of the references in the signature. Because the third rule really only applies in method signatures, we‚Äôll look at lifetimes in that context next to see why the third rule means we don‚Äôt have to annotate lifetimes in method signatures very often.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Lifetime Elision","id":"189","title":"Lifetime Elision"},"19":{"body":"The installation of Rust also includes a local copy of the documentation so that you can read it offline. Run rustup doc to open the local documentation in your browser. Any time a type or function is provided by the standard library and you‚Äôre not sure what it does or how to use it, use the application programming interface (API) documentation to find out!","breadcrumbs":"Getting Started ¬ª Installation ¬ª Reading the Local Documentation","id":"19","title":"Reading the Local Documentation"},"190":{"body":"When we implement methods on a struct with lifetimes, we use the same syntax as that of generic type parameters, as shown in Listing 10-11. Where we declare and use the lifetime parameters depends on whether they‚Äôre related to the struct fields or the method parameters and return values. Lifetime names for struct fields always need to be declared after the impl keyword and then used after the struct‚Äôs name because those lifetimes are part of the struct‚Äôs type. In method signatures inside the impl block, references might be tied to the lifetime of references in the struct‚Äôs fields, or they might be independent. In addition, the lifetime elision rules often make it so that lifetime annotations aren‚Äôt necessary in method signatures. Let‚Äôs look at some examples using the struct named ImportantExcerpt that we defined in Listing 10-24. First, we‚Äôll use a method named level whose only parameter is a reference to self and whose return value is an i32, which is not a reference to anything: # struct ImportantExcerpt<\'a> {\\n# part: &\'a str,\\n# }\\n# impl<\'a> ImportantExcerpt<\'a> { fn level(&self) -> i32 { 3 }\\n}\\n# # impl<\'a> ImportantExcerpt<\'a> {\\n# fn announce_and_return_part(&self, announcement: &str) -> &str {\\n# println!(\\"Attention please: {announcement}\\");\\n# self.part\\n# }\\n# }\\n# # fn main() {\\n# let novel = String::from(\\"Call me Ishmael. Some years ago...\\");\\n# let first_sentence = novel.split(\'.\').next().unwrap();\\n# let i = ImportantExcerpt {\\n# part: first_sentence,\\n# };\\n# } The lifetime parameter declaration after impl and its use after the type name are required, but because of the first elision rule, we‚Äôre not required to annotate the lifetime of the reference to self. Here is an example where the third lifetime elision rule applies: # struct ImportantExcerpt<\'a> {\\n# part: &\'a str,\\n# }\\n# # impl<\'a> ImportantExcerpt<\'a> {\\n# fn level(&self) -> i32 {\\n# 3\\n# }\\n# }\\n# impl<\'a> ImportantExcerpt<\'a> { fn announce_and_return_part(&self, announcement: &str) -> &str { println!(\\"Attention please: {announcement}\\"); self.part }\\n}\\n# # fn main() {\\n# let novel = String::from(\\"Call me Ishmael. Some years ago...\\");\\n# let first_sentence = novel.split(\'.\').next().unwrap();\\n# let i = ImportantExcerpt {\\n# part: first_sentence,\\n# };\\n# } There are two input lifetimes, so Rust applies the first lifetime elision rule and gives both &self and announcement their own lifetimes. Then, because one of the parameters is &self, the return type gets the lifetime of &self, and all lifetimes have been accounted for.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª In Method Definitions","id":"190","title":"In Method Definitions"},"191":{"body":"One special lifetime we need to discuss is \'static, which denotes that the affected reference can live for the entire duration of the program. All string literals have the \'static lifetime, which we can annotate as follows: let s: &\'static str = \\"I have a static lifetime.\\"; The text of this string is stored directly in the program‚Äôs binary, which is always available. Therefore, the lifetime of all string literals is \'static. You might see suggestions in error messages to use the \'static lifetime. But before specifying \'static as the lifetime for a reference, think about whether or not the reference you have actually lives the entire lifetime of your program, and whether you want it to. Most of the time, an error message suggesting the \'static lifetime results from attempting to create a dangling reference or a mismatch of the available lifetimes. In such cases, the solution is to fix those problems, not to specify the \'static lifetime.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª The Static Lifetime","id":"191","title":"The Static Lifetime"},"192":{"body":"Let‚Äôs briefly look at the syntax of specifying generic type parameters, trait bounds, and lifetimes all in one function! # fn main() {\\n# let string1 = String::from(\\"abcd\\");\\n# let string2 = \\"xyz\\";\\n# # let result = longest_with_an_announcement(\\n# string1.as_str(),\\n# string2,\\n# \\"Today is someone\'s birthday!\\",\\n# );\\n# println!(\\"The longest string is {result}\\");\\n# }\\n# use std::fmt::Display; fn longest_with_an_announcement<\'a, T>( x: &\'a str, y: &\'a str, ann: T,\\n) -> &\'a str\\nwhere T: Display,\\n{ println!(\\"Announcement! {ann}\\"); if x.len() > y.len() { x } else { y }\\n} This is the longest function from Listing 10-21 that returns the longer of two string slices. But now it has an extra parameter named ann of the generic type T, which can be filled in by any type that implements the Display trait as specified by the where clause. This extra parameter will be printed using {}, which is why the Display trait bound is necessary. Because lifetimes are a type of generic, the declarations of the lifetime parameter \'a and the generic type parameter T go in the same list inside the angle brackets after the function name.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Generic Type Parameters, Trait Bounds, and Lifetimes","id":"192","title":"Generic Type Parameters, Trait Bounds, and Lifetimes"},"193":{"body":"We covered a lot in this chapter! Now that you know about generic type parameters, traits and trait bounds, and generic lifetime parameters, you‚Äôre ready to write code without repetition that works in many different situations. Generic type parameters let you apply the code to different types. Traits and trait bounds ensure that even though the types are generic, they‚Äôll have the behavior the code needs. You learned how to use lifetime annotations to ensure that this flexible code won‚Äôt have any dangling references. And all of this analysis happens at compile time, which doesn‚Äôt affect runtime performance! Believe it or not, there is much more to learn on the topics we discussed in this chapter: Chapter 18 discusses trait objects, which are another way to use traits. There are also more complex scenarios involving lifetime annotations that you will only need in very advanced scenarios; for those, you should read the Rust Reference . But next, you‚Äôll learn how to write tests in Rust so that you can make sure your code is working the way it should.","breadcrumbs":"Generic Types, Traits, and Lifetimes ¬ª Validating References with Lifetimes ¬ª Summary","id":"193","title":"Summary"},"194":{"body":"In his 1972 essay ‚ÄúThe Humble Programmer,‚Äù Edsger W. Dijkstra said that ‚Äúprogram testing can be a very effective way to show the presence of bugs, but it is hopelessly inadequate for showing their absence.‚Äù That doesn‚Äôt mean we shouldn‚Äôt try to test as much as we can! Correctness in our programs is the extent to which our code does what we intend it to do. Rust is designed with a high degree of concern about the correctness of programs, but correctness is complex and not easy to prove. Rust‚Äôs type system shoulders a huge part of this burden, but the type system cannot catch everything. As such, Rust includes support for writing automated software tests. Say we write a function add_two that adds 2 to whatever number is passed to it. This function‚Äôs signature accepts an integer as a parameter and returns an integer as a result. When we implement and compile that function, Rust does all the type checking and borrow checking that you‚Äôve learned so far to ensure that, for instance, we aren‚Äôt passing a String value or an invalid reference to this function. But Rust can‚Äôt check that this function will do precisely what we intend, which is return the parameter plus 2 rather than, say, the parameter plus 10 or the parameter minus 50! That‚Äôs where tests come in. We can write tests that assert, for example, that when we pass 3 to the add_two function, the returned value is 5. We can run these tests whenever we make changes to our code to make sure any existing correct behavior has not changed. Testing is a complex skill: Although we can‚Äôt cover in one chapter every detail about how to write good tests, in this chapter we will discuss the mechanics of Rust‚Äôs testing facilities. We‚Äôll talk about the annotations and macros available to you when writing your tests, the default behavior and options provided for running your tests, and how to organize tests into unit tests and integration tests.","breadcrumbs":"Writing Automated Tests ¬ª Writing Automated Tests","id":"194","title":"Writing Automated Tests"},"195":{"body":"Tests are Rust functions that verify that the non-test code is functioning in the expected manner. The bodies of test functions typically perform these three actions: Set up any needed data or state. Run the code you want to test. Assert that the results are what you expect. Let‚Äôs look at the features Rust provides specifically for writing tests that take these actions, which include the test attribute, a few macros, and the should_panic attribute.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª How to Write Tests","id":"195","title":"How to Write Tests"},"196":{"body":"At its simplest, a test in Rust is a function that‚Äôs annotated with the test attribute. Attributes are metadata about pieces of Rust code; one example is the derive attribute we used with structs in Chapter 5. To change a function into a test function, add #[test] on the line before fn. When you run your tests with the cargo test command, Rust builds a test runner binary that runs the annotated functions and reports on whether each test function passes or fails. Whenever we make a new library project with Cargo, a test module with a test function in it is automatically generated for us. This module gives you a template for writing your tests so that you don‚Äôt have to look up the exact structure and syntax every time you start a new project. You can add as many additional test functions and as many test modules as you want! We‚Äôll explore some aspects of how tests work by experimenting with the template test before we actually test any code. Then, we‚Äôll write some real-world tests that call some code that we‚Äôve written and assert that its behavior is correct. Let‚Äôs create a new library project called adder that will add two numbers: $ cargo new adder --lib Created library `adder` project\\n$ cd adder The contents of the src/lib.rs file in your adder library should look like Listing 11-1. Filename: src/lib.rs pub fn add(left: u64, right: u64) -> u64 { left + right\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_works() { let result = add(2, 2); assert_eq!(result, 4); }\\n} Listing 11-1: The code generated automatically by cargo new The file starts with an example add function so that we have something to test. For now, let‚Äôs focus solely on the it_works function. Note the #[test] annotation: This attribute indicates this is a test function, so the test runner knows to treat this function as a test. We might also have non-test functions in the tests module to help set up common scenarios or perform common operations, so we always need to indicate which functions are tests. The example function body uses the assert_eq! macro to assert that result, which contains the result of calling add with 2 and 2, equals 4. This assertion serves as an example of the format for a typical test. Let‚Äôs run it to see that this test passes. The cargo test command runs all tests in our project, as shown in Listing 11-2. $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.57s Running unittests src/lib.rs (target/debug/deps/adder-01ad14159ff659ab) running 1 test\\ntest tests::it_works ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Listing 11-2: The output from running the automatically generated test Cargo compiled and ran the test. We see the line running 1 test. The next line shows the name of the generated test function, called tests::it_works, and that the result of running that test is ok. The overall summary test result: ok. means that all the tests passed, and the portion that reads 1 passed; 0 failed totals the number of tests that passed or failed. It‚Äôs possible to mark a test as ignored so that it doesn‚Äôt run in a particular instance; we‚Äôll cover that in the ‚ÄúIgnoring Tests Unless Specifically Requested‚Äù section later in this chapter. Because we haven‚Äôt done that here, the summary shows 0 ignored. We can also pass an argument to the cargo test command to run only tests whose name matches a string; this is called filtering , and we‚Äôll cover it in the ‚ÄúRunning a Subset of Tests by Name‚Äù section. Here, we haven‚Äôt filtered the tests being run, so the end of the summary shows 0 filtered out. The 0 measured statistic is for benchmark tests that measure performance. Benchmark tests are, as of this writing, only available in nightly Rust. See the documentation about benchmark tests to learn more. The next part of the test output starting at Doc-tests adder is for the results of any documentation tests. We don‚Äôt have any documentation tests yet, but Rust can compile any code examples that appear in our API documentation. This feature helps keep your docs and your code in sync! We‚Äôll discuss how to write documentation tests in the ‚ÄúDocumentation Comments as Tests‚Äù section of Chapter 14. For now, we‚Äôll ignore the Doc-tests output. Let‚Äôs start to customize the test to our own needs. First, change the name of the it_works function to a different name, such as exploration, like so: Filename: src/lib.rs pub fn add(left: u64, right: u64) -> u64 { left + right\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn exploration() { let result = add(2, 2); assert_eq!(result, 4); }\\n} Then, run cargo test again. The output now shows exploration instead of it_works: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.59s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::exploration ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Now we‚Äôll add another test, but this time we‚Äôll make a test that fails! Tests fail when something in the test function panics. Each test is run in a new thread, and when the main thread sees that a test thread has died, the test is marked as failed. In Chapter 9, we talked about how the simplest way to panic is to call the panic! macro. Enter the new test as a function named another, so your src/lib.rs file looks like Listing 11-3. Filename: src/lib.rs pub fn add(left: u64, right: u64) -> u64 { left + right\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn exploration() { let result = add(2, 2); assert_eq!(result, 4); } #[test] fn another() { panic!(\\"Make this test fail\\"); }\\n} Listing 11-3: Adding a second test that will fail because we call the panic! macro Run the tests again using cargo test. The output should look like Listing 11-4, which shows that our exploration test passed and another failed. $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.72s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 2 tests\\ntest tests::another ... FAILED\\ntest tests::exploration ... ok failures: ---- tests::another stdout ---- thread \'tests::another\' panicked at src/lib.rs:17:9:\\nMake this test fail\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::another test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` Listing 11-4: Test results when one test passes and one test fails Instead of ok, the line test tests::another shows FAILED. Two new sections appear between the individual results and the summary: The first displays the detailed reason for each test failure. In this case, we get the details that tests::another failed because it panicked with the message Make this test fail on line 17 in the src/lib.rs file. The next section lists just the names of all the failing tests, which is useful when there are lots of tests and lots of detailed failing test output. We can use the name of a failing test to run just that test to debug it more easily; we‚Äôll talk more about ways to run tests in the ‚ÄúControlling How Tests Are Run‚Äù section. The summary line displays at the end: Overall, our test result is FAILED. We had one test pass and one test fail. Now that you‚Äôve seen what the test results look like in different scenarios, let‚Äôs look at some macros other than panic! that are useful in tests.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Structuring Test Functions","id":"196","title":"Structuring Test Functions"},"197":{"body":"The assert! macro, provided by the standard library, is useful when you want to ensure that some condition in a test evaluates to true. We give the assert! macro an argument that evaluates to a Boolean. If the value is true, nothing happens and the test passes. If the value is false, the assert! macro calls panic! to cause the test to fail. Using the assert! macro helps us check that our code is functioning in the way we intend. In Chapter 5, Listing 5-15, we used a Rectangle struct and a can_hold method, which are repeated here in Listing 11-5. Let‚Äôs put this code in the src/lib.rs file, then write some tests for it using the assert! macro. Filename: src/lib.rs #[derive(Debug)]\\nstruct Rectangle { width: u32, height: u32,\\n} impl Rectangle { fn can_hold(&self, other: &Rectangle) -> bool { self.width > other.width && self.height > other.height }\\n} Listing 11-5: The Rectangle struct and its can_hold method from Chapter 5 The can_hold method returns a Boolean, which means it‚Äôs a perfect use case for the assert! macro. In Listing 11-6, we write a test that exercises the can_hold method by creating a Rectangle instance that has a width of 8 and a height of 7 and asserting that it can hold another Rectangle instance that has a width of 5 and a height of 1. Filename: src/lib.rs # #[derive(Debug)]\\n# struct Rectangle {\\n# width: u32,\\n# height: u32,\\n# }\\n# # impl Rectangle {\\n# fn can_hold(&self, other: &Rectangle) -> bool {\\n# self.width > other.width && self.height > other.height\\n# }\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; #[test] fn larger_can_hold_smaller() { let larger = Rectangle { width: 8, height: 7, }; let smaller = Rectangle { width: 5, height: 1, }; assert!(larger.can_hold(&smaller)); }\\n} Listing 11-6: A test for can_hold that checks whether a larger rectangle can indeed hold a smaller rectangle Note the use super::*; line inside the tests module. The tests module is a regular module that follows the usual visibility rules we covered in Chapter 7 in the ‚ÄúPaths for Referring to an Item in the Module Tree‚Äù section. Because the tests module is an inner module, we need to bring the code under test in the outer module into the scope of the inner module. We use a glob here, so anything we define in the outer module is available to this tests module. We‚Äôve named our test larger_can_hold_smaller, and we‚Äôve created the two Rectangle instances that we need. Then, we called the assert! macro and passed it the result of calling larger.can_hold(&smaller). This expression is supposed to return true, so our test should pass. Let‚Äôs find out! $ cargo test Compiling rectangle v0.1.0 (file:///projects/rectangle) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.66s Running unittests src/lib.rs (target/debug/deps/rectangle-6584c4561e48942e) running 1 test\\ntest tests::larger_can_hold_smaller ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests rectangle running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s It does pass! Let‚Äôs add another test, this time asserting that a smaller rectangle cannot hold a larger rectangle: Filename: src/lib.rs # #[derive(Debug)]\\n# struct Rectangle {\\n# width: u32,\\n# height: u32,\\n# }\\n# # impl Rectangle {\\n# fn can_hold(&self, other: &Rectangle) -> bool {\\n# self.width > other.width && self.height > other.height\\n# }\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; #[test] fn larger_can_hold_smaller() { // --snip--\\n# let larger = Rectangle {\\n# width: 8,\\n# height: 7,\\n# };\\n# let smaller = Rectangle {\\n# width: 5,\\n# height: 1,\\n# };\\n# # assert!(larger.can_hold(&smaller)); } #[test] fn smaller_cannot_hold_larger() { let larger = Rectangle { width: 8, height: 7, }; let smaller = Rectangle { width: 5, height: 1, }; assert!(!smaller.can_hold(&larger)); }\\n} Because the correct result of the can_hold function in this case is false, we need to negate that result before we pass it to the assert! macro. As a result, our test will pass if can_hold returns false: $ cargo test Compiling rectangle v0.1.0 (file:///projects/rectangle) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.66s Running unittests src/lib.rs (target/debug/deps/rectangle-6584c4561e48942e) running 2 tests\\ntest tests::larger_can_hold_smaller ... ok\\ntest tests::smaller_cannot_hold_larger ... ok test result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests rectangle running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Two tests that pass! Now let‚Äôs see what happens to our test results when we introduce a bug in our code. We‚Äôll change the implementation of the can_hold method by replacing the greater-than sign (>) with a less-than sign (<) when it compares the widths: # #[derive(Debug)]\\n# struct Rectangle {\\n# width: u32,\\n# height: u32,\\n# }\\n# // --snip--\\nimpl Rectangle { fn can_hold(&self, other: &Rectangle) -> bool { self.width < other.width && self.height > other.height }\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn larger_can_hold_smaller() {\\n# let larger = Rectangle {\\n# width: 8,\\n# height: 7,\\n# };\\n# let smaller = Rectangle {\\n# width: 5,\\n# height: 1,\\n# };\\n# # assert!(larger.can_hold(&smaller));\\n# }\\n# # #[test]\\n# fn smaller_cannot_hold_larger() {\\n# let larger = Rectangle {\\n# width: 8,\\n# height: 7,\\n# };\\n# let smaller = Rectangle {\\n# width: 5,\\n# height: 1,\\n# };\\n# # assert!(!smaller.can_hold(&larger));\\n# }\\n# } Running the tests now produces the following: $ cargo test Compiling rectangle v0.1.0 (file:///projects/rectangle) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.66s Running unittests src/lib.rs (target/debug/deps/rectangle-6584c4561e48942e) running 2 tests\\ntest tests::larger_can_hold_smaller ... FAILED\\ntest tests::smaller_cannot_hold_larger ... ok failures: ---- tests::larger_can_hold_smaller stdout ---- thread \'tests::larger_can_hold_smaller\' panicked at src/lib.rs:28:9:\\nassertion failed: larger.can_hold(&smaller)\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::larger_can_hold_smaller test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` Our tests caught the bug! Because larger.width is 8 and smaller.width is 5, the comparison of the widths in can_hold now returns false: 8 is not less than 5.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Checking Results with assert!","id":"197","title":"Checking Results with assert!"},"198":{"body":"A common way to verify functionality is to test for equality between the result of the code under test and the value you expect the code to return. You could do this by using the assert! macro and passing it an expression using the == operator. However, this is such a common test that the standard library provides a pair of macros‚Äîassert_eq! and assert_ne!‚Äîto perform this test more conveniently. These macros compare two arguments for equality or inequality, respectively. They‚Äôll also print the two values if the assertion fails, which makes it easier to see why the test failed; conversely, the assert! macro only indicates that it got a false value for the == expression, without printing the values that led to the false value. In Listing 11-7, we write a function named add_two that adds 2 to its parameter, and then we test this function using the assert_eq! macro. Filename: src/lib.rs pub fn add_two(a: u64) -> u64 { a + 2\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_adds_two() { let result = add_two(2); assert_eq!(result, 4); }\\n} Listing 11-7: Testing the function add_two using the assert_eq! macro Let‚Äôs check that it passes! $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.58s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::it_adds_two ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s We create a variable named result that holds the result of calling add_two(2). Then, we pass result and 4 as the arguments to the assert_eq! macro. The output line for this test is test tests::it_adds_two ... ok, and the ok text indicates that our test passed! Let‚Äôs introduce a bug into our code to see what assert_eq! looks like when it fails. Change the implementation of the add_two function to instead add 3: pub fn add_two(a: u64) -> u64 { a + 3\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn it_adds_two() {\\n# let result = add_two(2);\\n# assert_eq!(result, 4);\\n# }\\n# } Run the tests again: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.61s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::it_adds_two ... FAILED failures: ---- tests::it_adds_two stdout ---- thread \'tests::it_adds_two\' panicked at src/lib.rs:12:9:\\nassertion `left == right` failed left: 5 right: 4\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::it_adds_two test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` Our test caught the bug! The tests::it_adds_two test failed, and the message tells us that the assertion that failed was left == right and what the left and right values are. This message helps us start debugging: The left argument, where we had the result of calling add_two(2), was 5, but the right argument was 4. You can imagine that this would be especially helpful when we have a lot of tests going on. Note that in some languages and test frameworks, the parameters to equality assertion functions are called expected and actual, and the order in which we specify the arguments matters. However, in Rust, they‚Äôre called left and right, and the order in which we specify the value we expect and the value the code produces doesn‚Äôt matter. We could write the assertion in this test as assert_eq!(4, result), which would result in the same failure message that displays assertion `left == right` failed. The assert_ne! macro will pass if the two values we give it are not equal and will fail if they are equal. This macro is most useful for cases when we‚Äôre not sure what a value will be, but we know what the value definitely shouldn‚Äôt be. For example, if we‚Äôre testing a function that is guaranteed to change its input in some way, but the way in which the input is changed depends on the day of the week that we run our tests, the best thing to assert might be that the output of the function is not equal to the input. Under the surface, the assert_eq! and assert_ne! macros use the operators == and !=, respectively. When the assertions fail, these macros print their arguments using debug formatting, which means the values being compared must implement the PartialEq and Debug traits. All primitive types and most of the standard library types implement these traits. For structs and enums that you define yourself, you‚Äôll need to implement PartialEq to assert equality of those types. You‚Äôll also need to implement Debug to print the values when the assertion fails. Because both traits are derivable traits, as mentioned in Listing 5-12 in Chapter 5, this is usually as straightforward as adding the #[derive(PartialEq, Debug)] annotation to your struct or enum definition. See Appendix C, ‚ÄúDerivable Traits,‚Äù for more details about these and other derivable traits.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Testing Equality with assert_eq! and assert_ne!","id":"198","title":"Testing Equality with assert_eq! and assert_ne!"},"199":{"body":"You can also add a custom message to be printed with the failure message as optional arguments to the assert!, assert_eq!, and assert_ne! macros. Any arguments specified after the required arguments are passed along to the format! macro (discussed in ‚ÄúConcatenating with + or format!‚Äù in Chapter 8), so you can pass a format string that contains {} placeholders and values to go in those placeholders. Custom messages are useful for documenting what an assertion means; when a test fails, you‚Äôll have a better idea of what the problem is with the code. For example, let‚Äôs say we have a function that greets people by name and we want to test that the name we pass into the function appears in the output: Filename: src/lib.rs pub fn greeting(name: &str) -> String { format!(\\"Hello {name}!\\")\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn greeting_contains_name() { let result = greeting(\\"Carol\\"); assert!(result.contains(\\"Carol\\")); }\\n} The requirements for this program haven‚Äôt been agreed upon yet, and we‚Äôre pretty sure the Hello text at the beginning of the greeting will change. We decided we don‚Äôt want to have to update the test when the requirements change, so instead of checking for exact equality to the value returned from the greeting function, we‚Äôll just assert that the output contains the text of the input parameter. Now let‚Äôs introduce a bug into this code by changing greeting to exclude name to see what the default test failure looks like: pub fn greeting(name: &str) -> String { String::from(\\"Hello!\\")\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn greeting_contains_name() {\\n# let result = greeting(\\"Carol\\");\\n# assert!(result.contains(\\"Carol\\"));\\n# }\\n# } Running this test produces the following: $ cargo test Compiling greeter v0.1.0 (file:///projects/greeter) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.91s Running unittests src/lib.rs (target/debug/deps/greeter-170b942eb5bf5e3a) running 1 test\\ntest tests::greeting_contains_name ... FAILED failures: ---- tests::greeting_contains_name stdout ---- thread \'tests::greeting_contains_name\' panicked at src/lib.rs:12:9:\\nassertion failed: result.contains(\\"Carol\\")\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::greeting_contains_name test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` This result just indicates that the assertion failed and which line the assertion is on. A more useful failure message would print the value from the greeting function. Let‚Äôs add a custom failure message composed of a format string with a placeholder filled in with the actual value we got from the greeting function: # pub fn greeting(name: &str) -> String {\\n# String::from(\\"Hello!\\")\\n# }\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# #[test] fn greeting_contains_name() { let result = greeting(\\"Carol\\"); assert!( result.contains(\\"Carol\\"), \\"Greeting did not contain name, value was `{result}`\\" ); }\\n# } Now when we run the test, we‚Äôll get a more informative error message: $ cargo test Compiling greeter v0.1.0 (file:///projects/greeter) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.93s Running unittests src/lib.rs (target/debug/deps/greeter-170b942eb5bf5e3a) running 1 test\\ntest tests::greeting_contains_name ... FAILED failures: ---- tests::greeting_contains_name stdout ---- thread \'tests::greeting_contains_name\' panicked at src/lib.rs:12:9:\\nGreeting did not contain name, value was `Hello!`\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::greeting_contains_name test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` We can see the value we actually got in the test output, which would help us debug what happened instead of what we were expecting to happen.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Adding Custom Failure Messages","id":"199","title":"Adding Custom Failure Messages"},"2":{"body":"Note: This edition of the book is the same as The Rust Programming Language available in print and ebook format from No Starch Press . Welcome to The Rust Programming Language , an introductory book about Rust. The Rust programming language helps you write faster, more reliable software. High-level ergonomics and low-level control are often at odds in programming language design; Rust challenges that conflict. Through balancing powerful technical capacity and a great developer experience, Rust gives you the option to control low-level details (such as memory usage) without all the hassle traditionally associated with such control.","breadcrumbs":"Introduction ¬ª Introduction","id":"2","title":"Introduction"},"20":{"body":"This book makes no assumptions about what tools you use to author Rust code. Just about any text editor will get the job done! However, many text editors and integrated development environments (IDEs) have built-in support for Rust. You can always find a fairly current list of many editors and IDEs on the tools page on the Rust website.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Using Text Editors and IDEs","id":"20","title":"Using Text Editors and IDEs"},"200":{"body":"In addition to checking return values, it‚Äôs important to check that our code handles error conditions as we expect. For example, consider the Guess type that we created in Chapter 9, Listing 9-13. Other code that uses Guess depends on the guarantee that Guess instances will contain only values between 1 and 100. We can write a test that ensures that attempting to create a Guess instance with a value outside that range panics. We do this by adding the attribute should_panic to our test function. The test passes if the code inside the function panics; the test fails if the code inside the function doesn‚Äôt panic. Listing 11-8 shows a test that checks that the error conditions of Guess::new happen when we expect them to. Filename: src/lib.rs pub struct Guess { value: i32,\\n} impl Guess { pub fn new(value: i32) -> Guess { if value < 1 || value > 100 { panic!(\\"Guess value must be between 1 and 100, got {value}.\\"); } Guess { value } }\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] #[should_panic] fn greater_than_100() { Guess::new(200); }\\n} Listing 11-8: Testing that a condition will cause a panic! We place the #[should_panic] attribute after the #[test] attribute and before the test function it applies to. Let‚Äôs look at the result when this test passes: $ cargo test Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.58s Running unittests src/lib.rs (target/debug/deps/guessing_game-57d70c3acb738f4d) running 1 test\\ntest tests::greater_than_100 - should panic ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests guessing_game running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Looks good! Now let‚Äôs introduce a bug in our code by removing the condition that the new function will panic if the value is greater than 100: # pub struct Guess {\\n# value: i32,\\n# }\\n# // --snip--\\nimpl Guess { pub fn new(value: i32) -> Guess { if value < 1 { panic!(\\"Guess value must be between 1 and 100, got {value}.\\"); } Guess { value } }\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# #[should_panic]\\n# fn greater_than_100() {\\n# Guess::new(200);\\n# }\\n# } When we run the test in Listing 11-8, it will fail: $ cargo test Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.62s Running unittests src/lib.rs (target/debug/deps/guessing_game-57d70c3acb738f4d) running 1 test\\ntest tests::greater_than_100 - should panic ... FAILED failures: ---- tests::greater_than_100 stdout ----\\nnote: test did not panic as expected failures: tests::greater_than_100 test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` We don‚Äôt get a very helpful message in this case, but when we look at the test function, we see that it‚Äôs annotated with #[should_panic]. The failure we got means that the code in the test function did not cause a panic. Tests that use should_panic can be imprecise. A should_panic test would pass even if the test panics for a different reason from the one we were expecting. To make should_panic tests more precise, we can add an optional expected parameter to the should_panic attribute. The test harness will make sure that the failure message contains the provided text. For example, consider the modified code for Guess in Listing 11-9 where the new function panics with different messages depending on whether the value is too small or too large. Filename: src/lib.rs # pub struct Guess {\\n# value: i32,\\n# }\\n# // --snip-- impl Guess { pub fn new(value: i32) -> Guess { if value < 1 { panic!( \\"Guess value must be greater than or equal to 1, got {value}.\\" ); } else if value > 100 { panic!( \\"Guess value must be less than or equal to 100, got {value}.\\" ); } Guess { value } }\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] #[should_panic(expected = \\"less than or equal to 100\\")] fn greater_than_100() { Guess::new(200); }\\n} Listing 11-9: Testing for a panic! with a panic message containing a specified substring This test will pass because the value we put in the should_panic attribute‚Äôs expected parameter is a substring of the message that the Guess::new function panics with. We could have specified the entire panic message that we expect, which in this case would be Guess value must be less than or equal to 100, got 200. What you choose to specify depends on how much of the panic message is unique or dynamic and how precise you want your test to be. In this case, a substring of the panic message is enough to ensure that the code in the test function executes the else if value > 100 case. To see what happens when a should_panic test with an expected message fails, let‚Äôs again introduce a bug into our code by swapping the bodies of the if value < 1 and the else if value > 100 blocks: # pub struct Guess {\\n# value: i32,\\n# }\\n# # impl Guess {\\n# pub fn new(value: i32) -> Guess { if value < 1 { panic!( \\"Guess value must be less than or equal to 100, got {value}.\\" ); } else if value > 100 { panic!( \\"Guess value must be greater than or equal to 1, got {value}.\\" ); }\\n# # Guess { value }\\n# }\\n# }\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# #[should_panic(expected = \\"less than or equal to 100\\")]\\n# fn greater_than_100() {\\n# Guess::new(200);\\n# }\\n# } This time when we run the should_panic test, it will fail: $ cargo test Compiling guessing_game v0.1.0 (file:///projects/guessing_game) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.66s Running unittests src/lib.rs (target/debug/deps/guessing_game-57d70c3acb738f4d) running 1 test\\ntest tests::greater_than_100 - should panic ... FAILED failures: ---- tests::greater_than_100 stdout ---- thread \'tests::greater_than_100\' panicked at src/lib.rs:12:13:\\nGuess value must be greater than or equal to 1, got 200.\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\\nnote: panic did not contain expected string panic message: `\\"Guess value must be greater than or equal to 1, got 200.\\"`, expected substring: `\\"less than or equal to 100\\"` failures: tests::greater_than_100 test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` The failure message indicates that this test did indeed panic as we expected, but the panic message did not include the expected string less than or equal to 100. The panic message that we did get in this case was Guess value must be greater than or equal to 1, got 200. Now we can start figuring out where our bug is!","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Checking for Panics with should_panic","id":"200","title":"Checking for Panics with should_panic"},"201":{"body":"All of our tests so far panic when they fail. We can also write tests that use Result<T, E>! Here‚Äôs the test from Listing 11-1, rewritten to use Result<T, E> and return an Err instead of panicking: # pub fn add(left: u64, right: u64) -> u64 {\\n# left + right\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_works() -> Result<(), String> { let result = add(2, 2); if result == 4 { Ok(()) } else { Err(String::from(\\"two plus two does not equal four\\")) } }\\n} The it_works function now has the Result<(), String> return type. In the body of the function, rather than calling the assert_eq! macro, we return Ok(()) when the test passes and an Err with a String inside when the test fails. Writing tests so that they return a Result<T, E> enables you to use the question mark operator in the body of tests, which can be a convenient way to write tests that should fail if any operation within them returns an Err variant. You can‚Äôt use the #[should_panic] annotation on tests that use Result<T, E>. To assert that an operation returns an Err variant, don‚Äôt use the question mark operator on the Result<T, E> value. Instead, use assert!(value.is_err()). Now that you know several ways to write tests, let‚Äôs look at what is happening when we run our tests and explore the different options we can use with cargo test.","breadcrumbs":"Writing Automated Tests ¬ª How to Write Tests ¬ª Using Result<T, E> in Tests","id":"201","title":"Using Result<T, E> in Tests"},"202":{"body":"Just as cargo run compiles your code and then runs the resultant binary, cargo test compiles your code in test mode and runs the resultant test binary. The default behavior of the binary produced by cargo test is to run all the tests in parallel and capture output generated during test runs, preventing the output from being displayed and making it easier to read the output related to the test results. You can, however, specify command line options to change this default behavior. Some command line options go to cargo test, and some go to the resultant test binary. To separate these two types of arguments, you list the arguments that go to cargo test followed by the separator -- and then the ones that go to the test binary. Running cargo test --help displays the options you can use with cargo test, and running cargo test -- --help displays the options you can use after the separator. These options are also documented in the ‚ÄúTests‚Äù section of The rustc Book .","breadcrumbs":"Writing Automated Tests ¬ª Controlling How Tests Are Run ¬ª Controlling How Tests Are Run","id":"202","title":"Controlling How Tests Are Run"},"203":{"body":"When you run multiple tests, by default they run in parallel using threads, meaning they finish running more quickly and you get feedback sooner. Because the tests are running at the same time, you must make sure your tests don‚Äôt depend on each other or on any shared state, including a shared environment, such as the current working directory or environment variables. For example, say each of your tests runs some code that creates a file on disk named test-output.txt and writes some data to that file. Then, each test reads the data in that file and asserts that the file contains a particular value, which is different in each test. Because the tests run at the same time, one test might overwrite the file in the time between when another test is writing and reading the file. The second test will then fail, not because the code is incorrect but because the tests have interfered with each other while running in parallel. One solution is to make sure each test writes to a different file; another solution is to run the tests one at a time. If you don‚Äôt want to run the tests in parallel or if you want more fine-grained control over the number of threads used, you can send the --test-threads flag and the number of threads you want to use to the test binary. Take a look at the following example: $ cargo test -- --test-threads=1 We set the number of test threads to 1, telling the program not to use any parallelism. Running the tests using one thread will take longer than running them in parallel, but the tests won‚Äôt interfere with each other if they share state.","breadcrumbs":"Writing Automated Tests ¬ª Controlling How Tests Are Run ¬ª Running Tests in Parallel or Consecutively","id":"203","title":"Running Tests in Parallel or Consecutively"},"204":{"body":"By default, if a test passes, Rust‚Äôs test library captures anything printed to standard output. For example, if we call println! in a test and the test passes, we won‚Äôt see the println! output in the terminal; we‚Äôll see only the line that indicates the test passed. If a test fails, we‚Äôll see whatever was printed to standard output with the rest of the failure message. As an example, Listing 11-10 has a silly function that prints the value of its parameter and returns 10, as well as a test that passes and a test that fails. Filename: src/lib.rs fn prints_and_returns_10(a: i32) -> i32 { println!(\\"I got the value {a}\\"); 10\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn this_test_will_pass() { let value = prints_and_returns_10(4); assert_eq!(value, 10); } #[test] fn this_test_will_fail() { let value = prints_and_returns_10(8); assert_eq!(value, 5); }\\n} Listing 11-10: Tests for a function that calls println! When we run these tests with cargo test, we‚Äôll see the following output: $ cargo test Compiling silly-function v0.1.0 (file:///projects/silly-function) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.58s Running unittests src/lib.rs (target/debug/deps/silly_function-160869f38cff9166) running 2 tests\\ntest tests::this_test_will_fail ... FAILED\\ntest tests::this_test_will_pass ... ok failures: ---- tests::this_test_will_fail stdout ----\\nI got the value 8 thread \'tests::this_test_will_fail\' panicked at src/lib.rs:19:9:\\nassertion `left == right` failed left: 10 right: 5\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::this_test_will_fail test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` Note that nowhere in this output do we see I got the value 4, which is printed when the test that passes runs. That output has been captured. The output from the test that failed, I got the value 8, appears in the section of the test summary output, which also shows the cause of the test failure. If we want to see printed values for passing tests as well, we can tell Rust to also show the output of successful tests with --show-output: $ cargo test -- --show-output When we run the tests in Listing 11-10 again with the --show-output flag, we see the following output: $ cargo test -- --show-output Compiling silly-function v0.1.0 (file:///projects/silly-function) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.60s Running unittests src/lib.rs (target/debug/deps/silly_function-160869f38cff9166) running 2 tests\\ntest tests::this_test_will_fail ... FAILED\\ntest tests::this_test_will_pass ... ok successes: ---- tests::this_test_will_pass stdout ----\\nI got the value 4 successes: tests::this_test_will_pass failures: ---- tests::this_test_will_fail stdout ----\\nI got the value 8 thread \'tests::this_test_will_fail\' panicked at src/lib.rs:19:9:\\nassertion `left == right` failed left: 10 right: 5\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::this_test_will_fail test result: FAILED. 1 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib`","breadcrumbs":"Writing Automated Tests ¬ª Controlling How Tests Are Run ¬ª Showing Function Output","id":"204","title":"Showing Function Output"},"205":{"body":"Running a full test suite can sometimes take a long time. If you‚Äôre working on code in a particular area, you might want to run only the tests pertaining to that code. You can choose which tests to run by passing cargo test the name or names of the test(s) you want to run as an argument. To demonstrate how to run a subset of tests, we‚Äôll first create three tests for our add_two function, as shown in Listing 11-11, and choose which ones to run. Filename: src/lib.rs pub fn add_two(a: u64) -> u64 { a + 2\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn add_two_and_two() { let result = add_two(2); assert_eq!(result, 4); } #[test] fn add_three_and_two() { let result = add_two(3); assert_eq!(result, 5); } #[test] fn one_hundred() { let result = add_two(100); assert_eq!(result, 102); }\\n} Listing 11-11: Three tests with three different names If we run the tests without passing any arguments, as we saw earlier, all the tests will run in parallel: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.62s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 3 tests\\ntest tests::add_three_and_two ... ok\\ntest tests::add_two_and_two ... ok\\ntest tests::one_hundred ... ok test result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running Single Tests We can pass the name of any test function to cargo test to run only that test: $ cargo test one_hundred Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.69s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::one_hundred ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 2 filtered out; finished in 0.00s Only the test with the name one_hundred ran; the other two tests didn‚Äôt match that name. The test output lets us know we had more tests that didn‚Äôt run by displaying 2 filtered out at the end. We can‚Äôt specify the names of multiple tests in this way; only the first value given to cargo test will be used. But there is a way to run multiple tests. Filtering to Run Multiple Tests We can specify part of a test name, and any test whose name matches that value will be run. For example, because two of our tests‚Äô names contain add, we can run those two by running cargo test add: $ cargo test add Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.61s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 2 tests\\ntest tests::add_three_and_two ... ok\\ntest tests::add_two_and_two ... ok test result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 1 filtered out; finished in 0.00s This command ran all tests with add in the name and filtered out the test named one_hundred. Also note that the module in which a test appears becomes part of the test‚Äôs name, so we can run all the tests in a module by filtering on the module‚Äôs name.","breadcrumbs":"Writing Automated Tests ¬ª Controlling How Tests Are Run ¬ª Running a Subset of Tests by Name","id":"205","title":"Running a Subset of Tests by Name"},"206":{"body":"Sometimes a few specific tests can be very time-consuming to execute, so you might want to exclude them during most runs of cargo test. Rather than listing as arguments all tests you do want to run, you can instead annotate the time-consuming tests using the ignore attribute to exclude them, as shown here: Filename: src/lib.rs # pub fn add(left: u64, right: u64) -> u64 {\\n# left + right\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_works() { let result = add(2, 2); assert_eq!(result, 4); } #[test] #[ignore] fn expensive_test() { // code that takes an hour to run }\\n} After #[test], we add the #[ignore] line to the test we want to exclude. Now when we run our tests, it_works runs, but expensive_test doesn‚Äôt: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.60s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 2 tests\\ntest tests::expensive_test ... ignored\\ntest tests::it_works ... ok test result: ok. 1 passed; 0 failed; 1 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s The expensive_test function is listed as ignored. If we want to run only the ignored tests, we can use cargo test -- --ignored: $ cargo test -- --ignored Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.61s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::expensive_test ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 1 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s By controlling which tests run, you can make sure your cargo test results will be returned quickly. When you‚Äôre at a point where it makes sense to check the results of the ignored tests and you have time to wait for the results, you can run cargo test -- --ignored instead. If you want to run all tests whether they‚Äôre ignored or not, you can run cargo test -- --include-ignored.","breadcrumbs":"Writing Automated Tests ¬ª Controlling How Tests Are Run ¬ª Ignoring Tests Unless Specifically Requested","id":"206","title":"Ignoring Tests Unless Specifically Requested"},"207":{"body":"As mentioned at the start of the chapter, testing is a complex discipline, and different people use different terminology and organization. The Rust community thinks about tests in terms of two main categories: unit tests and integration tests. Unit tests are small and more focused, testing one module in isolation at a time, and can test private interfaces. Integration tests are entirely external to your library and use your code in the same way any other external code would, using only the public interface and potentially exercising multiple modules per test. Writing both kinds of tests is important to ensure that the pieces of your library are doing what you expect them to, separately and together.","breadcrumbs":"Writing Automated Tests ¬ª Test Organization ¬ª Test Organization","id":"207","title":"Test Organization"},"208":{"body":"The purpose of unit tests is to test each unit of code in isolation from the rest of the code to quickly pinpoint where code is and isn‚Äôt working as expected. You‚Äôll put unit tests in the src directory in each file with the code that they‚Äôre testing. The convention is to create a module named tests in each file to contain the test functions and to annotate the module with cfg(test). The tests Module and #[cfg(test)] The #[cfg(test)] annotation on the tests module tells Rust to compile and run the test code only when you run cargo test, not when you run cargo build. This saves compile time when you only want to build the library and saves space in the resultant compiled artifact because the tests are not included. You‚Äôll see that because integration tests go in a different directory, they don‚Äôt need the #[cfg(test)] annotation. However, because unit tests go in the same files as the code, you‚Äôll use #[cfg(test)] to specify that they shouldn‚Äôt be included in the compiled result. Recall that when we generated the new adder project in the first section of this chapter, Cargo generated this code for us: Filename: src/lib.rs pub fn add(left: u64, right: u64) -> u64 { left + right\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_works() { let result = add(2, 2); assert_eq!(result, 4); }\\n} On the automatically generated tests module, the attribute cfg stands for configuration and tells Rust that the following item should only be included given a certain configuration option. In this case, the configuration option is test, which is provided by Rust for compiling and running tests. By using the cfg attribute, Cargo compiles our test code only if we actively run the tests with cargo test. This includes any helper functions that might be within this module, in addition to the functions annotated with #[test]. Private Function Tests There‚Äôs debate within the testing community about whether or not private functions should be tested directly, and other languages make it difficult or impossible to test private functions. Regardless of which testing ideology you adhere to, Rust‚Äôs privacy rules do allow you to test private functions. Consider the code in Listing 11-12 with the private function internal_adder. Filename: src/lib.rs pub fn add_two(a: u64) -> u64 { internal_adder(a, 2)\\n} fn internal_adder(left: u64, right: u64) -> u64 { left + right\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn internal() { let result = internal_adder(2, 2); assert_eq!(result, 4); }\\n} Listing 11-12: Testing a private function Note that the internal_adder function is not marked as pub. Tests are just Rust code, and the tests module is just another module. As we discussed in ‚ÄúPaths for Referring to an Item in the Module Tree‚Äù , items in child modules can use the items in their ancestor modules. In this test, we bring all of the items belonging to the tests module‚Äôs parent into scope with use super::*, and then the test can call internal_adder. If you don‚Äôt think private functions should be tested, there‚Äôs nothing in Rust that will compel you to do so.","breadcrumbs":"Writing Automated Tests ¬ª Test Organization ¬ª Unit Tests","id":"208","title":"Unit Tests"},"209":{"body":"In Rust, integration tests are entirely external to your library. They use your library in the same way any other code would, which means they can only call functions that are part of your library‚Äôs public API. Their purpose is to test whether many parts of your library work together correctly. Units of code that work correctly on their own could have problems when integrated, so test coverage of the integrated code is important as well. To create integration tests, you first need a tests directory. The tests Directory We create a tests directory at the top level of our project directory, next to src . Cargo knows to look for integration test files in this directory. We can then make as many test files as we want, and Cargo will compile each of the files as an individual crate. Let‚Äôs create an integration test. With the code in Listing 11-12 still in the src/lib.rs file, make a tests directory, and create a new file named tests/integration_test.rs . Your directory structure should look like this: adder\\n‚îú‚îÄ‚îÄ Cargo.lock\\n‚îú‚îÄ‚îÄ Cargo.toml\\n‚îú‚îÄ‚îÄ src\\n‚îÇ ‚îî‚îÄ‚îÄ lib.rs\\n‚îî‚îÄ‚îÄ tests ‚îî‚îÄ‚îÄ integration_test.rs Enter the code in Listing 11-13 into the tests/integration_test.rs file. Filename: tests/integration_test.rs use adder::add_two; #[test]\\nfn it_adds_two() { let result = add_two(2); assert_eq!(result, 4);\\n} Listing 11-13: An integration test of a function in the adder crate Each file in the tests directory is a separate crate, so we need to bring our library into each test crate‚Äôs scope. For that reason, we add use adder::add_two; at the top of the code, which we didn‚Äôt need in the unit tests. We don‚Äôt need to annotate any code in tests/integration_test.rs with #[cfg(test)]. Cargo treats the tests directory specially and compiles files in this directory only when we run cargo test. Run cargo test now: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 1.31s Running unittests src/lib.rs (target/debug/deps/adder-1082c4b063a8fbe6) running 1 test\\ntest tests::internal ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running tests/integration_test.rs (target/debug/deps/integration_test-1082c4b063a8fbe6) running 1 test\\ntest it_adds_two ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s The three sections of output include the unit tests, the integration test, and the doc tests. Note that if any test in a section fails, the following sections will not be run. For example, if a unit test fails, there won‚Äôt be any output for integration and doc tests, because those tests will only be run if all unit tests are passing. The first section for the unit tests is the same as we‚Äôve been seeing: one line for each unit test (one named internal that we added in Listing 11-12) and then a summary line for the unit tests. The integration tests section starts with the line Running tests/integration_test.rs. Next, there is a line for each test function in that integration test and a summary line for the results of the integration test just before the Doc-tests adder section starts. Each integration test file has its own section, so if we add more files in the tests directory, there will be more integration test sections. We can still run a particular integration test function by specifying the test function‚Äôs name as an argument to cargo test. To run all the tests in a particular integration test file, use the --test argument of cargo test followed by the name of the file: $ cargo test --test integration_test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.64s Running tests/integration_test.rs (target/debug/deps/integration_test-82e7799c1bc62298) running 1 test\\ntest it_adds_two ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s This command runs only the tests in the tests/integration_test.rs file. Submodules in Integration Tests As you add more integration tests, you might want to make more files in the tests directory to help organize them; for example, you can group the test functions by the functionality they‚Äôre testing. As mentioned earlier, each file in the tests directory is compiled as its own separate crate, which is useful for creating separate scopes to more closely imitate the way end users will be using your crate. However, this means files in the tests directory don‚Äôt share the same behavior as files in src do, as you learned in Chapter 7 regarding how to separate code into modules and files. The different behavior of tests directory files is most noticeable when you have a set of helper functions to use in multiple integration test files, and you try to follow the steps in the ‚ÄúSeparating Modules into Different Files‚Äù section of Chapter 7 to extract them into a common module. For example, if we create tests/common.rs and place a function named setup in it, we can add some code to setup that we want to call from multiple test functions in multiple test files: Filename: tests/common.rs pub fn setup() { // setup code specific to your library\'s tests would go here\\n} When we run the tests again, we‚Äôll see a new section in the test output for the common.rs file, even though this file doesn‚Äôt contain any test functions nor did we call the setup function from anywhere: $ cargo test Compiling adder v0.1.0 (file:///projects/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.89s Running unittests src/lib.rs (target/debug/deps/adder-92948b65e88960b4) running 1 test\\ntest tests::internal ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running tests/common.rs (target/debug/deps/common-92948b65e88960b4) running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running tests/integration_test.rs (target/debug/deps/integration_test-92948b65e88960b4) running 1 test\\ntest it_adds_two ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests adder running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Having common appear in the test results with running 0 tests displayed for it is not what we wanted. We just wanted to share some code with the other integration test files. To avoid having common appear in the test output, instead of creating tests/common.rs , we‚Äôll create tests/common/mod.rs . The project directory now looks like this: ‚îú‚îÄ‚îÄ Cargo.lock\\n‚îú‚îÄ‚îÄ Cargo.toml\\n‚îú‚îÄ‚îÄ src\\n‚îÇ ‚îî‚îÄ‚îÄ lib.rs\\n‚îî‚îÄ‚îÄ tests ‚îú‚îÄ‚îÄ common ‚îÇ ‚îî‚îÄ‚îÄ mod.rs ‚îî‚îÄ‚îÄ integration_test.rs This is the older naming convention that Rust also understands that we mentioned in ‚ÄúAlternate File Paths‚Äù in Chapter 7. Naming the file this way tells Rust not to treat the common module as an integration test file. When we move the setup function code into tests/common/mod.rs and delete the tests/common.rs file, the section in the test output will no longer appear. Files in subdirectories of the tests directory don‚Äôt get compiled as separate crates or have sections in the test output. After we‚Äôve created tests/common/mod.rs , we can use it from any of the integration test files as a module. Here‚Äôs an example of calling the setup function from the it_adds_two test in tests/integration_test.rs : Filename: tests/integration_test.rs use adder::add_two; mod common; #[test]\\nfn it_adds_two() { common::setup(); let result = add_two(2); assert_eq!(result, 4);\\n} Note that the mod common; declaration is the same as the module declaration we demonstrated in Listing 7-21. Then, in the test function, we can call the common::setup() function. Integration Tests for Binary Crates If our project is a binary crate that only contains a src/main.rs file and doesn‚Äôt have a src/lib.rs file, we can‚Äôt create integration tests in the tests directory and bring functions defined in the src/main.rs file into scope with a use statement. Only library crates expose functions that other crates can use; binary crates are meant to be run on their own. This is one of the reasons Rust projects that provide a binary have a straightforward src/main.rs file that calls logic that lives in the src/lib.rs file. Using that structure, integration tests can test the library crate with use to make the important functionality available. If the important functionality works, the small amount of code in the src/main.rs file will work as well, and that small amount of code doesn‚Äôt need to be tested.","breadcrumbs":"Writing Automated Tests ¬ª Test Organization ¬ª Integration Tests","id":"209","title":"Integration Tests"},"21":{"body":"In several examples, we will use Rust packages beyond the standard library. To work through those examples, you will either need to have an internet connection or to have downloaded those dependencies ahead of time. To download the dependencies ahead of time, you can run the following commands. (We‚Äôll explain what cargo is and what each of these commands does in detail later.) $ cargo new get-dependencies\\n$ cd get-dependencies\\n$ cargo add rand@0.8.5 trpl@0.2.0 This will cache the downloads for these packages so you will not need to download them later. Once you have run this command, you do not need to keep the get-dependencies folder. If you have run this command, you can use the --offline flag with all cargo commands in the rest of the book to use these cached versions instead of attempting to use the network.","breadcrumbs":"Getting Started ¬ª Installation ¬ª Working Offline with This Book","id":"21","title":"Working Offline with This Book"},"210":{"body":"Rust‚Äôs testing features provide a way to specify how code should function to ensure that it continues to work as you expect, even as you make changes. Unit tests exercise different parts of a library separately and can test private implementation details. Integration tests check that many parts of the library work together correctly, and they use the library‚Äôs public API to test the code in the same way external code will use it. Even though Rust‚Äôs type system and ownership rules help prevent some kinds of bugs, tests are still important to reduce logic bugs having to do with how your code is expected to behave. Let‚Äôs combine the knowledge you learned in this chapter and in previous chapters to work on a project!","breadcrumbs":"Writing Automated Tests ¬ª Test Organization ¬ª Summary","id":"210","title":"Summary"},"211":{"body":"This chapter is a recap of the many skills you‚Äôve learned so far and an exploration of a few more standard library features. We‚Äôll build a command line tool that interacts with file and command line input/output to practice some of the Rust concepts you now have under your belt. Rust‚Äôs speed, safety, single binary output, and cross-platform support make it an ideal language for creating command line tools, so for our project, we‚Äôll make our own version of the classic command line search tool grep ( g lobally search a r egular e xpression and p rint). In the simplest use case, grep searches a specified file for a specified string. To do so, grep takes as its arguments a file path and a string. Then, it reads the file, finds lines in that file that contain the string argument, and prints those lines. Along the way, we‚Äôll show how to make our command line tool use the terminal features that many other command line tools use. We‚Äôll read the value of an environment variable to allow the user to configure the behavior of our tool. We‚Äôll also print error messages to the standard error console stream (stderr) instead of standard output (stdout) so that, for example, the user can redirect successful output to a file while still seeing error messages onscreen. One Rust community member, Andrew Gallant, has already created a fully featured, very fast version of grep, called ripgrep. By comparison, our version will be fairly simple, but this chapter will give you some of the background knowledge you need to understand a real-world project such as ripgrep. Our grep project will combine a number of concepts you‚Äôve learned so far: Organizing code ( Chapter 7 ) Using vectors and strings ( Chapter 8 ) Handling errors ( Chapter 9 ) Using traits and lifetimes where appropriate ( Chapter 10 ) Writing tests ( Chapter 11 ) We‚Äôll also briefly introduce closures, iterators, and trait objects, which Chapter 13 and Chapter 18 will cover in detail.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª An I/O Project: Building a Command Line Program","id":"211","title":"An I/O Project: Building a Command Line Program"},"212":{"body":"Let‚Äôs create a new project with, as always, cargo new. We‚Äôll call our project minigrep to distinguish it from the grep tool that you might already have on your system: $ cargo new minigrep Created binary (application) `minigrep` project\\n$ cd minigrep The first task is to make minigrep accept its two command line arguments: the file path and a string to search for. That is, we want to be able to run our program with cargo run, two hyphens to indicate the following arguments are for our program rather than for cargo, a string to search for, and a path to a file to search in, like so: $ cargo run -- searchstring example-filename.txt Right now, the program generated by cargo new cannot process arguments we give it. Some existing libraries on crates.io can help with writing a program that accepts command line arguments, but because you‚Äôre just learning this concept, let‚Äôs implement this capability ourselves.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Accepting Command Line Arguments ¬ª Accepting Command Line Arguments","id":"212","title":"Accepting Command Line Arguments"},"213":{"body":"To enable minigrep to read the values of command line arguments we pass to it, we‚Äôll need the std::env::args function provided in Rust‚Äôs standard library. This function returns an iterator of the command line arguments passed to minigrep. We‚Äôll cover iterators fully in Chapter 13 . For now, you only need to know two details about iterators: Iterators produce a series of values, and we can call the collect method on an iterator to turn it into a collection, such as a vector, which contains all the elements the iterator produces. The code in Listing 12-1 allows your minigrep program to read any command line arguments passed to it and then collect the values into a vector. Filename: src/main.rs use std::env; fn main() { let args: Vec<String> = env::args().collect(); dbg!(args);\\n} Listing 12-1: Collecting the command line arguments into a vector and printing them First, we bring the std::env module into scope with a use statement so that we can use its args function. Notice that the std::env::args function is nested in two levels of modules. As we discussed in Chapter 7 , in cases where the desired function is nested in more than one module, we‚Äôve chosen to bring the parent module into scope rather than the function. By doing so, we can easily use other functions from std::env. It‚Äôs also less ambiguous than adding use std::env::args and then calling the function with just args, because args might easily be mistaken for a function that‚Äôs defined in the current module.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Accepting Command Line Arguments ¬ª Reading the Argument Values","id":"213","title":"Reading the Argument Values"},"214":{"body":"Note that std::env::args will panic if any argument contains invalid Unicode. If your program needs to accept arguments containing invalid Unicode, use std::env::args_os instead. That function returns an iterator that produces OsString values instead of String values. We‚Äôve chosen to use std::env::args here for simplicity because OsString values differ per platform and are more complex to work with than String values. On the first line of main, we call env::args, and we immediately use collect to turn the iterator into a vector containing all the values produced by the iterator. We can use the collect function to create many kinds of collections, so we explicitly annotate the type of args to specify that we want a vector of strings. Although you very rarely need to annotate types in Rust, collect is one function you do often need to annotate because Rust isn‚Äôt able to infer the kind of collection you want. Finally, we print the vector using the debug macro. Let‚Äôs try running the code first with no arguments and then with two arguments: $ cargo run Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.61s Running `target/debug/minigrep`\\n[src/main.rs:5:5] args = [ \\"target/debug/minigrep\\",\\n] $ cargo run -- needle haystack Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 1.57s Running `target/debug/minigrep needle haystack`\\n[src/main.rs:5:5] args = [ \\"target/debug/minigrep\\", \\"needle\\", \\"haystack\\",\\n] Notice that the first value in the vector is \\"target/debug/minigrep\\", which is the name of our binary. This matches the behavior of the arguments list in C, letting programs use the name by which they were invoked in their execution. It‚Äôs often convenient to have access to the program name in case you want to print it in messages or change the behavior of the program based on what command line alias was used to invoke the program. But for the purposes of this chapter, we‚Äôll ignore it and save only the two arguments we need.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Accepting Command Line Arguments ¬ª The args Function and Invalid Unicode","id":"214","title":"The args Function and Invalid Unicode"},"215":{"body":"The program is currently able to access the values specified as command line arguments. Now we need to save the values of the two arguments in variables so that we can use the values throughout the rest of the program. We do that in Listing 12-2. Filename: src/main.rs use std::env; fn main() { let args: Vec<String> = env::args().collect(); let query = &args[1]; let file_path = &args[2]; println!(\\"Searching for {query}\\"); println!(\\"In file {file_path}\\");\\n} Listing 12-2: Creating variables to hold the query argument and file path argument As we saw when we printed the vector, the program‚Äôs name takes up the first value in the vector at args[0], so we‚Äôre starting arguments at index 1. The first argument minigrep takes is the string we‚Äôre searching for, so we put a reference to the first argument in the variable query. The second argument will be the file path, so we put a reference to the second argument in the variable file_path. We temporarily print the values of these variables to prove that the code is working as we intend. Let‚Äôs run this program again with the arguments test and sample.txt: $ cargo run -- test sample.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep test sample.txt`\\nSearching for test\\nIn file sample.txt Great, the program is working! The values of the arguments we need are being saved into the right variables. Later we‚Äôll add some error handling to deal with certain potential erroneous situations, such as when the user provides no arguments; for now, we‚Äôll ignore that situation and work on adding file-reading capabilities instead.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Accepting Command Line Arguments ¬ª Saving the Argument Values in Variables","id":"215","title":"Saving the Argument Values in Variables"},"216":{"body":"Now we‚Äôll add functionality to read the file specified in the file_path argument. First, we need a sample file to test it with: We‚Äôll use a file with a small amount of text over multiple lines with some repeated words. Listing 12-3 has an Emily Dickinson poem that will work well! Create a file called poem.txt at the root level of your project, and enter the poem ‚ÄúI‚Äôm Nobody! Who are you?‚Äù Filename: poem.txt I\'m nobody! Who are you?\\nAre you nobody, too?\\nThen there\'s a pair of us - don\'t tell!\\nThey\'d banish us, you know. How dreary to be somebody!\\nHow public, like a frog\\nTo tell your name the livelong day\\nTo an admiring bog! Listing 12-3: A poem by Emily Dickinson makes a good test case. With the text in place, edit src/main.rs and add code to read the file, as shown in Listing 12-4. Filename: src/main.rs use std::env;\\nuse std::fs; fn main() { // --snip--\\n# let args: Vec<String> = env::args().collect();\\n# # let query = &args[1];\\n# let file_path = &args[2];\\n# # println!(\\"Searching for {query}\\"); println!(\\"In file {file_path}\\"); let contents = fs::read_to_string(file_path) .expect(\\"Should have been able to read the file\\"); println!(\\"With text:\\\\n{contents}\\");\\n} Listing 12-4: Reading the contents of the file specified by the second argument First, we bring in a relevant part of the standard library with a use statement: We need std::fs to handle files. In main, the new statement fs::read_to_string takes the file_path, opens that file, and returns a value of type std::io::Result<String> that contains the file‚Äôs contents. After that, we again add a temporary println! statement that prints the value of contents after the file is read so that we can check that the program is working so far. Let‚Äôs run this code with any string as the first command line argument (because we haven‚Äôt implemented the searching part yet) and the poem.txt file as the second argument: $ cargo run -- the poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep the poem.txt`\\nSearching for the\\nIn file poem.txt\\nWith text:\\nI\'m nobody! Who are you?\\nAre you nobody, too?\\nThen there\'s a pair of us - don\'t tell!\\nThey\'d banish us, you know. How dreary to be somebody!\\nHow public, like a frog\\nTo tell your name the livelong day\\nTo an admiring bog! Great! The code read and then printed the contents of the file. But the code has a few flaws. At the moment, the main function has multiple responsibilities: Generally, functions are clearer and easier to maintain if each function is responsible for only one idea. The other problem is that we‚Äôre not handling errors as well as we could. The program is still small, so these flaws aren‚Äôt a big problem, but as the program grows, it will be harder to fix them cleanly. It‚Äôs a good practice to begin refactoring early on when developing a program because it‚Äôs much easier to refactor smaller amounts of code. We‚Äôll do that next.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Reading a File ¬ª Reading a File","id":"216","title":"Reading a File"},"217":{"body":"To improve our program, we‚Äôll fix four problems that have to do with the program‚Äôs structure and how it‚Äôs handling potential errors. First, our main function now performs two tasks: It parses arguments and reads files. As our program grows, the number of separate tasks the main function handles will increase. As a function gains responsibilities, it becomes more difficult to reason about, harder to test, and harder to change without breaking one of its parts. It‚Äôs best to separate functionality so that each function is responsible for one task. This issue also ties into the second problem: Although query and file_path are configuration variables to our program, variables like contents are used to perform the program‚Äôs logic. The longer main becomes, the more variables we‚Äôll need to bring into scope; the more variables we have in scope, the harder it will be to keep track of the purpose of each. It‚Äôs best to group the configuration variables into one structure to make their purpose clear. The third problem is that we‚Äôve used expect to print an error message when reading the file fails, but the error message just prints Should have been able to read the file. Reading a file can fail in a number of ways: For example, the file could be missing, or we might not have permission to open it. Right now, regardless of the situation, we‚Äôd print the same error message for everything, which wouldn‚Äôt give the user any information! Fourth, we use expect to handle an error, and if the user runs our program without specifying enough arguments, they‚Äôll get an index out of bounds error from Rust that doesn‚Äôt clearly explain the problem. It would be best if all the error-handling code were in one place so that future maintainers had only one place to consult the code if the error-handling logic needed to change. Having all the error-handling code in one place will also ensure that we‚Äôre printing messages that will be meaningful to our end users. Let‚Äôs address these four problems by refactoring our project.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª Refactoring to Improve Modularity and Error Handling","id":"217","title":"Refactoring to Improve Modularity and Error Handling"},"218":{"body":"The organizational problem of allocating responsibility for multiple tasks to the main function is common to many binary projects. As a result, many Rust programmers find it useful to split up the separate concerns of a binary program when the main function starts getting large. This process has the following steps: Split your program into a main.rs file and a lib.rs file and move your program‚Äôs logic to lib.rs . As long as your command line parsing logic is small, it can remain in the main function. When the command line parsing logic starts getting complicated, extract it from the main function into other functions or types. The responsibilities that remain in the main function after this process should be limited to the following: Calling the command line parsing logic with the argument values Setting up any other configuration Calling a run function in lib.rs Handling the error if run returns an error This pattern is about separating concerns: main.rs handles running the program and lib.rs handles all the logic of the task at hand. Because you can‚Äôt test the main function directly, this structure lets you test all of your program‚Äôs logic by moving it out of the main function. The code that remains in the main function will be small enough to verify its correctness by reading it. Let‚Äôs rework our program by following this process. Extracting the Argument Parser We‚Äôll extract the functionality for parsing arguments into a function that main will call. Listing 12-5 shows the new start of the main function that calls a new function parse_config, which we‚Äôll define in src/main.rs . Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# fn main() { let args: Vec<String> = env::args().collect(); let (query, file_path) = parse_config(&args); // --snip--\\n# # println!(\\"Searching for {query}\\");\\n# println!(\\"In file {file_path}\\");\\n# # let contents = fs::read_to_string(file_path)\\n# .expect(\\"Should have been able to read the file\\");\\n# # println!(\\"With text:\\\\n{contents}\\");\\n} fn parse_config(args: &[String]) -> (&str, &str) { let query = &args[1]; let file_path = &args[2]; (query, file_path)\\n} Listing 12-5: Extracting a parse_config function from main We‚Äôre still collecting the command line arguments into a vector, but instead of assigning the argument value at index 1 to the variable query and the argument value at index 2 to the variable file_path within the main function, we pass the whole vector to the parse_config function. The parse_config function then holds the logic that determines which argument goes in which variable and passes the values back to main. We still create the query and file_path variables in main, but main no longer has the responsibility of determining how the command line arguments and variables correspond. This rework may seem like overkill for our small program, but we‚Äôre refactoring in small, incremental steps. After making this change, run the program again to verify that the argument parsing still works. It‚Äôs good to check your progress often, to help identify the cause of problems when they occur. Grouping Configuration Values We can take another small step to improve the parse_config function further. At the moment, we‚Äôre returning a tuple, but then we immediately break that tuple into individual parts again. This is a sign that perhaps we don‚Äôt have the right abstraction yet. Another indicator that shows there‚Äôs room for improvement is the config part of parse_config, which implies that the two values we return are related and are both part of one configuration value. We‚Äôre not currently conveying this meaning in the structure of the data other than by grouping the two values into a tuple; we‚Äôll instead put the two values into one struct and give each of the struct fields a meaningful name. Doing so will make it easier for future maintainers of this code to understand how the different values relate to each other and what their purpose is. Listing 12-6 shows the improvements to the parse_config function. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# fn main() { let args: Vec<String> = env::args().collect(); let config = parse_config(&args); println!(\\"Searching for {}\\", config.query); println!(\\"In file {}\\", config.file_path); let contents = fs::read_to_string(config.file_path) .expect(\\"Should have been able to read the file\\"); // --snip--\\n# # println!(\\"With text:\\\\n{contents}\\");\\n} struct Config { query: String, file_path: String,\\n} fn parse_config(args: &[String]) -> Config { let query = args[1].clone(); let file_path = args[2].clone(); Config { query, file_path }\\n} Listing 12-6: Refactoring parse_config to return an instance of a Config struct We‚Äôve added a struct named Config defined to have fields named query and file_path. The signature of parse_config now indicates that it returns a Config value. In the body of parse_config, where we used to return string slices that reference String values in args, we now define Config to contain owned String values. The args variable in main is the owner of the argument values and is only letting the parse_config function borrow them, which means we‚Äôd violate Rust‚Äôs borrowing rules if Config tried to take ownership of the values in args. There are a number of ways we could manage the String data; the easiest, though somewhat inefficient, route is to call the clone method on the values. This will make a full copy of the data for the Config instance to own, which takes more time and memory than storing a reference to the string data. However, cloning the data also makes our code very straightforward because we don‚Äôt have to manage the lifetimes of the references; in this circumstance, giving up a little performance to gain simplicity is a worthwhile trade-off.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª Separating Concerns in Binary Projects","id":"218","title":"Separating Concerns in Binary Projects"},"219":{"body":"There‚Äôs a tendency among many Rustaceans to avoid using clone to fix ownership problems because of its runtime cost. In Chapter 13 , you‚Äôll learn how to use more efficient methods in this type of situation. But for now, it‚Äôs okay to copy a few strings to continue making progress because you‚Äôll make these copies only once and your file path and query string are very small. It‚Äôs better to have a working program that‚Äôs a bit inefficient than to try to hyperoptimize code on your first pass. As you become more experienced with Rust, it‚Äôll be easier to start with the most efficient solution, but for now, it‚Äôs perfectly acceptable to call clone. We‚Äôve updated main so that it places the instance of Config returned by parse_config into a variable named config, and we updated the code that previously used the separate query and file_path variables so that it now uses the fields on the Config struct instead. Now our code more clearly conveys that query and file_path are related and that their purpose is to configure how the program will work. Any code that uses these values knows to find them in the config instance in the fields named for their purpose. Creating a Constructor for Config So far, we‚Äôve extracted the logic responsible for parsing the command line arguments from main and placed it in the parse_config function. Doing so helped us see that the query and file_path values were related, and that relationship should be conveyed in our code. We then added a Config struct to name the related purpose of query and file_path and to be able to return the values‚Äô names as struct field names from the parse_config function. So, now that the purpose of the parse_config function is to create a Config instance, we can change parse_config from a plain function to a function named new that is associated with the Config struct. Making this change will make the code more idiomatic. We can create instances of types in the standard library, such as String, by calling String::new. Similarly, by changing parse_config into a new function associated with Config, we‚Äôll be able to create instances of Config by calling Config::new. Listing 12-7 shows the changes we need to make. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# fn main() { let args: Vec<String> = env::args().collect(); let config = Config::new(&args);\\n# # println!(\\"Searching for {}\\", config.query);\\n# println!(\\"In file {}\\", config.file_path);\\n# # let contents = fs::read_to_string(config.file_path)\\n# .expect(\\"Should have been able to read the file\\");\\n# # println!(\\"With text:\\\\n{contents}\\"); // --snip--\\n} // --snip-- # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# impl Config { fn new(args: &[String]) -> Config { let query = args[1].clone(); let file_path = args[2].clone(); Config { query, file_path } }\\n} Listing 12-7: Changing parse_config into Config::new We‚Äôve updated main where we were calling parse_config to instead call Config::new. We‚Äôve changed the name of parse_config to new and moved it within an impl block, which associates the new function with Config. Try compiling this code again to make sure it works.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª The Trade-Offs of Using clone","id":"219","title":"The Trade-Offs of Using clone"},"22":{"body":"Now that you‚Äôve installed Rust, it‚Äôs time to write your first Rust program. It‚Äôs traditional when learning a new language to write a little program that prints the text Hello, world! to the screen, so we‚Äôll do the same here! Note: This book assumes basic familiarity with the command line. Rust makes no specific demands about your editing or tooling or where your code lives, so if you prefer to use an IDE instead of the command line, feel free to use your favorite IDE. Many IDEs now have some degree of Rust support; check the IDE‚Äôs documentation for details. The Rust team has been focusing on enabling great IDE support via rust-analyzer. See Appendix D for more details.","breadcrumbs":"Getting Started ¬ª Hello, World! ¬ª Hello, World!","id":"22","title":"Hello, World!"},"220":{"body":"Now we‚Äôll work on fixing our error handling. Recall that attempting to access the values in the args vector at index 1 or index 2 will cause the program to panic if the vector contains fewer than three items. Try running the program without any arguments; it will look like this: $ cargo run Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep` thread \'main\' panicked at src/main.rs:27:21:\\nindex out of bounds: the len is 1 but the index is 1\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace The line index out of bounds: the len is 1 but the index is 1 is an error message intended for programmers. It won‚Äôt help our end users understand what they should do instead. Let‚Äôs fix that now. Improving the Error Message In Listing 12-8, we add a check in the new function that will verify that the slice is long enough before accessing index 1 and index 2. If the slice isn‚Äôt long enough, the program panics and displays a better error message. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::new(&args);\\n# # println!(\\"Searching for {}\\", config.query);\\n# println!(\\"In file {}\\", config.file_path);\\n# # let contents = fs::read_to_string(config.file_path)\\n# .expect(\\"Should have been able to read the file\\");\\n# # println!(\\"With text:\\\\n{contents}\\");\\n# }\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config { // --snip-- fn new(args: &[String]) -> Config { if args.len() < 3 { panic!(\\"not enough arguments\\"); } // --snip--\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Config { query, file_path }\\n# }\\n# } Listing 12-8: Adding a check for the number of arguments This code is similar to the Guess::new function we wrote in Listing 9-13 , where we called panic! when the value argument was out of the range of valid values. Instead of checking for a range of values here, we‚Äôre checking that the length of args is at least 3 and the rest of the function can operate under the assumption that this condition has been met. If args has fewer than three items, this condition will be true, and we call the panic! macro to end the program immediately. With these extra few lines of code in new, let‚Äôs run the program without any arguments again to see what the error looks like now: $ cargo run Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep` thread \'main\' panicked at src/main.rs:26:13:\\nnot enough arguments\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace This output is better: We now have a reasonable error message. However, we also have extraneous information we don‚Äôt want to give to our users. Perhaps the technique we used in Listing 9-13 isn‚Äôt the best one to use here: A call to panic! is more appropriate for a programming problem than a usage problem, as discussed in Chapter 9 . Instead, we‚Äôll use the other technique you learned about in Chapter 9‚Äî returning a Result that indicates either success or an error. Returning a Result Instead of Calling panic! We can instead return a Result value that will contain a Config instance in the successful case and will describe the problem in the error case. We‚Äôre also going to change the function name from new to build because many programmers expect new functions to never fail. When Config::build is communicating to main, we can use the Result type to signal there was a problem. Then, we can change main to convert an Err variant into a more practical error for our users without the surrounding text about thread \'main\' and RUST_BACKTRACE that a call to panic! causes. Listing 12-9 shows the changes we need to make to the return value of the function we‚Äôre now calling Config::build and the body of the function needed to return a Result. Note that this won‚Äôt compile until we update main as well, which we‚Äôll do in the next listing. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::new(&args);\\n# # println!(\\"Searching for {}\\", config.query);\\n# println!(\\"In file {}\\", config.file_path);\\n# # let contents = fs::read_to_string(config.file_path)\\n# .expect(\\"Should have been able to read the file\\");\\n# # println!(\\"With text:\\\\n{contents}\\");\\n# }\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# impl Config { fn build(args: &[String]) -> Result<Config, &\'static str> { if args.len() < 3 { return Err(\\"not enough arguments\\"); } let query = args[1].clone(); let file_path = args[2].clone(); Ok(Config { query, file_path }) }\\n} Listing 12-9: Returning a Result from Config::build Our build function returns a Result with a Config instance in the success case and a string literal in the error case. Our error values will always be string literals that have the \'static lifetime. We‚Äôve made two changes in the body of the function: Instead of calling panic! when the user doesn‚Äôt pass enough arguments, we now return an Err value, and we‚Äôve wrapped the Config return value in an Ok. These changes make the function conform to its new type signature. Returning an Err value from Config::build allows the main function to handle the Result value returned from the build function and exit the process more cleanly in the error case. Calling Config::build and Handling Errors To handle the error case and print a user-friendly message, we need to update main to handle the Result being returned by Config::build, as shown in Listing 12-10. We‚Äôll also take the responsibility of exiting the command line tool with a nonzero error code away from panic! and instead implement it by hand. A nonzero exit status is a convention to signal to the process that called our program that the program exited with an error state. Filename: src/main.rs # use std::env;\\n# use std::fs;\\nuse std::process; fn main() { let args: Vec<String> = env::args().collect(); let config = Config::build(&args).unwrap_or_else(|err| { println!(\\"Problem parsing arguments: {err}\\"); process::exit(1); }); // --snip--\\n# # println!(\\"Searching for {}\\", config.query);\\n# println!(\\"In file {}\\", config.file_path);\\n# # let contents = fs::read_to_string(config.file_path)\\n# .expect(\\"Should have been able to read the file\\");\\n# # println!(\\"With text:\\\\n{contents}\\");\\n# }\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# } Listing 12-10: Exiting with an error code if building a Config fails In this listing, we‚Äôve used a method we haven‚Äôt covered in detail yet: unwrap_or_else, which is defined on Result<T, E> by the standard library. Using unwrap_or_else allows us to define some custom, non-panic! error handling. If the Result is an Ok value, this method‚Äôs behavior is similar to unwrap: It returns the inner value that Ok is wrapping. However, if the value is an Err value, this method calls the code in the closure, which is an anonymous function we define and pass as an argument to unwrap_or_else. We‚Äôll cover closures in more detail in Chapter 13 . For now, you just need to know that unwrap_or_else will pass the inner value of the Err, which in this case is the static string \\"not enough arguments\\" that we added in Listing 12-9, to our closure in the argument err that appears between the vertical pipes. The code in the closure can then use the err value when it runs. We‚Äôve added a new use line to bring process from the standard library into scope. The code in the closure that will be run in the error case is only two lines: We print the err value and then call process::exit. The process::exit function will stop the program immediately and return the number that was passed as the exit status code. This is similar to the panic!-based handling we used in Listing 12-8, but we no longer get all the extra output. Let‚Äôs try it: $ cargo run Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.48s Running `target/debug/minigrep`\\nProblem parsing arguments: not enough arguments Great! This output is much friendlier for our users.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª Fixing the Error Handling","id":"220","title":"Fixing the Error Handling"},"221":{"body":"Now that we‚Äôve finished refactoring the configuration parsing, let‚Äôs turn to the program‚Äôs logic. As we stated in ‚ÄúSeparating Concerns in Binary Projects‚Äù , we‚Äôll extract a function named run that will hold all the logic currently in the main function that isn‚Äôt involved with setting up configuration or handling errors. When we‚Äôre done, the main function will be concise and easy to verify by inspection, and we‚Äôll be able to write tests for all the other logic. Listing 12-11 shows the small, incremental improvement of extracting a run function. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# use std::process;\\n# fn main() { // --snip-- # let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# println!(\\"Searching for {}\\", config.query); println!(\\"In file {}\\", config.file_path); run(config);\\n} fn run(config: Config) { let contents = fs::read_to_string(config.file_path) .expect(\\"Should have been able to read the file\\"); println!(\\"With text:\\\\n{contents}\\");\\n} // --snip--\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# } Listing 12-11: Extracting a run function containing the rest of the program logic The run function now contains all the remaining logic from main, starting from reading the file. The run function takes the Config instance as an argument. Returning Errors from run With the remaining program logic separated into the run function, we can improve the error handling, as we did with Config::build in Listing 12-9. Instead of allowing the program to panic by calling expect, the run function will return a Result<T, E> when something goes wrong. This will let us further consolidate the logic around handling errors into main in a user-friendly way. Listing 12-12 shows the changes we need to make to the signature and body of run. Filename: src/main.rs # use std::env;\\n# use std::fs;\\n# use std::process;\\nuse std::error::Error; // --snip-- # # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # println!(\\"Searching for {}\\", config.query);\\n# println!(\\"In file {}\\", config.file_path);\\n# # run(config);\\n# }\\n# fn run(config: Config) -> Result<(), Box<dyn Error>> { let contents = fs::read_to_string(config.file_path)?; println!(\\"With text:\\\\n{contents}\\"); Ok(())\\n}\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# } Listing 12-12: Changing the run function to return Result We‚Äôve made three significant changes here. First, we changed the return type of the run function to Result<(), Box<dyn Error>>. This function previously returned the unit type, (), and we keep that as the value returned in the Ok case. For the error type, we used the trait object Box<dyn Error> (and we brought std::error::Error into scope with a use statement at the top). We‚Äôll cover trait objects in Chapter 18 . For now, just know that Box<dyn Error> means the function will return a type that implements the Error trait, but we don‚Äôt have to specify what particular type the return value will be. This gives us flexibility to return error values that may be of different types in different error cases. The dyn keyword is short for dynamic . Second, we‚Äôve removed the call to expect in favor of the ? operator, as we talked about in Chapter 9 . Rather than panic! on an error, ? will return the error value from the current function for the caller to handle. Third, the run function now returns an Ok value in the success case. We‚Äôve declared the run function‚Äôs success type as () in the signature, which means we need to wrap the unit type value in the Ok value. This Ok(()) syntax might look a bit strange at first. But using () like this is the idiomatic way to indicate that we‚Äôre calling run for its side effects only; it doesn‚Äôt return a value we need. When you run this code, it will compile but will display a warning: $ cargo run -- the poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep)\\nwarning: unused `Result` that must be used --> src/main.rs:19:5 |\\n19 | run(config); | ^^^^^^^^^^^ | = note: this `Result` may be an `Err` variant, which should be handled = note: `#[warn(unused_must_use)]` on by default\\nhelp: use `let _ = ...` to ignore the resulting value |\\n19 | let _ = run(config); | +++++++ warning: `minigrep` (bin \\"minigrep\\") generated 1 warning Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.71s Running `target/debug/minigrep the poem.txt`\\nSearching for the\\nIn file poem.txt\\nWith text:\\nI\'m nobody! Who are you?\\nAre you nobody, too?\\nThen there\'s a pair of us - don\'t tell!\\nThey\'d banish us, you know. How dreary to be somebody!\\nHow public, like a frog\\nTo tell your name the livelong day\\nTo an admiring bog! Rust tells us that our code ignored the Result value and the Result value might indicate that an error occurred. But we‚Äôre not checking to see whether or not there was an error, and the compiler reminds us that we probably meant to have some error-handling code here! Let‚Äôs rectify that problem now. Handling Errors Returned from run in main We‚Äôll check for errors and handle them using a technique similar to one we used with Config::build in Listing 12-10, but with a slight difference: Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# fn main() { // --snip-- # let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# println!(\\"Searching for {}\\", config.query); println!(\\"In file {}\\", config.file_path); if let Err(e) = run(config) { println!(\\"Application error: {e}\\"); process::exit(1); }\\n}\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # println!(\\"With text:\\\\n{contents}\\");\\n# # Ok(())\\n# }\\n# # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# } We use if let rather than unwrap_or_else to check whether run returns an Err value and to call process::exit(1) if it does. The run function doesn‚Äôt return a value that we want to unwrap in the same way that Config::build returns the Config instance. Because run returns () in the success case, we only care about detecting an error, so we don‚Äôt need unwrap_or_else to return the unwrapped value, which would only be (). The bodies of the if let and the unwrap_or_else functions are the same in both cases: We print the error and exit.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª Extracting Logic from main","id":"221","title":"Extracting Logic from main"},"222":{"body":"Our minigrep project is looking good so far! Now we‚Äôll split the src/main.rs file and put some code into the src/lib.rs file. That way, we can test the code and have a src/main.rs file with fewer responsibilities. Let‚Äôs define the code responsible for searching text in src/lib.rs rather than in src/main.rs , which will let us (or anyone else using our minigrep library) call the searching function from more contexts than our minigrep binary. First, let‚Äôs define the search function signature in src/lib.rs as shown in Listing 12-13, with a body that calls the unimplemented! macro. We‚Äôll explain the signature in more detail when we fill in the implementation. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { unimplemented!();\\n} Listing 12-13: Defining the search function in src/lib.rs We‚Äôve used the pub keyword on the function definition to designate search as part of our library crate‚Äôs public API. We now have a library crate that we can use from our binary crate and that we can test! Now we need to bring the code defined in src/lib.rs into the scope of the binary crate in src/main.rs and call it, as shown in Listing 12-14. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# // --snip--\\nuse minigrep::search; fn main() { // --snip--\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# println!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n} // --snip-- # # struct Config {\\n# query: String,\\n# file_path: String,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# }\\n# fn run(config: Config) -> Result<(), Box<dyn Error>> { let contents = fs::read_to_string(config.file_path)?; for line in search(&config.query, &contents) { println!(\\"{line}\\"); } Ok(())\\n} Listing 12-14: Using the minigrep library crate‚Äôs search function in src/main.rs We add a use minigrep::search line to bring the search function from the library crate into the binary crate‚Äôs scope. Then, in the run function, rather than printing out the contents of the file, we call the search function and pass the config.query value and contents as arguments. Then, run will use a for loop to print each line returned from search that matched the query. This is also a good time to remove the println! calls in the main function that displayed the query and the file path so that our program only prints the search results (if no errors occur). Note that the search function will be collecting all the results into a vector it returns before any printing happens. This implementation could be slow to display results when searching large files, because results aren‚Äôt printed as they‚Äôre found; we‚Äôll discuss a possible way to fix this using iterators in Chapter 13. Whew! That was a lot of work, but we‚Äôve set ourselves up for success in the future. Now it‚Äôs much easier to handle errors, and we‚Äôve made the code more modular. Almost all of our work will be done in src/lib.rs from here on out. Let‚Äôs take advantage of this newfound modularity by doing something that would have been difficult with the old code but is easy with the new code: We‚Äôll write some tests!","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Refactoring to Improve Modularity and Error Handling ¬ª Splitting Code into a Library Crate","id":"222","title":"Splitting Code into a Library Crate"},"223":{"body":"Now that we have the search logic in src/lib.rs separate from the main function, it‚Äôs much easier to write tests for the core functionality of our code. We can call functions directly with various arguments and check return values without having to call our binary from the command line. In this section, we‚Äôll add the searching logic to the minigrep program using the test-driven development (TDD) process with the following steps: Write a test that fails and run it to make sure it fails for the reason you expect. Write or modify just enough code to make the new test pass. Refactor the code you just added or changed and make sure the tests continue to pass. Repeat from step 1! Though it‚Äôs just one of many ways to write software, TDD can help drive code design. Writing the test before you write the code that makes the test pass helps maintain high test coverage throughout the process. We‚Äôll test-drive the implementation of the functionality that will actually do the searching for the query string in the file contents and produce a list of lines that match the query. We‚Äôll add this functionality in a function called search.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Adding Functionality with Test Driven Development ¬ª Adding Functionality with Test-Driven Development","id":"223","title":"Adding Functionality with Test-Driven Development"},"224":{"body":"In src/lib.rs , we‚Äôll add a tests module with a test function, as we did in Chapter 11 . The test function specifies the behavior we want the search function to have: It will take a query and the text to search, and it will return only the lines from the text that contain the query. Listing 12-15 shows this test. Filename: src/lib.rs # pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> {\\n# unimplemented!();\\n# }\\n# // --snip-- #[cfg(test)]\\nmod tests { use super::*; #[test] fn one_result() { let query = \\"duct\\"; let contents = \\"\\\\\\nRust:\\nsafe, fast, productive.\\nPick three.\\"; assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents)); }\\n} Listing 12-15: Creating a failing test for the search function for the functionality we wish we had This test searches for the string \\"duct\\". The text we‚Äôre searching is three lines, only one of which contains \\"duct\\" (note that the backslash after the opening double quote tells Rust not to put a newline character at the beginning of the contents of this string literal). We assert that the value returned from the search function contains only the line we expect. If we run this test, it will currently fail because the unimplemented! macro panics with the message ‚Äúnot implemented‚Äù. In accordance with TDD principles, we‚Äôll take a small step of adding just enough code to get the test to not panic when calling the function by defining the search function to always return an empty vector, as shown in Listing 12-16. Then, the test should compile and fail because an empty vector doesn‚Äôt match a vector containing the line \\"safe, fast, productive.\\". Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { vec![]\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn one_result() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# } Listing 12-16: Defining just enough of the search function so that calling it won‚Äôt panic Now let‚Äôs discuss why we need to define an explicit lifetime \'a in the signature of search and use that lifetime with the contents argument and the return value. Recall in Chapter 10 that the lifetime parameters specify which argument lifetime is connected to the lifetime of the return value. In this case, we indicate that the returned vector should contain string slices that reference slices of the argument contents (rather than the argument query). In other words, we tell Rust that the data returned by the search function will live as long as the data passed into the search function in the contents argument. This is important! The data referenced by a slice needs to be valid for the reference to be valid; if the compiler assumes we‚Äôre making string slices of query rather than contents, it will do its safety checking incorrectly. If we forget the lifetime annotations and try to compile this function, we‚Äôll get this error: $ cargo build Compiling minigrep v0.1.0 (file:///projects/minigrep)\\nerror[E0106]: missing lifetime specifier --> src/lib.rs:1:51 |\\n1 | pub fn search(query: &str, contents: &str) -> Vec<&str> { | ---- ---- ^ expected named lifetime parameter | = help: this function\'s return type contains a borrowed value, but the signature does not say whether it is borrowed from `query` or `contents`\\nhelp: consider introducing a named lifetime parameter |\\n1 | pub fn search<\'a>(query: &\'a str, contents: &\'a str) -> Vec<&\'a str> { | ++++ ++ ++ ++ For more information about this error, try `rustc --explain E0106`.\\nerror: could not compile `minigrep` (lib) due to 1 previous error Rust can‚Äôt know which of the two parameters we need for the output, so we need to tell it explicitly. Note that the help text suggests specifying the same lifetime parameter for all the parameters and the output type, which is incorrect! Because contents is the parameter that contains all of our text and we want to return the parts of that text that match, we know contents is the only parameter that should be connected to the return value using the lifetime syntax. Other programming languages don‚Äôt require you to connect arguments to return values in the signature, but this practice will get easier over time. You might want to compare this example with the examples in the ‚ÄúValidating References with Lifetimes‚Äù section in Chapter 10.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Adding Functionality with Test Driven Development ¬ª Writing a Failing Test","id":"224","title":"Writing a Failing Test"},"225":{"body":"Currently, our test is failing because we always return an empty vector. To fix that and implement search, our program needs to follow these steps: Iterate through each line of the contents. Check whether the line contains our query string. If it does, add it to the list of values we‚Äôre returning. If it doesn‚Äôt, do nothing. Return the list of results that match. Let‚Äôs work through each step, starting with iterating through lines. Iterating Through Lines with the lines Method Rust has a helpful method to handle line-by-line iteration of strings, conveniently named lines, that works as shown in Listing 12-17. Note that this won‚Äôt compile yet. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { for line in contents.lines() { // do something with line }\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn one_result() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# } Listing 12-17: Iterating through each line in contents The lines method returns an iterator. We‚Äôll talk about iterators in depth in Chapter 13 . But recall that you saw this way of using an iterator in Listing 3-5 , where we used a for loop with an iterator to run some code on each item in a collection. Searching Each Line for the Query Next, we‚Äôll check whether the current line contains our query string. Fortunately, strings have a helpful method named contains that does this for us! Add a call to the contains method in the search function, as shown in Listing 12-18. Note that this still won‚Äôt compile yet. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { for line in contents.lines() { if line.contains(query) { // do something with line } }\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn one_result() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# } Listing 12-18: Adding functionality to see whether the line contains the string in query At the moment, we‚Äôre building up functionality. To get the code to compile, we need to return a value from the body as we indicated we would in the function signature. Storing Matching Lines To finish this function, we need a way to store the matching lines that we want to return. For that, we can make a mutable vector before the for loop and call the push method to store a line in the vector. After the for loop, we return the vector, as shown in Listing 12-19. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { let mut results = Vec::new(); for line in contents.lines() { if line.contains(query) { results.push(line); } } results\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn one_result() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# } Listing 12-19: Storing the lines that match so that we can return them Now the search function should return only the lines that contain query, and our test should pass. Let‚Äôs run the test: $ cargo test Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `test` profile [unoptimized + debuginfo] target(s) in 1.22s Running unittests src/lib.rs (target/debug/deps/minigrep-9cd200e5fac0fc94) running 1 test\\ntest tests::one_result ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running unittests src/main.rs (target/debug/deps/minigrep-9cd200e5fac0fc94) running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests minigrep running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Our test passed, so we know it works! At this point, we could consider opportunities for refactoring the implementation of the search function while keeping the tests passing to maintain the same functionality. The code in the search function isn‚Äôt too bad, but it doesn‚Äôt take advantage of some useful features of iterators. We‚Äôll return to this example in Chapter 13 , where we‚Äôll explore iterators in detail, and look at how to improve it. Now the entire program should work! Let‚Äôs try it out, first with a word that should return exactly one line from the Emily Dickinson poem: frog . $ cargo run -- frog poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.38s Running `target/debug/minigrep frog poem.txt`\\nHow public, like a frog Cool! Now let‚Äôs try a word that will match multiple lines, like body : $ cargo run -- body poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep body poem.txt`\\nI\'m nobody! Who are you?\\nAre you nobody, too?\\nHow dreary to be somebody! And finally, let‚Äôs make sure that we don‚Äôt get any lines when we search for a word that isn‚Äôt anywhere in the poem, such as monomorphization : $ cargo run -- monomorphization poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep monomorphization poem.txt` Excellent! We‚Äôve built our own mini version of a classic tool and learned a lot about how to structure applications. We‚Äôve also learned a bit about file input and output, lifetimes, testing, and command line parsing. To round out this project, we‚Äôll briefly demonstrate how to work with environment variables and how to print to standard error, both of which are useful when you‚Äôre writing command line programs.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Adding Functionality with Test Driven Development ¬ª Writing Code to Pass the Test","id":"225","title":"Writing Code to Pass the Test"},"226":{"body":"We‚Äôll improve the minigrep binary by adding an extra feature: an option for case-insensitive searching that the user can turn on via an environment variable. We could make this feature a command line option and require that users enter it each time they want it to apply, but by instead making it an environment variable, we allow our users to set the environment variable once and have all their searches be case insensitive in that terminal session.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Working with Environment Variables ¬ª Working with Environment Variables","id":"226","title":"Working with Environment Variables"},"227":{"body":"We first add a new search_case_insensitive function to the minigrep library that will be called when the environment variable has a value. We‚Äôll continue to follow the TDD process, so the first step is again to write a failing test. We‚Äôll add a new test for the new search_case_insensitive function and rename our old test from one_result to case_sensitive to clarify the differences between the two tests, as shown in Listing 12-20. Filename: src/lib.rs # pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> {\\n# let mut results = Vec::new();\\n# # for line in contents.lines() {\\n# if line.contains(query) {\\n# results.push(line);\\n# }\\n# }\\n# # results\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; #[test] fn case_sensitive() { let query = \\"duct\\"; let contents = \\"\\\\\\nRust:\\nsafe, fast, productive.\\nPick three.\\nDuct tape.\\"; assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents)); } #[test] fn case_insensitive() { let query = \\"rUsT\\"; let contents = \\"\\\\\\nRust:\\nsafe, fast, productive.\\nPick three.\\nTrust me.\\"; assert_eq!( vec![\\"Rust:\\", \\"Trust me.\\"], search_case_insensitive(query, contents) ); }\\n} Listing 12-20: Adding a new failing test for the case-insensitive function we‚Äôre about to add Note that we‚Äôve edited the old test‚Äôs contents too. We‚Äôve added a new line with the text \\"Duct tape.\\" using a capital D that shouldn‚Äôt match the query \\"duct\\" when we‚Äôre searching in a case-sensitive manner. Changing the old test in this way helps ensure that we don‚Äôt accidentally break the case-sensitive search functionality that we‚Äôve already implemented. This test should pass now and should continue to pass as we work on the case-insensitive search. The new test for the case- insensitive search uses \\"rUsT\\" as its query. In the search_case_insensitive function we‚Äôre about to add, the query \\"rUsT\\" should match the line containing \\"Rust:\\" with a capital R and match the line \\"Trust me.\\" even though both have different casing from the query. This is our failing test, and it will fail to compile because we haven‚Äôt yet defined the search_case_insensitive function. Feel free to add a skeleton implementation that always returns an empty vector, similar to the way we did for the search function in Listing 12-16 to see the test compile and fail.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Working with Environment Variables ¬ª Writing a Failing Test for Case-Insensitive Search","id":"227","title":"Writing a Failing Test for Case-Insensitive Search"},"228":{"body":"The search_case_insensitive function, shown in Listing 12-21, will be almost the same as the search function. The only difference is that we‚Äôll lowercase the query and each line so that whatever the case of the input arguments, they‚Äôll be the same case when we check whether the line contains the query. Filename: src/lib.rs # pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> {\\n# let mut results = Vec::new();\\n# # for line in contents.lines() {\\n# if line.contains(query) {\\n# results.push(line);\\n# }\\n# }\\n# # results\\n# }\\n# pub fn search_case_insensitive<\'a>( query: &str, contents: &\'a str,\\n) -> Vec<&\'a str> { let query = query.to_lowercase(); let mut results = Vec::new(); for line in contents.lines() { if line.to_lowercase().contains(&query) { results.push(line); } } results\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn case_sensitive() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\n# Duct tape.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# # #[test]\\n# fn case_insensitive() {\\n# let query = \\"rUsT\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\n# Trust me.\\";\\n# # assert_eq!(\\n# vec![\\"Rust:\\", \\"Trust me.\\"],\\n# search_case_insensitive(query, contents)\\n# );\\n# }\\n# } Listing 12-21: Defining the search_case_insensitive function to lowercase the query and the line before comparing them First, we lowercase the query string and store it in a new variable with the same name, shadowing the original query. Calling to_lowercase on the query is necessary so that no matter whether the user‚Äôs query is \\"rust\\", \\"RUST\\", \\"Rust\\", or \\"rUsT\\", we‚Äôll treat the query as if it were \\"rust\\" and be insensitive to the case. While to_lowercase will handle basic Unicode, it won‚Äôt be 100 percent accurate. If we were writing a real application, we‚Äôd want to do a bit more work here, but this section is about environment variables, not Unicode, so we‚Äôll leave it at that here. Note that query is now a String rather than a string slice because calling to_lowercase creates new data rather than referencing existing data. Say the query is \\"rUsT\\", as an example: That string slice doesn‚Äôt contain a lowercase u or t for us to use, so we have to allocate a new String containing \\"rust\\". When we pass query as an argument to the contains method now, we need to add an ampersand because the signature of contains is defined to take a string slice. Next, we add a call to to_lowercase on each line to lowercase all characters. Now that we‚Äôve converted line and query to lowercase, we‚Äôll find matches no matter what the case of the query is. Let‚Äôs see if this implementation passes the tests: $ cargo test Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `test` profile [unoptimized + debuginfo] target(s) in 1.33s Running unittests src/lib.rs (target/debug/deps/minigrep-9cd200e5fac0fc94) running 2 tests\\ntest tests::case_insensitive ... ok\\ntest tests::case_sensitive ... ok test result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running unittests src/main.rs (target/debug/deps/minigrep-9cd200e5fac0fc94) running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests minigrep running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Great! They passed. Now let‚Äôs call the new search_case_insensitive function from the run function. First, we‚Äôll add a configuration option to the Config struct to switch between case-sensitive and case-insensitive search. Adding this field will cause compiler errors because we aren‚Äôt initializing this field anywhere yet: Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# # // --snip--\\n# # # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# println!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# pub struct Config { pub query: String, pub file_path: String, pub ignore_case: bool,\\n}\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# }\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } We added the ignore_case field that holds a Boolean. Next, we need the run function to check the ignore_case field‚Äôs value and use that to decide whether to call the search function or the search_case_insensitive function, as shown in Listing 12-22. This still won‚Äôt compile yet. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# use minigrep::{search, search_case_insensitive}; // --snip-- # # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# println!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # Ok(Config { query, file_path })\\n# }\\n# }\\n# fn run(config: Config) -> Result<(), Box<dyn Error>> { let contents = fs::read_to_string(config.file_path)?; let results = if config.ignore_case { search_case_insensitive(&config.query, &contents) } else { search(&config.query, &contents) }; for line in results { println!(\\"{line}\\"); } Ok(())\\n} Listing 12-22: Calling either search or search_case_insensitive based on the value in config.ignore_case Finally, we need to check for the environment variable. The functions for working with environment variables are in the env module in the standard library, which is already in scope at the top of src/main.rs . We‚Äôll use the var function from the env module to check to see if any value has been set for an environment variable named IGNORE_CASE, as shown in Listing 12-23. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# println!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# impl Config { fn build(args: &[String]) -> Result<Config, &\'static str> { if args.len() < 3 { return Err(\\"not enough arguments\\"); } let query = args[1].clone(); let file_path = args[2].clone(); let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok(); Ok(Config { query, file_path, ignore_case, }) }\\n}\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 12-23: Checking for any value in an environment variable named IGNORE_CASE Here, we create a new variable, ignore_case. To set its value, we call the env::var function and pass it the name of the IGNORE_CASE environment variable. The env::var function returns a Result that will be the successful Ok variant that contains the value of the environment variable if the environment variable is set to any value. It will return the Err variant if the environment variable is not set. We‚Äôre using the is_ok method on the Result to check whether the environment variable is set, which means the program should do a case-insensitive search. If the IGNORE_CASE environment variable isn‚Äôt set to anything, is_ok will return false and the program will perform a case-sensitive search. We don‚Äôt care about the value of the environment variable, just whether it‚Äôs set or unset, so we‚Äôre checking is_ok rather than using unwrap, expect, or any of the other methods we‚Äôve seen on Result. We pass the value in the ignore_case variable to the Config instance so that the run function can read that value and decide whether to call search_case_insensitive or search, as we implemented in Listing 12-22. Let‚Äôs give it a try! First, we‚Äôll run our program without the environment variable set and with the query to, which should match any line that contains the word to in all lowercase: $ cargo run -- to poem.txt Compiling minigrep v0.1.0 (file:///projects/minigrep) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.0s Running `target/debug/minigrep to poem.txt`\\nAre you nobody, too?\\nHow dreary to be somebody! Looks like that still works! Now let‚Äôs run the program with IGNORE_CASE set to 1 but with the same query to: $ IGNORE_CASE=1 cargo run -- to poem.txt If you‚Äôre using PowerShell, you will need to set the environment variable and run the program as separate commands: PS> $Env:IGNORE_CASE=1; cargo run -- to poem.txt This will make IGNORE_CASE persist for the remainder of your shell session. It can be unset with the Remove-Item cmdlet: PS> Remove-Item Env:IGNORE_CASE We should get lines that contain to that might have uppercase letters: Are you nobody, too?\\nHow dreary to be somebody!\\nTo tell your name the livelong day\\nTo an admiring bog! Excellent, we also got lines containing To ! Our minigrep program can now do case-insensitive searching controlled by an environment variable. Now you know how to manage options set using either command line arguments or environment variables. Some programs allow arguments and environment variables for the same configuration. In those cases, the programs decide that one or the other takes precedence. For another exercise on your own, try controlling case sensitivity through either a command line argument or an environment variable. Decide whether the command line argument or the environment variable should take precedence if the program is run with one set to case sensitive and one set to ignore case. The std::env module contains many more useful features for dealing with environment variables: Check out its documentation to see what is available.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Working with Environment Variables ¬ª Implementing the search_case_insensitive Function","id":"228","title":"Implementing the search_case_insensitive Function"},"229":{"body":"At the moment, we‚Äôre writing all of our output to the terminal using the println! macro. In most terminals, there are two kinds of output: standard output (stdout) for general information and standard error (stderr) for error messages. This distinction enables users to choose to direct the successful output of a program to a file but still print error messages to the screen. The println! macro is only capable of printing to standard output, so we have to use something else to print to standard error.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Redirecting Errors to Standard Error ¬ª Redirecting Errors to Standard Error","id":"229","title":"Redirecting Errors to Standard Error"},"23":{"body":"You‚Äôll start by making a directory to store your Rust code. It doesn‚Äôt matter to Rust where your code lives, but for the exercises and projects in this book, we suggest making a projects directory in your home directory and keeping all your projects there. Open a terminal and enter the following commands to make a projects directory and a directory for the ‚ÄúHello, world!‚Äù project within the projects directory. For Linux, macOS, and PowerShell on Windows, enter this: $ mkdir ~/projects\\n$ cd ~/projects\\n$ mkdir hello_world\\n$ cd hello_world For Windows CMD, enter this: > mkdir \\"%USERPROFILE%\\\\projects\\"\\n> cd /d \\"%USERPROFILE%\\\\projects\\"\\n> mkdir hello_world\\n> cd hello_world","breadcrumbs":"Getting Started ¬ª Hello, World! ¬ª Project Directory Setup","id":"23","title":"Project Directory Setup"},"230":{"body":"First, let‚Äôs observe how the content printed by minigrep is currently being written to standard output, including any error messages we want to write to standard error instead. We‚Äôll do that by redirecting the standard output stream to a file while intentionally causing an error. We won‚Äôt redirect the standard error stream, so any content sent to standard error will continue to display on the screen. Command line programs are expected to send error messages to the standard error stream so that we can still see error messages on the screen even if we redirect the standard output stream to a file. Our program is not currently well behaved: We‚Äôre about to see that it saves the error message output to a file instead! To demonstrate this behavior, we‚Äôll run the program with > and the file path, output.txt , that we want to redirect the standard output stream to. We won‚Äôt pass any arguments, which should cause an error: $ cargo run > output.txt The > syntax tells the shell to write the contents of standard output to output.txt instead of the screen. We didn‚Äôt see the error message we were expecting printed to the screen, so that means it must have ended up in the file. This is what output.txt contains: Problem parsing arguments: not enough arguments Yup, our error message is being printed to standard output. It‚Äôs much more useful for error messages like this to be printed to standard error so that only data from a successful run ends up in the file. We‚Äôll change that.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Redirecting Errors to Standard Error ¬ª Checking Where Errors Are Written","id":"230","title":"Checking Where Errors Are Written"},"231":{"body":"We‚Äôll use the code in Listing 12-24 to change how error messages are printed. Because of the refactoring we did earlier in this chapter, all the code that prints error messages is in one function, main. The standard library provides the eprintln! macro that prints to the standard error stream, so let‚Äôs change the two places we were calling println! to print errors to use eprintln! instead. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# fn main() { let args: Vec<String> = env::args().collect(); let config = Config::build(&args).unwrap_or_else(|err| { eprintln!(\\"Problem parsing arguments: {err}\\"); process::exit(1); }); if let Err(e) = run(config) { eprintln!(\\"Application error: {e}\\"); process::exit(1); }\\n}\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok();\\n# # Ok(Config {\\n# query,\\n# file_path,\\n# ignore_case,\\n# })\\n# }\\n# }\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 12-24: Writing error messages to standard error instead of standard output using eprintln! Let‚Äôs now run the program again in the same way, without any arguments and redirecting standard output with >: $ cargo run > output.txt\\nProblem parsing arguments: not enough arguments Now we see the error onscreen and output.txt contains nothing, which is the behavior we expect of command line programs. Let‚Äôs run the program again with arguments that don‚Äôt cause an error but still redirect standard output to a file, like so: $ cargo run -- to poem.txt > output.txt We won‚Äôt see any output to the terminal, and output.txt will contain our results: Filename: output.txt Are you nobody, too?\\nHow dreary to be somebody! This demonstrates that we‚Äôre now using standard output for successful output and standard error for error output as appropriate.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Redirecting Errors to Standard Error ¬ª Printing Errors to Standard Error","id":"231","title":"Printing Errors to Standard Error"},"232":{"body":"This chapter recapped some of the major concepts you‚Äôve learned so far and covered how to perform common I/O operations in Rust. By using command line arguments, files, environment variables, and the eprintln! macro for printing errors, you‚Äôre now prepared to write command line applications. Combined with the concepts in previous chapters, your code will be well organized, store data effectively in the appropriate data structures, handle errors nicely, and be well tested. Next, we‚Äôll explore some Rust features that were influenced by functional languages: closures and iterators.","breadcrumbs":"An I/O Project: Building a Command Line Program ¬ª Redirecting Errors to Standard Error ¬ª Summary","id":"232","title":"Summary"},"233":{"body":"Rust‚Äôs design has taken inspiration from many existing languages and techniques, and one significant influence is functional programming . Programming in a functional style often includes using functions as values by passing them in arguments, returning them from other functions, assigning them to variables for later execution, and so forth. In this chapter, we won‚Äôt debate the issue of what functional programming is or isn‚Äôt but will instead discuss some features of Rust that are similar to features in many languages often referred to as functional. More specifically, we‚Äôll cover: Closures , a function-like construct you can store in a variable Iterators , a way of processing a series of elements How to use closures and iterators to improve the I/O project in Chapter 12 The performance of closures and iterators (spoiler alert: They‚Äôre faster than you might think!) We‚Äôve already covered some other Rust features, such as pattern matching and enums, that are also influenced by the functional style. Because mastering closures and iterators is an important part of writing fast, idiomatic, Rust code, we‚Äôll devote this entire chapter to them.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Functional Language Features: Iterators and Closures","id":"233","title":"Functional Language Features: Iterators and Closures"},"234":{"body":"Rust‚Äôs closures are anonymous functions you can save in a variable or pass as arguments to other functions. You can create the closure in one place and then call the closure elsewhere to evaluate it in a different context. Unlike functions, closures can capture values from the scope in which they‚Äôre defined. We‚Äôll demonstrate how these closure features allow for code reuse and behavior customization.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Closures ¬ª Closures","id":"234","title":"Closures"},"235":{"body":"We‚Äôll first examine how we can use closures to capture values from the environment they‚Äôre defined in for later use. Here‚Äôs the scenario: Every so often, our T-shirt company gives away an exclusive, limited-edition shirt to someone on our mailing list as a promotion. People on the mailing list can optionally add their favorite color to their profile. If the person chosen for a free shirt has their favorite color set, they get that color shirt. If the person hasn‚Äôt specified a favorite color, they get whatever color the company currently has the most of. There are many ways to implement this. For this example, we‚Äôre going to use an enum called ShirtColor that has the variants Red and Blue (limiting the number of colors available for simplicity). We represent the company‚Äôs inventory with an Inventory struct that has a field named shirts that contains a Vec<ShirtColor> representing the shirt colors currently in stock. The method giveaway defined on Inventory gets the optional shirt color preference of the free-shirt winner, and it returns the shirt color the person will get. This setup is shown in Listing 13-1. Filename: src/main.rs #[derive(Debug, PartialEq, Copy, Clone)]\\nenum ShirtColor { Red, Blue,\\n} struct Inventory { shirts: Vec<ShirtColor>,\\n} impl Inventory { fn giveaway(&self, user_preference: Option<ShirtColor>) -> ShirtColor { user_preference.unwrap_or_else(|| self.most_stocked()) } fn most_stocked(&self) -> ShirtColor { let mut num_red = 0; let mut num_blue = 0; for color in &self.shirts { match color { ShirtColor::Red => num_red += 1, ShirtColor::Blue => num_blue += 1, } } if num_red > num_blue { ShirtColor::Red } else { ShirtColor::Blue } }\\n} fn main() { let store = Inventory { shirts: vec![ShirtColor::Blue, ShirtColor::Red, ShirtColor::Blue], }; let user_pref1 = Some(ShirtColor::Red); let giveaway1 = store.giveaway(user_pref1); println!( \\"The user with preference {:?} gets {:?}\\", user_pref1, giveaway1 ); let user_pref2 = None; let giveaway2 = store.giveaway(user_pref2); println!( \\"The user with preference {:?} gets {:?}\\", user_pref2, giveaway2 );\\n} Listing 13-1: Shirt company giveaway situation The store defined in main has two blue shirts and one red shirt remaining to distribute for this limited-edition promotion. We call the giveaway method for a user with a preference for a red shirt and a user without any preference. Again, this code could be implemented in many ways, and here, to focus on closures, we‚Äôve stuck to concepts you‚Äôve already learned, except for the body of the giveaway method that uses a closure. In the giveaway method, we get the user preference as a parameter of type Option<ShirtColor> and call the unwrap_or_else method on user_preference. The unwrap_or_else method on Option<T> is defined by the standard library. It takes one argument: a closure without any arguments that returns a value T (the same type stored in the Some variant of the Option<T>, in this case ShirtColor). If the Option<T> is the Some variant, unwrap_or_else returns the value from within the Some. If the Option<T> is the None variant, unwrap_or_else calls the closure and returns the value returned by the closure. We specify the closure expression || self.most_stocked() as the argument to unwrap_or_else. This is a closure that takes no parameters itself (if the closure had parameters, they would appear between the two vertical pipes). The body of the closure calls self.most_stocked(). We‚Äôre defining the closure here, and the implementation of unwrap_or_else will evaluate the closure later if the result is needed. Running this code prints the following: $ cargo run Compiling shirt-company v0.1.0 (file:///projects/shirt-company) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.27s Running `target/debug/shirt-company`\\nThe user with preference Some(Red) gets Red\\nThe user with preference None gets Blue One interesting aspect here is that we‚Äôve passed a closure that calls self.most_stocked() on the current Inventory instance. The standard library didn‚Äôt need to know anything about the Inventory or ShirtColor types we defined, or the logic we want to use in this scenario. The closure captures an immutable reference to the self Inventory instance and passes it with the code we specify to the unwrap_or_else method. Functions, on the other hand, are not able to capture their environment in this way.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Closures ¬ª Capturing the Environment","id":"235","title":"Capturing the Environment"},"236":{"body":"There are more differences between functions and closures. Closures don‚Äôt usually require you to annotate the types of the parameters or the return value like fn functions do. Type annotations are required on functions because the types are part of an explicit interface exposed to your users. Defining this interface rigidly is important for ensuring that everyone agrees on what types of values a function uses and returns. Closures, on the other hand, aren‚Äôt used in an exposed interface like this: They‚Äôre stored in variables, and they‚Äôre used without naming them and exposing them to users of our library. Closures are typically short and relevant only within a narrow context rather than in any arbitrary scenario. Within these limited contexts, the compiler can infer the types of the parameters and the return type, similar to how it‚Äôs able to infer the types of most variables (there are rare cases where the compiler needs closure type annotations too). As with variables, we can add type annotations if we want to increase explicitness and clarity at the cost of being more verbose than is strictly necessary. Annotating the types for a closure would look like the definition shown in Listing 13-2. In this example, we‚Äôre defining a closure and storing it in a variable rather than defining the closure in the spot we pass it as an argument, as we did in Listing 13-1. Filename: src/main.rs # use std::thread;\\n# use std::time::Duration;\\n# # fn generate_workout(intensity: u32, random_number: u32) { let expensive_closure = |num: u32| -> u32 { println!(\\"calculating slowly...\\"); thread::sleep(Duration::from_secs(2)); num };\\n# # if intensity < 25 {\\n# println!(\\"Today, do {} pushups!\\", expensive_closure(intensity));\\n# println!(\\"Next, do {} situps!\\", expensive_closure(intensity));\\n# } else {\\n# if random_number == 3 {\\n# println!(\\"Take a break today! Remember to stay hydrated!\\");\\n# } else {\\n# println!(\\n# \\"Today, run for {} minutes!\\",\\n# expensive_closure(intensity)\\n# );\\n# }\\n# }\\n# }\\n# # fn main() {\\n# let simulated_user_specified_value = 10;\\n# let simulated_random_number = 7;\\n# # generate_workout(simulated_user_specified_value, simulated_random_number);\\n# } Listing 13-2: Adding optional type annotations of the parameter and return value types in the closure With type annotations added, the syntax of closures looks more similar to the syntax of functions. Here, we define a function that adds 1 to its parameter and a closure that has the same behavior, for comparison. We‚Äôve added some spaces to line up the relevant parts. This illustrates how closure syntax is similar to function syntax except for the use of pipes and the amount of syntax that is optional: fn add_one_v1 (x: u32) -> u32 { x + 1 }\\nlet add_one_v2 = |x: u32| -> u32 { x + 1 };\\nlet add_one_v3 = |x| { x + 1 };\\nlet add_one_v4 = |x| x + 1 ; The first line shows a function definition and the second line shows a fully annotated closure definition. In the third line, we remove the type annotations from the closure definition. In the fourth line, we remove the brackets, which are optional because the closure body has only one expression. These are all valid definitions that will produce the same behavior when they‚Äôre called. The add_one_v3 and add_one_v4 lines require the closures to be evaluated to be able to compile because the types will be inferred from their usage. This is similar to let v = Vec::new(); needing either type annotations or values of some type to be inserted into the Vec for Rust to be able to infer the type. For closure definitions, the compiler will infer one concrete type for each of their parameters and for their return value. For instance, Listing 13-3 shows the definition of a short closure that just returns the value it receives as a parameter. This closure isn‚Äôt very useful except for the purposes of this example. Note that we haven‚Äôt added any type annotations to the definition. Because there are no type annotations, we can call the closure with any type, which we‚Äôve done here with String the first time. If we then try to call example_closure with an integer, we‚Äôll get an error. Filename: src/main.rs # fn main() { let example_closure = |x| x; let s = example_closure(String::from(\\"hello\\")); let n = example_closure(5);\\n# } Listing 13-3: Attempting to call a closure whose types are inferred with two different types The compiler gives us this error: $ cargo run Compiling closure-example v0.1.0 (file:///projects/closure-example)\\nerror[E0308]: mismatched types --> src/main.rs:5:29 |\\n5 | let n = example_closure(5); | --------------- ^- help: try using a conversion method: `.to_string()` | | | | | expected `String`, found integer | arguments to this function are incorrect |\\nnote: expected because the closure was earlier called with an argument of type `String` --> src/main.rs:4:29 |\\n4 | let s = example_closure(String::from(\\"hello\\")); | --------------- ^^^^^^^^^^^^^^^^^^^^^ expected because this argument is of type `String` | | | in this closure call\\nnote: closure parameter defined here --> src/main.rs:2:28 |\\n2 | let example_closure = |x| x; | ^ For more information about this error, try `rustc --explain E0308`.\\nerror: could not compile `closure-example` (bin \\"closure-example\\") due to 1 previous error The first time we call example_closure with the String value, the compiler infers the type of x and the return type of the closure to be String. Those types are then locked into the closure in example_closure, and we get a type error when we next try to use a different type with the same closure.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Closures ¬ª Inferring and Annotating Closure Types","id":"236","title":"Inferring and Annotating Closure Types"},"237":{"body":"Closures can capture values from their environment in three ways, which directly map to the three ways a function can take a parameter: borrowing immutably, borrowing mutably, and taking ownership. The closure will decide which of these to use based on what the body of the function does with the captured values. In Listing 13-4, we define a closure that captures an immutable reference to the vector named list because it only needs an immutable reference to print the value. Filename: src/main.rs fn main() { let list = vec![1, 2, 3]; println!(\\"Before defining closure: {list:?}\\"); let only_borrows = || println!(\\"From closure: {list:?}\\"); println!(\\"Before calling closure: {list:?}\\"); only_borrows(); println!(\\"After calling closure: {list:?}\\");\\n} Listing 13-4: Defining and calling a closure that captures an immutable reference This example also illustrates that a variable can bind to a closure definition, and we can later call the closure by using the variable name and parentheses as if the variable name were a function name. Because we can have multiple immutable references to list at the same time, list is still accessible from the code before the closure definition, after the closure definition but before the closure is called, and after the closure is called. This code compiles, runs, and prints: $ cargo run Compiling closure-example v0.1.0 (file:///projects/closure-example) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.43s Running `target/debug/closure-example`\\nBefore defining closure: [1, 2, 3]\\nBefore calling closure: [1, 2, 3]\\nFrom closure: [1, 2, 3]\\nAfter calling closure: [1, 2, 3] Next, in Listing 13-5, we change the closure body so that it adds an element to the list vector. The closure now captures a mutable reference. Filename: src/main.rs fn main() { let mut list = vec![1, 2, 3]; println!(\\"Before defining closure: {list:?}\\"); let mut borrows_mutably = || list.push(7); borrows_mutably(); println!(\\"After calling closure: {list:?}\\");\\n} Listing 13-5: Defining and calling a closure that captures a mutable reference This code compiles, runs, and prints: $ cargo run Compiling closure-example v0.1.0 (file:///projects/closure-example) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.43s Running `target/debug/closure-example`\\nBefore defining closure: [1, 2, 3]\\nAfter calling closure: [1, 2, 3, 7] Note that there‚Äôs no longer a println! between the definition and the call of the borrows_mutably closure: When borrows_mutably is defined, it captures a mutable reference to list. We don‚Äôt use the closure again after the closure is called, so the mutable borrow ends. Between the closure definition and the closure call, an immutable borrow to print isn‚Äôt allowed, because no other borrows are allowed when there‚Äôs a mutable borrow. Try adding a println! there to see what error message you get! If you want to force the closure to take ownership of the values it uses in the environment even though the body of the closure doesn‚Äôt strictly need ownership, you can use the move keyword before the parameter list. This technique is mostly useful when passing a closure to a new thread to move the data so that it‚Äôs owned by the new thread. We‚Äôll discuss threads and why you would want to use them in detail in Chapter 16 when we talk about concurrency, but for now, let‚Äôs briefly explore spawning a new thread using a closure that needs the move keyword. Listing 13-6 shows Listing 13-4 modified to print the vector in a new thread rather than in the main thread. Filename: src/main.rs use std::thread; fn main() { let list = vec![1, 2, 3]; println!(\\"Before defining closure: {list:?}\\"); thread::spawn(move || println!(\\"From thread: {list:?}\\")) .join() .unwrap();\\n} Listing 13-6: Using move to force the closure for the thread to take ownership of list We spawn a new thread, giving the thread a closure to run as an argument. The closure body prints out the list. In Listing 13-4, the closure only captured list using an immutable reference because that‚Äôs the least amount of access to list needed to print it. In this example, even though the closure body still only needs an immutable reference, we need to specify that list should be moved into the closure by putting the move keyword at the beginning of the closure definition. If the main thread performed more operations before calling join on the new thread, the new thread might finish before the rest of the main thread finishes, or the main thread might finish first. If the main thread maintained ownership of list but ended before the new thread and drops list, the immutable reference in the thread would be invalid. Therefore, the compiler requires that list be moved into the closure given to the new thread so that the reference will be valid. Try removing the move keyword or using list in the main thread after the closure is defined to see what compiler errors you get!","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Closures ¬ª Capturing References or Moving Ownership","id":"237","title":"Capturing References or Moving Ownership"},"238":{"body":"Once a closure has captured a reference or captured ownership of a value from the environment where the closure is defined (thus affecting what, if anything, is moved into the closure), the code in the body of the closure defines what happens to the references or values when the closure is evaluated later (thus affecting what, if anything, is moved out of the closure). A closure body can do any of the following: Move a captured value out of the closure, mutate the captured value, neither move nor mutate the value, or capture nothing from the environment to begin with. The way a closure captures and handles values from the environment affects which traits the closure implements, and traits are how functions and structs can specify what kinds of closures they can use. Closures will automatically implement one, two, or all three of these Fn traits, in an additive fashion, depending on how the closure‚Äôs body handles the values: FnOnce applies to closures that can be called once. All closures implement at least this trait because all closures can be called. A closure that moves captured values out of its body will only implement FnOnce and none of the other Fn traits because it can only be called once. FnMut applies to closures that don‚Äôt move captured values out of their body but might mutate the captured values. These closures can be called more than once. Fn applies to closures that don‚Äôt move captured values out of their body and don‚Äôt mutate captured values, as well as closures that capture nothing from their environment. These closures can be called more than once without mutating their environment, which is important in cases such as calling a closure multiple times concurrently. Let‚Äôs look at the definition of the unwrap_or_else method on Option<T> that we used in Listing 13-1: impl<T> Option<T> { pub fn unwrap_or_else<F>(self, f: F) -> T where F: FnOnce() -> T { match self { Some(x) => x, None => f(), } }\\n} Recall that T is the generic type representing the type of the value in the Some variant of an Option. That type T is also the return type of the unwrap_or_else function: Code that calls unwrap_or_else on an Option<String>, for example, will get a String. Next, notice that the unwrap_or_else function has the additional generic type parameter F. The F type is the type of the parameter named f, which is the closure we provide when calling unwrap_or_else. The trait bound specified on the generic type F is FnOnce() -> T, which means F must be able to be called once, take no arguments, and return a T. Using FnOnce in the trait bound expresses the constraint that unwrap_or_else will not call f more than once. In the body of unwrap_or_else, we can see that if the Option is Some, f won‚Äôt be called. If the Option is None, f will be called once. Because all closures implement FnOnce, unwrap_or_else accepts all three kinds of closures and is as flexible as it can be. Note: If what we want to do doesn‚Äôt require capturing a value from the environment, we can use the name of a function rather than a closure where we need something that implements one of the Fn traits. For example, on an Option<Vec<T>> value, we could call unwrap_or_else(Vec::new) to get a new, empty vector if the value is None. The compiler automatically implements whichever of the Fn traits is applicable for a function definition. Now let‚Äôs look at the standard library method sort_by_key, defined on slices, to see how that differs from unwrap_or_else and why sort_by_key uses FnMut instead of FnOnce for the trait bound. The closure gets one argument in the form of a reference to the current item in the slice being considered, and it returns a value of type K that can be ordered. This function is useful when you want to sort a slice by a particular attribute of each item. In Listing 13-7, we have a list of Rectangle instances, and we use sort_by_key to order them by their width attribute from low to high. Filename: src/main.rs #[derive(Debug)]\\nstruct Rectangle { width: u32, height: u32,\\n} fn main() { let mut list = [ Rectangle { width: 10, height: 1 }, Rectangle { width: 3, height: 5 }, Rectangle { width: 7, height: 12 }, ]; list.sort_by_key(|r| r.width); println!(\\"{list:#?}\\");\\n} Listing 13-7: Using sort_by_key to order rectangles by width This code prints: $ cargo run Compiling rectangles v0.1.0 (file:///projects/rectangles) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.41s Running `target/debug/rectangles`\\n[ Rectangle { width: 3, height: 5, }, Rectangle { width: 7, height: 12, }, Rectangle { width: 10, height: 1, },\\n] The reason sort_by_key is defined to take an FnMut closure is that it calls the closure multiple times: once for each item in the slice. The closure |r| r.width doesn‚Äôt capture, mutate, or move anything out from its environment, so it meets the trait bound requirements. In contrast, Listing 13-8 shows an example of a closure that implements just the FnOnce trait, because it moves a value out of the environment. The compiler won‚Äôt let us use this closure with sort_by_key. Filename: src/main.rs #[derive(Debug)]\\nstruct Rectangle { width: u32, height: u32,\\n} fn main() { let mut list = [ Rectangle { width: 10, height: 1 }, Rectangle { width: 3, height: 5 }, Rectangle { width: 7, height: 12 }, ]; let mut sort_operations = vec![]; let value = String::from(\\"closure called\\"); list.sort_by_key(|r| { sort_operations.push(value); r.width }); println!(\\"{list:#?}\\");\\n} Listing 13-8: Attempting to use an FnOnce closure with sort_by_key This is a contrived, convoluted way (that doesn‚Äôt work) to try to count the number of times sort_by_key calls the closure when sorting list. This code attempts to do this counting by pushing value‚Äîa String from the closure‚Äôs environment‚Äîinto the sort_operations vector. The closure captures value and then moves value out of the closure by transferring ownership of value to the sort_operations vector. This closure can be called once; trying to call it a second time wouldn‚Äôt work, because value would no longer be in the environment to be pushed into sort_operations again! Therefore, this closure only implements FnOnce. When we try to compile this code, we get this error that value can‚Äôt be moved out of the closure because the closure must implement FnMut: $ cargo run Compiling rectangles v0.1.0 (file:///projects/rectangles)\\nerror[E0507]: cannot move out of `value`, a captured variable in an `FnMut` closure --> src/main.rs:18:30 |\\n15 | let value = String::from(\\"closure called\\"); | ----- captured outer variable\\n16 |\\n17 | list.sort_by_key(|r| { | --- captured by this `FnMut` closure\\n18 | sort_operations.push(value); | ^^^^^ move occurs because `value` has type `String`, which does not implement the `Copy` trait |\\nhelp: consider cloning the value if the performance cost is acceptable |\\n18 | sort_operations.push(value.clone()); | ++++++++ For more information about this error, try `rustc --explain E0507`.\\nerror: could not compile `rectangles` (bin \\"rectangles\\") due to 1 previous error The error points to the line in the closure body that moves value out of the environment. To fix this, we need to change the closure body so that it doesn‚Äôt move values out of the environment. Keeping a counter in the environment and incrementing its value in the closure body is a more straightforward way to count the number of times the closure is called. The closure in Listing 13-9 works with sort_by_key because it is only capturing a mutable reference to the num_sort_operations counter and can therefore be called more than once. Filename: src/main.rs #[derive(Debug)]\\nstruct Rectangle { width: u32, height: u32,\\n} fn main() { let mut list = [ Rectangle { width: 10, height: 1 }, Rectangle { width: 3, height: 5 }, Rectangle { width: 7, height: 12 }, ]; let mut num_sort_operations = 0; list.sort_by_key(|r| { num_sort_operations += 1; r.width }); println!(\\"{list:#?}, sorted in {num_sort_operations} operations\\");\\n} Listing 13-9: Using an FnMut closure with sort_by_key is allowed. The Fn traits are important when defining or using functions or types that make use of closures. In the next section, we‚Äôll discuss iterators. Many iterator methods take closure arguments, so keep these closure details in mind as we continue!","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Closures ¬ª Moving Captured Values Out of Closures","id":"238","title":"Moving Captured Values Out of Closures"},"239":{"body":"The iterator pattern allows you to perform some task on a sequence of items in turn. An iterator is responsible for the logic of iterating over each item and determining when the sequence has finished. When you use iterators, you don‚Äôt have to reimplement that logic yourself. In Rust, iterators are lazy , meaning they have no effect until you call methods that consume the iterator to use it up. For example, the code in Listing 13-10 creates an iterator over the items in the vector v1 by calling the iter method defined on Vec<T>. This code by itself doesn‚Äôt do anything useful. Filename: src/main.rs # fn main() { let v1 = vec![1, 2, 3]; let v1_iter = v1.iter();\\n# } Listing 13-10: Creating an iterator The iterator is stored in the v1_iter variable. Once we‚Äôve created an iterator, we can use it in a variety of ways. In Listing 3-5, we iterated over an array using a for loop to execute some code on each of its items. Under the hood, this implicitly created and then consumed an iterator, but we glossed over how exactly that works until now. In the example in Listing 13-11, we separate the creation of the iterator from the use of the iterator in the for loop. When the for loop is called using the iterator in v1_iter, each element in the iterator is used in one iteration of the loop, which prints out each value. Filename: src/main.rs # fn main() { let v1 = vec![1, 2, 3]; let v1_iter = v1.iter(); for val in v1_iter { println!(\\"Got: {val}\\"); }\\n# } Listing 13-11: Using an iterator in a for loop In languages that don‚Äôt have iterators provided by their standard libraries, you would likely write this same functionality by starting a variable at index 0, using that variable to index into the vector to get a value, and incrementing the variable value in a loop until it reached the total number of items in the vector. Iterators handle all of that logic for you, cutting down on repetitive code you could potentially mess up. Iterators give you more flexibility to use the same logic with many different kinds of sequences, not just data structures you can index into, like vectors. Let‚Äôs examine how iterators do that.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Processing a Series of Items with Iterators ¬ª Processing a Series of Items with Iterators","id":"239","title":"Processing a Series of Items with Iterators"},"24":{"body":"Next, make a new source file and call it main.rs . Rust files always end with the .rs extension. If you‚Äôre using more than one word in your filename, the convention is to use an underscore to separate them. For example, use hello_world.rs rather than helloworld.rs . Now open the main.rs file you just created and enter the code in Listing 1-1. Filename: main.rs fn main() { println!(\\"Hello, world!\\");\\n} Listing 1-1: A program that prints Hello, world! Save the file and go back to your terminal window in the ~/projects/hello_world directory. On Linux or macOS, enter the following commands to compile and run the file: $ rustc main.rs\\n$ ./main\\nHello, world! On Windows, enter the command .\\\\main instead of ./main: > rustc main.rs\\n> .\\\\main\\nHello, world! Regardless of your operating system, the string Hello, world! should print to the terminal. If you don‚Äôt see this output, refer back to the ‚ÄúTroubleshooting‚Äù part of the Installation section for ways to get help. If Hello, world! did print, congratulations! You‚Äôve officially written a Rust program. That makes you a Rust programmer‚Äîwelcome!","breadcrumbs":"Getting Started ¬ª Hello, World! ¬ª Rust Program Basics","id":"24","title":"Rust Program Basics"},"240":{"body":"All iterators implement a trait named Iterator that is defined in the standard library. The definition of the trait looks like this: pub trait Iterator { type Item; fn next(&mut self) -> Option<Self::Item>; // methods with default implementations elided\\n} Notice that this definition uses some new syntax: type Item and Self::Item, which are defining an associated type with this trait. We‚Äôll talk about associated types in depth in Chapter 20. For now, all you need to know is that this code says implementing the Iterator trait requires that you also define an Item type, and this Item type is used in the return type of the next method. In other words, the Item type will be the type returned from the iterator. The Iterator trait only requires implementors to define one method: the next method, which returns one item of the iterator at a time, wrapped in Some, and, when iteration is over, returns None. We can call the next method on iterators directly; Listing 13-12 demonstrates what values are returned from repeated calls to next on the iterator created from the vector. Filename: src/lib.rs # #[cfg(test)]\\n# mod tests { #[test] fn iterator_demonstration() { let v1 = vec![1, 2, 3]; let mut v1_iter = v1.iter(); assert_eq!(v1_iter.next(), Some(&1)); assert_eq!(v1_iter.next(), Some(&2)); assert_eq!(v1_iter.next(), Some(&3)); assert_eq!(v1_iter.next(), None); }\\n# } Listing 13-12: Calling the next method on an iterator Note that we needed to make v1_iter mutable: Calling the next method on an iterator changes internal state that the iterator uses to keep track of where it is in the sequence. In other words, this code consumes , or uses up, the iterator. Each call to next eats up an item from the iterator. We didn‚Äôt need to make v1_iter mutable when we used a for loop, because the loop took ownership of v1_iter and made it mutable behind the scenes. Also note that the values we get from the calls to next are immutable references to the values in the vector. The iter method produces an iterator over immutable references. If we want to create an iterator that takes ownership of v1 and returns owned values, we can call into_iter instead of iter. Similarly, if we want to iterate over mutable references, we can call iter_mut instead of iter.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Processing a Series of Items with Iterators ¬ª The Iterator Trait and the next Method","id":"240","title":"The Iterator Trait and the next Method"},"241":{"body":"The Iterator trait has a number of different methods with default implementations provided by the standard library; you can find out about these methods by looking in the standard library API documentation for the Iterator trait. Some of these methods call the next method in their definition, which is why you‚Äôre required to implement the next method when implementing the Iterator trait. Methods that call next are called consuming adapters because calling them uses up the iterator. One example is the sum method, which takes ownership of the iterator and iterates through the items by repeatedly calling next, thus consuming the iterator. As it iterates through, it adds each item to a running total and returns the total when iteration is complete. Listing 13-13 has a test illustrating a use of the sum method. Filename: src/lib.rs # #[cfg(test)]\\n# mod tests { #[test] fn iterator_sum() { let v1 = vec![1, 2, 3]; let v1_iter = v1.iter(); let total: i32 = v1_iter.sum(); assert_eq!(total, 6); }\\n# } Listing 13-13: Calling the sum method to get the total of all items in the iterator We aren‚Äôt allowed to use v1_iter after the call to sum, because sum takes ownership of the iterator we call it on.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Processing a Series of Items with Iterators ¬ª Methods That Consume the Iterator","id":"241","title":"Methods That Consume the Iterator"},"242":{"body":"Iterator adapters are methods defined on the Iterator trait that don‚Äôt consume the iterator. Instead, they produce different iterators by changing some aspect of the original iterator. Listing 13-14 shows an example of calling the iterator adapter method map, which takes a closure to call on each item as the items are iterated through. The map method returns a new iterator that produces the modified items. The closure here creates a new iterator in which each item from the vector will be incremented by 1. Filename: src/main.rs # fn main() { let v1: Vec<i32> = vec![1, 2, 3]; v1.iter().map(|x| x + 1);\\n# } Listing 13-14: Calling the iterator adapter map to create a new iterator However, this code produces a warning: $ cargo run Compiling iterators v0.1.0 (file:///projects/iterators)\\nwarning: unused `Map` that must be used --> src/main.rs:4:5 |\\n4 | v1.iter().map(|x| x + 1); | ^^^^^^^^^^^^^^^^^^^^^^^^ | = note: iterators are lazy and do nothing unless consumed = note: `#[warn(unused_must_use)]` on by default\\nhelp: use `let _ = ...` to ignore the resulting value |\\n4 | let _ = v1.iter().map(|x| x + 1); | +++++++ warning: `iterators` (bin \\"iterators\\") generated 1 warning Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.47s Running `target/debug/iterators` The code in Listing 13-14 doesn‚Äôt do anything; the closure we‚Äôve specified never gets called. The warning reminds us why: Iterator adapters are lazy, and we need to consume the iterator here. To fix this warning and consume the iterator, we‚Äôll use the collect method, which we used with env::args in Listing 12-1. This method consumes the iterator and collects the resultant values into a collection data type. In Listing 13-15, we collect the results of iterating over the iterator that‚Äôs returned from the call to map into a vector. This vector will end up containing each item from the original vector, incremented by 1. Filename: src/main.rs # fn main() { let v1: Vec<i32> = vec![1, 2, 3]; let v2: Vec<_> = v1.iter().map(|x| x + 1).collect(); assert_eq!(v2, vec![2, 3, 4]);\\n# } Listing 13-15: Calling the map method to create a new iterator, and then calling the collect method to consume the new iterator and create a vector Because map takes a closure, we can specify any operation we want to perform on each item. This is a great example of how closures let you customize some behavior while reusing the iteration behavior that the Iterator trait provides. You can chain multiple calls to iterator adapters to perform complex actions in a readable way. But because all iterators are lazy, you have to call one of the consuming adapter methods to get results from calls to iterator adapters.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Processing a Series of Items with Iterators ¬ª Methods That Produce Other Iterators","id":"242","title":"Methods That Produce Other Iterators"},"243":{"body":"Many iterator adapters take closures as arguments, and commonly the closures we‚Äôll specify as arguments to iterator adapters will be closures that capture their environment. For this example, we‚Äôll use the filter method that takes a closure. The closure gets an item from the iterator and returns a bool. If the closure returns true, the value will be included in the iteration produced by filter. If the closure returns false, the value won‚Äôt be included. In Listing 13-16, we use filter with a closure that captures the shoe_size variable from its environment to iterate over a collection of Shoe struct instances. It will return only shoes that are the specified size. Filename: src/lib.rs #[derive(PartialEq, Debug)]\\nstruct Shoe { size: u32, style: String,\\n} fn shoes_in_size(shoes: Vec<Shoe>, shoe_size: u32) -> Vec<Shoe> { shoes.into_iter().filter(|s| s.size == shoe_size).collect()\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn filters_by_size() { let shoes = vec![ Shoe { size: 10, style: String::from(\\"sneaker\\"), }, Shoe { size: 13, style: String::from(\\"sandal\\"), }, Shoe { size: 10, style: String::from(\\"boot\\"), }, ]; let in_my_size = shoes_in_size(shoes, 10); assert_eq!( in_my_size, vec![ Shoe { size: 10, style: String::from(\\"sneaker\\") }, Shoe { size: 10, style: String::from(\\"boot\\") }, ] ); }\\n} Listing 13-16: Using the filter method with a closure that captures shoe_size The shoes_in_size function takes ownership of a vector of shoes and a shoe size as parameters. It returns a vector containing only shoes of the specified size. In the body of shoes_in_size, we call into_iter to create an iterator that takes ownership of the vector. Then, we call filter to adapt that iterator into a new iterator that only contains elements for which the closure returns true. The closure captures the shoe_size parameter from the environment and compares the value with each shoe‚Äôs size, keeping only shoes of the size specified. Finally, calling collect gathers the values returned by the adapted iterator into a vector that‚Äôs returned by the function. The test shows that when we call shoes_in_size, we get back only shoes that have the same size as the value we specified.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Processing a Series of Items with Iterators ¬ª Closures That Capture Their Environment","id":"243","title":"Closures That Capture Their Environment"},"244":{"body":"With this new knowledge about iterators, we can improve the I/O project in Chapter 12 by using iterators to make places in the code clearer and more concise. Let‚Äôs look at how iterators can improve our implementation of the Config::build function and the search function.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Improving Our I/O Project ¬ª Improving Our I/O Project","id":"244","title":"Improving Our I/O Project"},"245":{"body":"In Listing 12-6, we added code that took a slice of String values and created an instance of the Config struct by indexing into the slice and cloning the values, allowing the Config struct to own those values. In Listing 13-17, we‚Äôve reproduced the implementation of the Config::build function as it was in Listing 12-23. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# # fn main() {\\n# let args: Vec<String> = env::args().collect();\\n# # let config = Config::build(&args).unwrap_or_else(|err| {\\n# println!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# println!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# impl Config { fn build(args: &[String]) -> Result<Config, &\'static str> { if args.len() < 3 { return Err(\\"not enough arguments\\"); } let query = args[1].clone(); let file_path = args[2].clone(); let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok(); Ok(Config { query, file_path, ignore_case, }) }\\n}\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 13-17: Reproduction of the Config::build function from Listing 12-23 At the time, we said not to worry about the inefficient clone calls because we would remove them in the future. Well, that time is now! We needed clone here because we have a slice with String elements in the parameter args, but the build function doesn‚Äôt own args. To return ownership of a Config instance, we had to clone the values from the query and file_path fields of Config so that the Config instance can own its values. With our new knowledge about iterators, we can change the build function to take ownership of an iterator as its argument instead of borrowing a slice. We‚Äôll use the iterator functionality instead of the code that checks the length of the slice and indexes into specific locations. This will clarify what the Config::build function is doing because the iterator will access the values. Once Config::build takes ownership of the iterator and stops using indexing operations that borrow, we can move the String values from the iterator into Config rather than calling clone and making a new allocation. Using the Returned Iterator Directly Open your I/O project‚Äôs src/main.rs file, which should look like this: Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# fn main() { let args: Vec<String> = env::args().collect(); let config = Config::build(&args).unwrap_or_else(|err| { eprintln!(\\"Problem parsing arguments: {err}\\"); process::exit(1); }); // --snip--\\n# # if let Err(e) = run(config) {\\n# eprintln!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n}\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok();\\n# # Ok(Config {\\n# query,\\n# file_path,\\n# ignore_case,\\n# })\\n# }\\n# }\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } We‚Äôll first change the start of the main function that we had in Listing 12-24 to the code in Listing 13-18, which this time uses an iterator. This won‚Äôt compile until we update Config::build as well. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# fn main() { let config = Config::build(env::args()).unwrap_or_else(|err| { eprintln!(\\"Problem parsing arguments: {err}\\"); process::exit(1); }); // --snip--\\n# # if let Err(e) = run(config) {\\n# eprintln!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n}\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# # impl Config {\\n# fn build(args: &[String]) -> Result<Config, &\'static str> {\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok();\\n# # Ok(Config {\\n# query,\\n# file_path,\\n# ignore_case,\\n# })\\n# }\\n# }\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 13-18: Passing the return value of env::args to Config::build The env::args function returns an iterator! Rather than collecting the iterator values into a vector and then passing a slice to Config::build, now we‚Äôre passing ownership of the iterator returned from env::args to Config::build directly. Next, we need to update the definition of Config::build. Let‚Äôs change the signature of Config::build to look like Listing 13-19. This still won‚Äôt compile, because we need to update the function body. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# # fn main() {\\n# let config = Config::build(env::args()).unwrap_or_else(|err| {\\n# eprintln!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# eprintln!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# impl Config { fn build( mut args: impl Iterator<Item = String>, ) -> Result<Config, &\'static str> { // --snip--\\n# if args.len() < 3 {\\n# return Err(\\"not enough arguments\\");\\n# }\\n# # let query = args[1].clone();\\n# let file_path = args[2].clone();\\n# # let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok();\\n# # Ok(Config {\\n# query,\\n# file_path,\\n# ignore_case,\\n# })\\n# }\\n# }\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 13-19: Updating the signature of Config::build to expect an iterator The standard library documentation for the env::args function shows that the type of the iterator it returns is std::env::Args, and that type implements the Iterator trait and returns String values. We‚Äôve updated the signature of the Config::build function so that the parameter args has a generic type with the trait bounds impl Iterator<Item = String> instead of &[String]. This usage of the impl Trait syntax we discussed in the ‚ÄúUsing Traits as Parameters‚Äù section of Chapter 10 means that args can be any type that implements the Iterator trait and returns String items. Because we‚Äôre taking ownership of args and we‚Äôll be mutating args by iterating over it, we can add the mut keyword into the specification of the args parameter to make it mutable. Using Iterator Trait Methods Next, we‚Äôll fix the body of Config::build. Because args implements the Iterator trait, we know we can call the next method on it! Listing 13-20 updates the code from Listing 12-23 to use the next method. Filename: src/main.rs # use std::env;\\n# use std::error::Error;\\n# use std::fs;\\n# use std::process;\\n# # use minigrep::{search, search_case_insensitive};\\n# # fn main() {\\n# let config = Config::build(env::args()).unwrap_or_else(|err| {\\n# eprintln!(\\"Problem parsing arguments: {err}\\");\\n# process::exit(1);\\n# });\\n# # if let Err(e) = run(config) {\\n# eprintln!(\\"Application error: {e}\\");\\n# process::exit(1);\\n# }\\n# }\\n# # pub struct Config {\\n# pub query: String,\\n# pub file_path: String,\\n# pub ignore_case: bool,\\n# }\\n# impl Config { fn build( mut args: impl Iterator<Item = String>, ) -> Result<Config, &\'static str> { args.next(); let query = match args.next() { Some(arg) => arg, None => return Err(\\"Didn\'t get a query string\\"), }; let file_path = match args.next() { Some(arg) => arg, None => return Err(\\"Didn\'t get a file path\\"), }; let ignore_case = env::var(\\"IGNORE_CASE\\").is_ok(); Ok(Config { query, file_path, ignore_case, }) }\\n}\\n# # fn run(config: Config) -> Result<(), Box<dyn Error>> {\\n# let contents = fs::read_to_string(config.file_path)?;\\n# # let results = if config.ignore_case {\\n# search_case_insensitive(&config.query, &contents)\\n# } else {\\n# search(&config.query, &contents)\\n# };\\n# # for line in results {\\n# println!(\\"{line}\\");\\n# }\\n# # Ok(())\\n# } Listing 13-20: Changing the body of Config::build to use iterator methods Remember that the first value in the return value of env::args is the name of the program. We want to ignore that and get to the next value, so first we call next and do nothing with the return value. Then, we call next to get the value we want to put in the query field of Config. If next returns Some, we use a match to extract the value. If it returns None, it means not enough arguments were given, and we return early with an Err value. We do the same thing for the file_path value.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Improving Our I/O Project ¬ª Removing a clone Using an Iterator","id":"245","title":"Removing a clone Using an Iterator"},"246":{"body":"We can also take advantage of iterators in the search function in our I/O project, which is reproduced here in Listing 13-21 as it was in Listing 12-19. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { let mut results = Vec::new(); for line in contents.lines() { if line.contains(query) { results.push(line); } } results\\n}\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn one_result() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# } Listing 13-21: The implementation of the search function from Listing 12-19 We can write this code in a more concise way using iterator adapter methods. Doing so also lets us avoid having a mutable intermediate results vector. The functional programming style prefers to minimize the amount of mutable state to make code clearer. Removing the mutable state might enable a future enhancement to make searching happen in parallel because we wouldn‚Äôt have to manage concurrent access to the results vector. Listing 13-22 shows this change. Filename: src/lib.rs pub fn search<\'a>(query: &str, contents: &\'a str) -> Vec<&\'a str> { contents .lines() .filter(|line| line.contains(query)) .collect()\\n}\\n# # pub fn search_case_insensitive<\'a>(\\n# query: &str,\\n# contents: &\'a str,\\n# ) -> Vec<&\'a str> {\\n# let query = query.to_lowercase();\\n# let mut results = Vec::new();\\n# # for line in contents.lines() {\\n# if line.to_lowercase().contains(&query) {\\n# results.push(line);\\n# }\\n# }\\n# # results\\n# }\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# # #[test]\\n# fn case_sensitive() {\\n# let query = \\"duct\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\n# Duct tape.\\";\\n# # assert_eq!(vec![\\"safe, fast, productive.\\"], search(query, contents));\\n# }\\n# # #[test]\\n# fn case_insensitive() {\\n# let query = \\"rUsT\\";\\n# let contents = \\"\\\\\\n# Rust:\\n# safe, fast, productive.\\n# Pick three.\\n# Trust me.\\";\\n# # assert_eq!(\\n# vec![\\"Rust:\\", \\"Trust me.\\"],\\n# search_case_insensitive(query, contents)\\n# );\\n# }\\n# } Listing 13-22: Using iterator adapter methods in the implementation of the search function Recall that the purpose of the search function is to return all lines in contents that contain the query. Similar to the filter example in Listing 13-16, this code uses the filter adapter to keep only the lines for which line.contains(query) returns true. We then collect the matching lines into another vector with collect. Much simpler! Feel free to make the same change to use iterator methods in the search_case_insensitive function as well. For a further improvement, return an iterator from the search function by removing the call to collect and changing the return type to impl Iterator<Item = &\'a str> so that the function becomes an iterator adapter. Note that you‚Äôll also need to update the tests! Search through a large file using your minigrep tool before and after making this change to observe the difference in behavior. Before this change, the program won‚Äôt print any results until it has collected all of the results, but after the change, the results will be printed as each matching line is found because the for loop in the run function is able to take advantage of the laziness of the iterator.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Improving Our I/O Project ¬ª Clarifying Code with Iterator Adapters","id":"246","title":"Clarifying Code with Iterator Adapters"},"247":{"body":"The next logical question is which style you should choose in your own code and why: the original implementation in Listing 13-21 or the version using iterators in Listing 13-22 (assuming we‚Äôre collecting all the results before returning them rather than returning the iterator). Most Rust programmers prefer to use the iterator style. It‚Äôs a bit tougher to get the hang of at first, but once you get a feel for the various iterator adapters and what they do, iterators can be easier to understand. Instead of fiddling with the various bits of looping and building new vectors, the code focuses on the high-level objective of the loop. This abstracts away some of the commonplace code so that it‚Äôs easier to see the concepts that are unique to this code, such as the filtering condition each element in the iterator must pass. But are the two implementations truly equivalent? The intuitive assumption might be that the lower-level loop will be faster. Let‚Äôs talk about performance.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Improving Our I/O Project ¬ª Choosing Between Loops and Iterators","id":"247","title":"Choosing Between Loops and Iterators"},"248":{"body":"To determine whether to use loops or iterators, you need to know which implementation is faster: the version of the search function with an explicit for loop or the version with iterators. We ran a benchmark by loading the entire contents of The Adventures of Sherlock Holmes by Sir Arthur Conan Doyle into a String and looking for the word the in the contents. Here are the results of the benchmark on the version of search using the for loop and the version using iterators: test bench_search_for ... bench: 19,620,300 ns/iter (+/- 915,700)\\ntest bench_search_iter ... bench: 19,234,900 ns/iter (+/- 657,200) The two implementations have similar performance! We won‚Äôt explain the benchmark code here because the point is not to prove that the two versions are equivalent but to get a general sense of how these two implementations compare performance-wise. For a more comprehensive benchmark, you should check using various texts of various sizes as the contents, different words and words of different lengths as the query, and all kinds of other variations. The point is this: Iterators, although a high-level abstraction, get compiled down to roughly the same code as if you‚Äôd written the lower-level code yourself. Iterators are one of Rust‚Äôs zero-cost abstractions , by which we mean that using the abstraction imposes no additional runtime overhead. This is analogous to how Bjarne Stroustrup, the original designer and implementor of C++, defines zero-overhead in his 2012 ETAPS keynote presentation ‚ÄúFoundations of C++‚Äù: In general, C++ implementations obey the zero-overhead principle: What you don‚Äôt use, you don‚Äôt pay for. And further: What you do use, you couldn‚Äôt hand code any better. In many cases, Rust code using iterators compiles to the same assembly you‚Äôd write by hand. Optimizations such as loop unrolling and eliminating bounds checking on array access apply and make the resultant code extremely efficient. Now that you know this, you can use iterators and closures without fear! They make code seem like it‚Äôs higher level but don‚Äôt impose a runtime performance penalty for doing so.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Performance in Loops vs. Iterators ¬ª Performance in Loops vs. Iterators","id":"248","title":"Performance in Loops vs. Iterators"},"249":{"body":"Closures and iterators are Rust features inspired by functional programming language ideas. They contribute to Rust‚Äôs capability to clearly express high-level ideas at low-level performance. The implementations of closures and iterators are such that runtime performance is not affected. This is part of Rust‚Äôs goal to strive to provide zero-cost abstractions. Now that we‚Äôve improved the expressiveness of our I/O project, let‚Äôs look at some more features of cargo that will help us share the project with the world.","breadcrumbs":"Functional Language Features: Iterators and Closures ¬ª Performance in Loops vs. Iterators ¬ª Summary","id":"249","title":"Summary"},"25":{"body":"Let‚Äôs review this ‚ÄúHello, world!‚Äù program in detail. Here‚Äôs the first piece of the puzzle: fn main() { } These lines define a function named main. The main function is special: It is always the first code that runs in every executable Rust program. Here, the first line declares a function named main that has no parameters and returns nothing. If there were parameters, they would go inside the parentheses (()). The function body is wrapped in {}. Rust requires curly brackets around all function bodies. It‚Äôs good style to place the opening curly bracket on the same line as the function declaration, adding one space in between. Note: If you want to stick to a standard style across Rust projects, you can use an automatic formatter tool called rustfmt to format your code in a particular style (more on rustfmt in Appendix D ). The Rust team has included this tool with the standard Rust distribution, as rustc is, so it should already be installed on your computer! The body of the main function holds the following code: println!(\\"Hello, world!\\"); This line does all the work in this little program: It prints text to the screen. There are three important details to notice here. First, println! calls a Rust macro. If it had called a function instead, it would be entered as println (without the !). Rust macros are a way to write code that generates code to extend Rust syntax, and we‚Äôll discuss them in more detail in Chapter 20 . For now, you just need to know that using a ! means that you‚Äôre calling a macro instead of a normal function and that macros don‚Äôt always follow the same rules as functions. Second, you see the \\"Hello, world!\\" string. We pass this string as an argument to println!, and the string is printed to the screen. Third, we end the line with a semicolon (;), which indicates that this expression is over, and the next one is ready to begin. Most lines of Rust code end with a semicolon.","breadcrumbs":"Getting Started ¬ª Hello, World! ¬ª The Anatomy of a Rust Program","id":"25","title":"The Anatomy of a Rust Program"},"250":{"body":"So far, we‚Äôve used only the most basic features of Cargo to build, run, and test our code, but it can do a lot more. In this chapter, we‚Äôll discuss some of its other, more advanced features to show you how to do the following: Customize your build through release profiles. Publish libraries on crates.io . Organize large projects with workspaces. Install binaries from crates.io . Extend Cargo using custom commands. Cargo can do even more than the functionality we cover in this chapter, so for a full explanation of all its features, see its documentation .","breadcrumbs":"More about Cargo and Crates.io ¬ª More About Cargo and Crates.io","id":"250","title":"More About Cargo and Crates.io"},"251":{"body":"In Rust, release profiles are predefined, customizable profiles with different configurations that allow a programmer to have more control over various options for compiling code. Each profile is configured independently of the others. Cargo has two main profiles: the dev profile Cargo uses when you run cargo build, and the release profile Cargo uses when you run cargo build --release. The dev profile is defined with good defaults for development, and the release profile has good defaults for release builds. These profile names might be familiar from the output of your builds: $ cargo build Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.00s\\n$ cargo build --release Finished `release` profile [optimized] target(s) in 0.32s The dev and release are these different profiles used by the compiler. Cargo has default settings for each of the profiles that apply when you haven‚Äôt explicitly added any [profile.*] sections in the project‚Äôs Cargo.toml file. By adding [profile.*] sections for any profile you want to customize, you override any subset of the default settings. For example, here are the default values for the opt-level setting for the dev and release profiles: Filename: Cargo.toml [profile.dev]\\nopt-level = 0 [profile.release]\\nopt-level = 3 The opt-level setting controls the number of optimizations Rust will apply to your code, with a range of 0 to 3. Applying more optimizations extends compiling time, so if you‚Äôre in development and compiling your code often, you‚Äôll want fewer optimizations to compile faster even if the resultant code runs slower. The default opt-level for dev is therefore 0. When you‚Äôre ready to release your code, it‚Äôs best to spend more time compiling. You‚Äôll only compile in release mode once, but you‚Äôll run the compiled program many times, so release mode trades longer compile time for code that runs faster. That is why the default opt-level for the release profile is 3. You can override a default setting by adding a different value for it in Cargo.toml . For example, if we want to use optimization level 1 in the development profile, we can add these two lines to our project‚Äôs Cargo.toml file: Filename: Cargo.toml [profile.dev]\\nopt-level = 1 This code overrides the default setting of 0. Now when we run cargo build, Cargo will use the defaults for the dev profile plus our customization to opt-level. Because we set opt-level to 1, Cargo will apply more optimizations than the default, but not as many as in a release build. For the full list of configuration options and defaults for each profile, see Cargo‚Äôs documentation .","breadcrumbs":"More about Cargo and Crates.io ¬ª Customizing Builds with Release Profiles ¬ª Customizing Builds with Release Profiles","id":"251","title":"Customizing Builds with Release Profiles"},"252":{"body":"We‚Äôve used packages from crates.io as dependencies of our project, but you can also share your code with other people by publishing your own packages. The crate registry at crates.io distributes the source code of your packages, so it primarily hosts code that is open source. Rust and Cargo have features that make your published package easier for people to find and use. We‚Äôll talk about some of these features next and then explain how to publish a package.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Publishing a Crate to Crates.io","id":"252","title":"Publishing a Crate to Crates.io"},"253":{"body":"Accurately documenting your packages will help other users know how and when to use them, so it‚Äôs worth investing the time to write documentation. In Chapter 3, we discussed how to comment Rust code using two slashes, //. Rust also has a particular kind of comment for documentation, known conveniently as a documentation comment , that will generate HTML documentation. The HTML displays the contents of documentation comments for public API items intended for programmers interested in knowing how to use your crate as opposed to how your crate is implemented . Documentation comments use three slashes, ///, instead of two and support Markdown notation for formatting the text. Place documentation comments just before the item they‚Äôre documenting. Listing 14-1 shows documentation comments for an add_one function in a crate named my_crate. Filename: src/lib.rs /// Adds one to the number given.\\n///\\n/// # Examples\\n///\\n/// ```\\n/// let arg = 5;\\n/// let answer = my_crate::add_one(arg);\\n///\\n/// assert_eq!(6, answer);\\n/// ```\\npub fn add_one(x: i32) -> i32 { x + 1\\n} Listing 14-1: A documentation comment for a function Here, we give a description of what the add_one function does, start a section with the heading Examples, and then provide code that demonstrates how to use the add_one function. We can generate the HTML documentation from this documentation comment by running cargo doc. This command runs the rustdoc tool distributed with Rust and puts the generated HTML documentation in the target/doc directory. For convenience, running cargo doc --open will build the HTML for your current crate‚Äôs documentation (as well as the documentation for all of your crate‚Äôs dependencies) and open the result in a web browser. Navigate to the add_one function and you‚Äôll see how the text in the documentation comments is rendered, as shown in Figure 14-1. Figure 14-1: The HTML documentation for the add_one function Commonly Used Sections We used the # Examples Markdown heading in Listing 14-1 to create a section in the HTML with the title ‚ÄúExamples.‚Äù Here are some other sections that crate authors commonly use in their documentation: Panics : These are the scenarios in which the function being documented could panic. Callers of the function who don‚Äôt want their programs to panic should make sure they don‚Äôt call the function in these situations. Errors : If the function returns a Result, describing the kinds of errors that might occur and what conditions might cause those errors to be returned can be helpful to callers so that they can write code to handle the different kinds of errors in different ways. Safety : If the function is unsafe to call (we discuss unsafety in Chapter 20), there should be a section explaining why the function is unsafe and covering the invariants that the function expects callers to uphold. Most documentation comments don‚Äôt need all of these sections, but this is a good checklist to remind you of the aspects of your code users will be interested in knowing about. Documentation Comments as Tests Adding example code blocks in your documentation comments can help demonstrate how to use your library and has an additional bonus: Running cargo test will run the code examples in your documentation as tests! Nothing is better than documentation with examples. But nothing is worse than examples that don‚Äôt work because the code has changed since the documentation was written. If we run cargo test with the documentation for the add_one function from Listing 14-1, we will see a section in the test results that looks like this: Doc-tests my_crate running 1 test\\ntest src/lib.rs - add_one (line 5) ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.27s Now, if we change either the function or the example so that the assert_eq! in the example panics, and run cargo test again, we‚Äôll see that the doc tests catch that the example and the code are out of sync with each other! Contained Item Comments The style of doc comment //! adds documentation to the item that contains the comments rather than to the items following the comments. We typically use these doc comments inside the crate root file ( src/lib.rs by convention) or inside a module to document the crate or the module as a whole. For example, to add documentation that describes the purpose of the my_crate crate that contains the add_one function, we add documentation comments that start with //! to the beginning of the src/lib.rs file, as shown in Listing 14-2. Filename: src/lib.rs //! # My Crate\\n//!\\n//! `my_crate` is a collection of utilities to make performing certain\\n//! calculations more convenient. /// Adds one to the number given.\\n// --snip--\\n# ///\\n# /// # Examples\\n# ///\\n# /// ```\\n# /// let arg = 5;\\n# /// let answer = my_crate::add_one(arg);\\n# ///\\n# /// assert_eq!(6, answer);\\n# /// ```\\n# pub fn add_one(x: i32) -> i32 {\\n# x + 1\\n# } Listing 14-2: The documentation for the my_crate crate as a whole Notice there isn‚Äôt any code after the last line that begins with //!. Because we started the comments with //! instead of ///, we‚Äôre documenting the item that contains this comment rather than an item that follows this comment. In this case, that item is the src/lib.rs file, which is the crate root. These comments describe the entire crate. When we run cargo doc --open, these comments will display on the front page of the documentation for my_crate above the list of public items in the crate, as shown in Figure 14-2. Documentation comments within items are useful for describing crates and modules especially. Use them to explain the overall purpose of the container to help your users understand the crate‚Äôs organization. Figure 14-2: The rendered documentation for my_crate, including the comment describing the crate as a whole","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Making Useful Documentation Comments","id":"253","title":"Making Useful Documentation Comments"},"254":{"body":"The structure of your public API is a major consideration when publishing a crate. People who use your crate are less familiar with the structure than you are and might have difficulty finding the pieces they want to use if your crate has a large module hierarchy. In Chapter 7, we covered how to make items public using the pub keyword, and how to bring items into a scope with the use keyword. However, the structure that makes sense to you while you‚Äôre developing a crate might not be very convenient for your users. You might want to organize your structs in a hierarchy containing multiple levels, but then people who want to use a type you‚Äôve defined deep in the hierarchy might have trouble finding out that type exists. They might also be annoyed at having to enter use my_crate::some_module::another_module::UsefulType; rather than use my_crate::UsefulType;. The good news is that if the structure isn‚Äôt convenient for others to use from another library, you don‚Äôt have to rearrange your internal organization: Instead, you can re-export items to make a public structure that‚Äôs different from your private structure by using pub use. Re-exporting takes a public item in one location and makes it public in another location, as if it were defined in the other location instead. For example, say we made a library named art for modeling artistic concepts. Within this library are two modules: a kinds module containing two enums named PrimaryColor and SecondaryColor and a utils module containing a function named mix, as shown in Listing 14-3. Filename: src/lib.rs //! # Art\\n//!\\n//! A library for modeling artistic concepts. pub mod kinds { /// The primary colors according to the RYB color model. pub enum PrimaryColor { Red, Yellow, Blue, } /// The secondary colors according to the RYB color model. pub enum SecondaryColor { Orange, Green, Purple, }\\n} pub mod utils { use crate::kinds::*; /// Combines two primary colors in equal amounts to create /// a secondary color. pub fn mix(c1: PrimaryColor, c2: PrimaryColor) -> SecondaryColor { // --snip--\\n# unimplemented!(); }\\n} Listing 14-3: An art library with items organized into kinds and utils modules Figure 14-3 shows what the front page of the documentation for this crate generated by cargo doc would look like. Figure 14-3: The front page of the documentation for art that lists the kinds and utils modules Note that the PrimaryColor and SecondaryColor types aren‚Äôt listed on the front page, nor is the mix function. We have to click kinds and utils to see them. Another crate that depends on this library would need use statements that bring the items from art into scope, specifying the module structure that‚Äôs currently defined. Listing 14-4 shows an example of a crate that uses the PrimaryColor and mix items from the art crate. Filename: src/main.rs use art::kinds::PrimaryColor;\\nuse art::utils::mix; fn main() { let red = PrimaryColor::Red; let yellow = PrimaryColor::Yellow; mix(red, yellow);\\n} Listing 14-4: A crate using the art crate‚Äôs items with its internal structure exported The author of the code in Listing 14-4, which uses the art crate, had to figure out that PrimaryColor is in the kinds module and mix is in the utils module. The module structure of the art crate is more relevant to developers working on the art crate than to those using it. The internal structure doesn‚Äôt contain any useful information for someone trying to understand how to use the art crate, but rather causes confusion because developers who use it have to figure out where to look, and must specify the module names in the use statements. To remove the internal organization from the public API, we can modify the art crate code in Listing 14-3 to add pub use statements to re-export the items at the top level, as shown in Listing 14-5. Filename: src/lib.rs //! # Art\\n//!\\n//! A library for modeling artistic concepts. pub use self::kinds::PrimaryColor;\\npub use self::kinds::SecondaryColor;\\npub use self::utils::mix; pub mod kinds { // --snip--\\n# /// The primary colors according to the RYB color model.\\n# pub enum PrimaryColor {\\n# Red,\\n# Yellow,\\n# Blue,\\n# }\\n# # /// The secondary colors according to the RYB color model.\\n# pub enum SecondaryColor {\\n# Orange,\\n# Green,\\n# Purple,\\n# }\\n} pub mod utils { // --snip--\\n# use crate::kinds::*;\\n# # /// Combines two primary colors in equal amounts to create\\n# /// a secondary color.\\n# pub fn mix(c1: PrimaryColor, c2: PrimaryColor) -> SecondaryColor {\\n# SecondaryColor::Orange\\n# }\\n} Listing 14-5: Adding pub use statements to re-export items The API documentation that cargo doc generates for this crate will now list and link re-exports on the front page, as shown in Figure 14-4, making the PrimaryColor and SecondaryColor types and the mix function easier to find. Figure 14-4: The front page of the documentation for art that lists the re-exports The art crate users can still see and use the internal structure from Listing 14-3 as demonstrated in Listing 14-4, or they can use the more convenient structure in Listing 14-5, as shown in Listing 14-6. Filename: src/main.rs use art::PrimaryColor;\\nuse art::mix; fn main() { // --snip--\\n# let red = PrimaryColor::Red;\\n# let yellow = PrimaryColor::Yellow;\\n# mix(red, yellow);\\n} Listing 14-6: A program using the re-exported items from the art crate In cases where there are many nested modules, re-exporting the types at the top level with pub use can make a significant difference in the experience of people who use the crate. Another common use of pub use is to re-export definitions of a dependency in the current crate to make that crate‚Äôs definitions part of your crate‚Äôs public API. Creating a useful public API structure is more an art than a science, and you can iterate to find the API that works best for your users. Choosing pub use gives you flexibility in how you structure your crate internally and decouples that internal structure from what you present to your users. Look at some of the code of crates you‚Äôve installed to see if their internal structure differs from their public API.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Exporting a Convenient Public API","id":"254","title":"Exporting a Convenient Public API"},"255":{"body":"Before you can publish any crates, you need to create an account on crates.io and get an API token. To do so, visit the home page at crates.io and log in via a GitHub account. (The GitHub account is currently a requirement, but the site might support other ways of creating an account in the future.) Once you‚Äôre logged in, visit your account settings at https://crates.io/me/ and retrieve your API key. Then, run the cargo login command and paste your API key when prompted, like this: $ cargo login\\nabcdefghijklmnopqrstuvwxyz012345 This command will inform Cargo of your API token and store it locally in ~/.cargo/credentials.toml . Note that this token is a secret: Do not share it with anyone else. If you do share it with anyone for any reason, you should revoke it and generate a new token on crates.io .","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Setting Up a Crates.io Account","id":"255","title":"Setting Up a Crates.io Account"},"256":{"body":"Let‚Äôs say you have a crate you want to publish. Before publishing, you‚Äôll need to add some metadata in the [package] section of the crate‚Äôs Cargo.toml file. Your crate will need a unique name. While you‚Äôre working on a crate locally, you can name a crate whatever you‚Äôd like. However, crate names on crates.io are allocated on a first-come, first-served basis. Once a crate name is taken, no one else can publish a crate with that name. Before attempting to publish a crate, search for the name you want to use. If the name has been used, you will need to find another name and edit the name field in the Cargo.toml file under the [package] section to use the new name for publishing, like so: Filename: Cargo.toml [package]\\nname = \\"guessing_game\\" Even if you‚Äôve chosen a unique name, when you run cargo publish to publish the crate at this point, you‚Äôll get a warning and then an error: $ cargo publish Updating crates.io index\\nwarning: manifest has no description, license, license-file, documentation, homepage or repository.\\nSee https://doc.rust-lang.org/cargo/reference/manifest.html#package-metadata for more info.\\n--snip--\\nerror: failed to publish to registry at https://crates.io Caused by: the remote server responded with an error (status 400 Bad Request): missing or empty metadata fields: description, license. Please see https://doc.rust-lang.org/cargo/reference/manifest.html for more information on configuring these fields This results in an error because you‚Äôre missing some crucial information: A description and license are required so that people will know what your crate does and under what terms they can use it. In Cargo.toml , add a description that‚Äôs just a sentence or two, because it will appear with your crate in search results. For the license field, you need to give a license identifier value . The Linux Foundation‚Äôs Software Package Data Exchange (SPDX) lists the identifiers you can use for this value. For example, to specify that you‚Äôve licensed your crate using the MIT License, add the MIT identifier: Filename: Cargo.toml [package]\\nname = \\"guessing_game\\"\\nlicense = \\"MIT\\" If you want to use a license that doesn‚Äôt appear in the SPDX, you need to place the text of that license in a file, include the file in your project, and then use license-file to specify the name of that file instead of using the license key. Guidance on which license is appropriate for your project is beyond the scope of this book. Many people in the Rust community license their projects in the same way as Rust by using a dual license of MIT OR Apache-2.0. This practice demonstrates that you can also specify multiple license identifiers separated by OR to have multiple licenses for your project. With a unique name, the version, your description, and a license added, the Cargo.toml file for a project that is ready to publish might look like this: Filename: Cargo.toml [package]\\nname = \\"guessing_game\\"\\nversion = \\"0.1.0\\"\\nedition = \\"2024\\"\\ndescription = \\"A fun game where you guess what number the computer has chosen.\\"\\nlicense = \\"MIT OR Apache-2.0\\" [dependencies] Cargo‚Äôs documentation describes other metadata you can specify to ensure that others can discover and use your crate more easily.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Adding Metadata to a New Crate","id":"256","title":"Adding Metadata to a New Crate"},"257":{"body":"Now that you‚Äôve created an account, saved your API token, chosen a name for your crate, and specified the required metadata, you‚Äôre ready to publish! Publishing a crate uploads a specific version to crates.io for others to use. Be careful, because a publish is permanent . The version can never be overwritten, and the code cannot be deleted except in certain circumstances. One major goal of Crates.io is to act as a permanent archive of code so that builds of all projects that depend on crates from crates.io will continue to work. Allowing version deletions would make fulfilling that goal impossible. However, there is no limit to the number of crate versions you can publish. Run the cargo publish command again. It should succeed now: $ cargo publish Updating crates.io index Packaging guessing_game v0.1.0 (file:///projects/guessing_game) Packaged 6 files, 1.2KiB (895.0B compressed) Verifying guessing_game v0.1.0 (file:///projects/guessing_game) Compiling guessing_game v0.1.0\\n(file:///projects/guessing_game/target/package/guessing_game-0.1.0) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.19s Uploading guessing_game v0.1.0 (file:///projects/guessing_game) Uploaded guessing_game v0.1.0 to registry `crates-io`\\nnote: waiting for `guessing_game v0.1.0` to be available at registry\\n`crates-io`.\\nYou may press ctrl-c to skip waiting; the crate should be available shortly. Published guessing_game v0.1.0 at registry `crates-io` Congratulations! You‚Äôve now shared your code with the Rust community, and anyone can easily add your crate as a dependency of their project.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Publishing to Crates.io","id":"257","title":"Publishing to Crates.io"},"258":{"body":"When you‚Äôve made changes to your crate and are ready to release a new version, you change the version value specified in your Cargo.toml file and republish. Use the Semantic Versioning rules to decide what an appropriate next version number is, based on the kinds of changes you‚Äôve made. Then, run cargo publish to upload the new version.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Publishing a New Version of an Existing Crate","id":"258","title":"Publishing a New Version of an Existing Crate"},"259":{"body":"Although you can‚Äôt remove previous versions of a crate, you can prevent any future projects from adding them as a new dependency. This is useful when a crate version is broken for one reason or another. In such situations, Cargo supports yanking a crate version. Yanking a version prevents new projects from depending on that version while allowing all existing projects that depend on it to continue. Essentially, a yank means that all projects with a Cargo.lock will not break, and any future Cargo.lock files generated will not use the yanked version. To yank a version of a crate, in the directory of the crate that you‚Äôve previously published, run cargo yank and specify which version you want to yank. For example, if we‚Äôve published a crate named guessing_game version 1.0.1 and we want to yank it, then we‚Äôd run the following in the project directory for guessing_game: $ cargo yank --vers 1.0.1 Updating crates.io index Yank guessing_game@1.0.1 By adding --undo to the command, you can also undo a yank and allow projects to start depending on a version again: $ cargo yank --vers 1.0.1 --undo Updating crates.io index Unyank guessing_game@1.0.1 A yank does not delete any code. It cannot, for example, delete accidentally uploaded secrets. If that happens, you must reset those secrets immediately.","breadcrumbs":"More about Cargo and Crates.io ¬ª Publishing a Crate to Crates.io ¬ª Deprecating Versions from Crates.io","id":"259","title":"Deprecating Versions from Crates.io"},"26":{"body":"You‚Äôve just run a newly created program, so let‚Äôs examine each step in the process. Before running a Rust program, you must compile it using the Rust compiler by entering the rustc command and passing it the name of your source file, like this: $ rustc main.rs If you have a C or C++ background, you‚Äôll notice that this is similar to gcc or clang. After compiling successfully, Rust outputs a binary executable. On Linux, macOS, and PowerShell on Windows, you can see the executable by entering the ls command in your shell: $ ls\\nmain main.rs On Linux and macOS, you‚Äôll see two files. With PowerShell on Windows, you‚Äôll see the same three files that you would see using CMD. With CMD on Windows, you would enter the following: > dir /B %= the /B option says to only show the file names =%\\nmain.exe\\nmain.pdb\\nmain.rs This shows the source code file with the .rs extension, the executable file ( main.exe on Windows, but main on all other platforms), and, when using Windows, a file containing debugging information with the .pdb extension. From here, you run the main or main.exe file, like this: $ ./main # or .\\\\main on Windows If your main.rs is your ‚ÄúHello, world!‚Äù program, this line prints Hello, world! to your terminal. If you‚Äôre more familiar with a dynamic language, such as Ruby, Python, or JavaScript, you might not be used to compiling and running a program as separate steps. Rust is an ahead-of-time compiled language, meaning you can compile a program and give the executable to someone else, and they can run it even without having Rust installed. If you give someone a .rb , .py , or .js file, they need to have a Ruby, Python, or JavaScript implementation installed (respectively). But in those languages, you only need one command to compile and run your program. Everything is a trade-off in language design. Just compiling with rustc is fine for simple programs, but as your project grows, you‚Äôll want to manage all the options and make it easy to share your code. Next, we‚Äôll introduce you to the Cargo tool, which will help you write real-world Rust programs.","breadcrumbs":"Getting Started ¬ª Hello, World! ¬ª Compilation and Execution","id":"26","title":"Compilation and Execution"},"260":{"body":"In Chapter 12, we built a package that included a binary crate and a library crate. As your project develops, you might find that the library crate continues to get bigger and you want to split your package further into multiple library crates. Cargo offers a feature called workspaces that can help manage multiple related packages that are developed in tandem.","breadcrumbs":"More about Cargo and Crates.io ¬ª Cargo Workspaces ¬ª Cargo Workspaces","id":"260","title":"Cargo Workspaces"},"261":{"body":"A workspace is a set of packages that share the same Cargo.lock and output directory. Let‚Äôs make a project using a workspace‚Äîwe‚Äôll use trivial code so that we can concentrate on the structure of the workspace. There are multiple ways to structure a workspace, so we‚Äôll just show one common way. We‚Äôll have a workspace containing a binary and two libraries. The binary, which will provide the main functionality, will depend on the two libraries. One library will provide an add_one function and the other library an add_two function. These three crates will be part of the same workspace. We‚Äôll start by creating a new directory for the workspace: $ mkdir add\\n$ cd add Next, in the add directory, we create the Cargo.toml file that will configure the entire workspace. This file won‚Äôt have a [package] section. Instead, it will start with a [workspace] section that will allow us to add members to the workspace. We also make a point to use the latest and greatest version of Cargo‚Äôs resolver algorithm in our workspace by setting the resolver value to \\"3\\": Filename: Cargo.toml [workspace]\\nresolver = \\"3\\" Next, we‚Äôll create the adder binary crate by running cargo new within the add directory: $ cargo new adder Created binary (application) `adder` package Adding `adder` as member of workspace at `file:///projects/add` Running cargo new inside a workspace also automatically adds the newly created package to the members key in the [workspace] definition in the workspace Cargo.toml , like this: [workspace]\\nresolver = \\"3\\"\\nmembers = [\\"adder\\"] At this point, we can build the workspace by running cargo build. The files in your add directory should look like this: ‚îú‚îÄ‚îÄ Cargo.lock\\n‚îú‚îÄ‚îÄ Cargo.toml\\n‚îú‚îÄ‚îÄ adder\\n‚îÇ ‚îú‚îÄ‚îÄ Cargo.toml\\n‚îÇ ‚îî‚îÄ‚îÄ src\\n‚îÇ ‚îî‚îÄ‚îÄ main.rs\\n‚îî‚îÄ‚îÄ target The workspace has one target directory at the top level that the compiled artifacts will be placed into; the adder package doesn‚Äôt have its own target directory. Even if we were to run cargo build from inside the adder directory, the compiled artifacts would still end up in add/target rather than add/adder/target . Cargo structures the target directory in a workspace like this because the crates in a workspace are meant to depend on each other. If each crate had its own target directory, each crate would have to recompile each of the other crates in the workspace to place the artifacts in its own target directory. By sharing one target directory, the crates can avoid unnecessary rebuilding.","breadcrumbs":"More about Cargo and Crates.io ¬ª Cargo Workspaces ¬ª Creating a Workspace","id":"261","title":"Creating a Workspace"},"262":{"body":"Next, let‚Äôs create another member package in the workspace and call it add_one. Generate a new library crate named add_one: $ cargo new add_one --lib Created library `add_one` package Adding `add_one` as member of workspace at `file:///projects/add` The top-level Cargo.toml will now include the add_one path in the members list: Filename: Cargo.toml [workspace]\\nresolver = \\"3\\"\\nmembers = [\\"adder\\", \\"add_one\\"] Your add directory should now have these directories and files: ‚îú‚îÄ‚îÄ Cargo.lock\\n‚îú‚îÄ‚îÄ Cargo.toml\\n‚îú‚îÄ‚îÄ add_one\\n‚îÇ ‚îú‚îÄ‚îÄ Cargo.toml\\n‚îÇ ‚îî‚îÄ‚îÄ src\\n‚îÇ ‚îî‚îÄ‚îÄ lib.rs\\n‚îú‚îÄ‚îÄ adder\\n‚îÇ ‚îú‚îÄ‚îÄ Cargo.toml\\n‚îÇ ‚îî‚îÄ‚îÄ src\\n‚îÇ ‚îî‚îÄ‚îÄ main.rs\\n‚îî‚îÄ‚îÄ target In the add_one/src/lib.rs file, let‚Äôs add an add_one function: Filename: add_one/src/lib.rs pub fn add_one(x: i32) -> i32 { x + 1\\n} Now we can have the adder package with our binary depend on the add_one package that has our library. First, we‚Äôll need to add a path dependency on add_one to adder/Cargo.toml . Filename: adder/Cargo.toml [dependencies]\\nadd_one = { path = \\"../add_one\\" } Cargo doesn‚Äôt assume that crates in a workspace will depend on each other, so we need to be explicit about the dependency relationships. Next, let‚Äôs use the add_one function (from the add_one crate) in the adder crate. Open the adder/src/main.rs file and change the main function to call the add_one function, as in Listing 14-7. Filename: adder/src/main.rs fn main() { let num = 10; println!(\\"Hello, world! {num} plus one is {}!\\", add_one::add_one(num));\\n} Listing 14-7: Using the add_one library crate from the adder crate Let‚Äôs build the workspace by running cargo build in the top-level add directory! $ cargo build Compiling add_one v0.1.0 (file:///projects/add/add_one) Compiling adder v0.1.0 (file:///projects/add/adder) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.22s To run the binary crate from the add directory, we can specify which package in the workspace we want to run by using the -p argument and the package name with cargo run: $ cargo run -p adder Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/adder`\\nHello, world! 10 plus one is 11! This runs the code in adder/src/main.rs , which depends on the add_one crate.","breadcrumbs":"More about Cargo and Crates.io ¬ª Cargo Workspaces ¬ª Creating the Second Package in the Workspace","id":"262","title":"Creating the Second Package in the Workspace"},"263":{"body":"Notice that the workspace has only one Cargo.lock file at the top level, rather than having a Cargo.lock in each crate‚Äôs directory. This ensures that all crates are using the same version of all dependencies. If we add the rand package to the adder/Cargo.toml and add_one/Cargo.toml files, Cargo will resolve both of those to one version of rand and record that in the one Cargo.lock . Making all crates in the workspace use the same dependencies means the crates will always be compatible with each other. Let‚Äôs add the rand crate to the [dependencies] section in the add_one/Cargo.toml file so that we can use the rand crate in the add_one crate: Filename: add_one/Cargo.toml [dependencies]\\nrand = \\"0.8.5\\" We can now add use rand; to the add_one/src/lib.rs file, and building the whole workspace by running cargo build in the add directory will bring in and compile the rand crate. We will get one warning because we aren‚Äôt referring to the rand we brought into scope: $ cargo build Updating crates.io index Downloaded rand v0.8.5 --snip-- Compiling rand v0.8.5 Compiling add_one v0.1.0 (file:///projects/add/add_one)\\nwarning: unused import: `rand` --> add_one/src/lib.rs:1:5 |\\n1 | use rand; | ^^^^ | = note: `#[warn(unused_imports)]` on by default warning: `add_one` (lib) generated 1 warning (run `cargo fix --lib -p add_one` to apply 1 suggestion) Compiling adder v0.1.0 (file:///projects/add/adder) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.95s The top-level Cargo.lock now contains information about the dependency of add_one on rand. However, even though rand is used somewhere in the workspace, we can‚Äôt use it in other crates in the workspace unless we add rand to their Cargo.toml files as well. For example, if we add use rand; to the adder/src/main.rs file for the adder package, we‚Äôll get an error: $ cargo build --snip-- Compiling adder v0.1.0 (file:///projects/add/adder)\\nerror[E0432]: unresolved import `rand` --> adder/src/main.rs:2:5 |\\n2 | use rand; | ^^^^ no external crate `rand` To fix this, edit the Cargo.toml file for the adder package and indicate that rand is a dependency for it as well. Building the adder package will add rand to the list of dependencies for adder in Cargo.lock , but no additional copies of rand will be downloaded. Cargo will ensure that every crate in every package in the workspace using the rand package will use the same version as long as they specify compatible versions of rand, saving us space and ensuring that the crates in the workspace will be compatible with each other. If crates in the workspace specify incompatible versions of the same dependency, Cargo will resolve each of them but will still try to resolve as few versions as possible.","breadcrumbs":"More about Cargo and Crates.io ¬ª Cargo Workspaces ¬ª Depending on an External Package","id":"263","title":"Depending on an External Package"},"264":{"body":"For another enhancement, let‚Äôs add a test of the add_one::add_one function within the add_one crate: Filename: add_one/src/lib.rs pub fn add_one(x: i32) -> i32 { x + 1\\n} #[cfg(test)]\\nmod tests { use super::*; #[test] fn it_works() { assert_eq!(3, add_one(2)); }\\n} Now run cargo test in the top-level add directory. Running cargo test in a workspace structured like this one will run the tests for all the crates in the workspace: $ cargo test Compiling add_one v0.1.0 (file:///projects/add/add_one) Compiling adder v0.1.0 (file:///projects/add/adder) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.20s Running unittests src/lib.rs (target/debug/deps/add_one-93c49ee75dc46543) running 1 test\\ntest tests::it_works ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Running unittests src/main.rs (target/debug/deps/adder-3a47283c568d2b6a) running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests add_one running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s The first section of the output shows that the it_works test in the add_one crate passed. The next section shows that zero tests were found in the adder crate, and then the last section shows that zero documentation tests were found in the add_one crate. We can also run tests for one particular crate in a workspace from the top-level directory by using the -p flag and specifying the name of the crate we want to test: $ cargo test -p add_one Finished `test` profile [unoptimized + debuginfo] target(s) in 0.00s Running unittests src/lib.rs (target/debug/deps/add_one-93c49ee75dc46543) running 1 test\\ntest tests::it_works ... ok test result: ok. 1 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s Doc-tests add_one running 0 tests test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s This output shows cargo test only ran the tests for the add_one crate and didn‚Äôt run the adder crate tests. If you publish the crates in the workspace to crates.io , each crate in the workspace will need to be published separately. Like cargo test, we can publish a particular crate in our workspace by using the -p flag and specifying the name of the crate we want to publish. For additional practice, add an add_two crate to this workspace in a similar way as the add_one crate! As your project grows, consider using a workspace: It enables you to work with smaller, easier-to-understand components than one big blob of code. Furthermore, keeping the crates in a workspace can make coordination between crates easier if they are often changed at the same time.","breadcrumbs":"More about Cargo and Crates.io ¬ª Cargo Workspaces ¬ª Adding a Test to a Workspace","id":"264","title":"Adding a Test to a Workspace"},"265":{"body":"The cargo install command allows you to install and use binary crates locally. This isn‚Äôt intended to replace system packages; it‚Äôs meant to be a convenient way for Rust developers to install tools that others have shared on crates.io . Note that you can only install packages that have binary targets. A binary target is the runnable program that is created if the crate has a src/main.rs file or another file specified as a binary, as opposed to a library target that isn‚Äôt runnable on its own but is suitable for including within other programs. Usually, crates have information in the README file about whether a crate is a library, has a binary target, or both. All binaries installed with cargo install are stored in the installation root‚Äôs bin folder. If you installed Rust using rustup.rs and don‚Äôt have any custom configurations, this directory will be $HOME/.cargo/bin . Ensure that this directory is in your $PATH to be able to run programs you‚Äôve installed with cargo install. For example, in Chapter 12 we mentioned that there‚Äôs a Rust implementation of the grep tool called ripgrep for searching files. To install ripgrep, we can run the following: $ cargo install ripgrep Updating crates.io index Downloaded ripgrep v14.1.1 Downloaded 1 crate (213.6 KB) in 0.40s Installing ripgrep v14.1.1\\n--snip-- Compiling grep v0.3.2 Finished `release` profile [optimized + debuginfo] target(s) in 6.73s Installing ~/.cargo/bin/rg Installed package `ripgrep v14.1.1` (executable `rg`) The second-to-last line of the output shows the location and the name of the installed binary, which in the case of ripgrep is rg. As long as the installation directory is in your $PATH, as mentioned previously, you can then run rg --help and start using a faster, Rustier tool for searching files!","breadcrumbs":"More about Cargo and Crates.io ¬ª Installing Binaries with cargo install ¬ª Installing Binaries with cargo install","id":"265","title":"Installing Binaries with cargo install"},"266":{"body":"Cargo is designed so that you can extend it with new subcommands without having to modify it. If a binary in your $PATH is named cargo-something, you can run it as if it were a Cargo subcommand by running cargo something. Custom commands like this are also listed when you run cargo --list. Being able to use cargo install to install extensions and then run them just like the built-in Cargo tools is a super-convenient benefit of Cargo‚Äôs design!","breadcrumbs":"More about Cargo and Crates.io ¬ª Extending Cargo with Custom Commands ¬ª Extending Cargo with Custom Commands","id":"266","title":"Extending Cargo with Custom Commands"},"267":{"body":"Sharing code with Cargo and crates.io is part of what makes the Rust ecosystem useful for many different tasks. Rust‚Äôs standard library is small and stable, but crates are easy to share, use, and improve on a timeline different from that of the language. Don‚Äôt be shy about sharing code that‚Äôs useful to you on crates.io ; it‚Äôs likely that it will be useful to someone else as well!","breadcrumbs":"More about Cargo and Crates.io ¬ª Extending Cargo with Custom Commands ¬ª Summary","id":"267","title":"Summary"},"268":{"body":"A pointer is a general concept for a variable that contains an address in memory. This address refers to, or ‚Äúpoints at,‚Äù some other data. The most common kind of pointer in Rust is a reference, which you learned about in Chapter 4. References are indicated by the & symbol and borrow the value they point to. They don‚Äôt have any special capabilities other than referring to data, and they have no overhead. Smart pointers , on the other hand, are data structures that act like a pointer but also have additional metadata and capabilities. The concept of smart pointers isn‚Äôt unique to Rust: Smart pointers originated in C++ and exist in other languages as well. Rust has a variety of smart pointers defined in the standard library that provide functionality beyond that provided by references. To explore the general concept, we‚Äôll look at a couple of different examples of smart pointers, including a reference counting smart pointer type. This pointer enables you to allow data to have multiple owners by keeping track of the number of owners and, when no owners remain, cleaning up the data. In Rust, with its concept of ownership and borrowing, there is an additional difference between references and smart pointers: While references only borrow data, in many cases smart pointers own the data they point to. Smart pointers are usually implemented using structs. Unlike an ordinary struct, smart pointers implement the Deref and Drop traits. The Deref trait allows an instance of the smart pointer struct to behave like a reference so that you can write your code to work with either references or smart pointers. The Drop trait allows you to customize the code that‚Äôs run when an instance of the smart pointer goes out of scope. In this chapter, we‚Äôll discuss both of these traits and demonstrate why they‚Äôre important to smart pointers. Given that the smart pointer pattern is a general design pattern used frequently in Rust, this chapter won‚Äôt cover every existing smart pointer. Many libraries have their own smart pointers, and you can even write your own. We‚Äôll cover the most common smart pointers in the standard library: Box<T>, for allocating values on the heap Rc<T>, a reference counting type that enables multiple ownership Ref<T> and RefMut<T>, accessed through RefCell<T>, a type that enforces the borrowing rules at runtime instead of compile time In addition, we‚Äôll cover the interior mutability pattern where an immutable type exposes an API for mutating an interior value. We‚Äôll also discuss reference cycles: how they can leak memory and how to prevent them. Let‚Äôs dive in!","breadcrumbs":"Smart Pointers ¬ª Smart Pointers","id":"268","title":"Smart Pointers"},"269":{"body":"The most straightforward smart pointer is a box, whose type is written Box<T>. Boxes allow you to store data on the heap rather than the stack. What remains on the stack is the pointer to the heap data. Refer to Chapter 4 to review the difference between the stack and the heap. Boxes don‚Äôt have performance overhead, other than storing their data on the heap instead of on the stack. But they don‚Äôt have many extra capabilities either. You‚Äôll use them most often in these situations: When you have a type whose size can‚Äôt be known at compile time, and you want to use a value of that type in a context that requires an exact size When you have a large amount of data, and you want to transfer ownership but ensure that the data won‚Äôt be copied when you do so When you want to own a value, and you care only that it‚Äôs a type that implements a particular trait rather than being of a specific type We‚Äôll demonstrate the first situation in ‚ÄúEnabling Recursive Types with Boxes‚Äù . In the second case, transferring ownership of a large amount of data can take a long time because the data is copied around on the stack. To improve performance in this situation, we can store the large amount of data on the heap in a box. Then, only the small amount of pointer data is copied around on the stack, while the data it references stays in one place on the heap. The third case is known as a trait object , and ‚ÄúUsing Trait Objects to Abstract over Shared Behavior‚Äù in Chapter 18 is devoted to that topic. So, what you learn here you‚Äôll apply again in that section!","breadcrumbs":"Smart Pointers ¬ª Using Box<T> to Point to Data on the Heap ¬ª Using Box<T> to Point to Data on the Heap","id":"269","title":"Using Box<T> to Point to Data on the Heap"},"27":{"body":"Cargo is Rust‚Äôs build system and package manager. Most Rustaceans use this tool to manage their Rust projects because Cargo handles a lot of tasks for you, such as building your code, downloading the libraries your code depends on, and building those libraries. (We call the libraries that your code needs dependencies .) The simplest Rust programs, like the one we‚Äôve written so far, don‚Äôt have any dependencies. If we had built the ‚ÄúHello, world!‚Äù project with Cargo, it would only use the part of Cargo that handles building your code. As you write more complex Rust programs, you‚Äôll add dependencies, and if you start a project using Cargo, adding dependencies will be much easier to do. Because the vast majority of Rust projects use Cargo, the rest of this book assumes that you‚Äôre using Cargo too. Cargo comes installed with Rust if you used the official installers discussed in the ‚ÄúInstallation‚Äù section. If you installed Rust through some other means, check whether Cargo is installed by entering the following in your terminal: $ cargo --version If you see a version number, you have it! If you see an error, such as command not found, look at the documentation for your method of installation to determine how to install Cargo separately.","breadcrumbs":"Getting Started ¬ª Hello, Cargo! ¬ª Hello, Cargo!","id":"27","title":"Hello, Cargo!"},"270":{"body":"Before we discuss the heap storage use case for Box<T>, we‚Äôll cover the syntax and how to interact with values stored within a Box<T>. Listing 15-1 shows how to use a box to store an i32 value on the heap. Filename: src/main.rs fn main() { let b = Box::new(5); println!(\\"b = {b}\\");\\n} Listing 15-1: Storing an i32 value on the heap using a box We define the variable b to have the value of a Box that points to the value 5, which is allocated on the heap. This program will print b = 5; in this case, we can access the data in the box similarly to how we would if this data were on the stack. Just like any owned value, when a box goes out of scope, as b does at the end of main, it will be deallocated. The deallocation happens both for the box (stored on the stack) and the data it points to (stored on the heap). Putting a single value on the heap isn‚Äôt very useful, so you won‚Äôt use boxes by themselves in this way very often. Having values like a single i32 on the stack, where they‚Äôre stored by default, is more appropriate in the majority of situations. Let‚Äôs look at a case where boxes allow us to define types that we wouldn‚Äôt be allowed to define if we didn‚Äôt have boxes.","breadcrumbs":"Smart Pointers ¬ª Using Box<T> to Point to Data on the Heap ¬ª Storing Data on the Heap","id":"270","title":"Storing Data on the Heap"},"271":{"body":"A value of a recursive type can have another value of the same type as part of itself. Recursive types pose an issue because Rust needs to know at compile time how much space a type takes up. However, the nesting of values of recursive types could theoretically continue infinitely, so Rust can‚Äôt know how much space the value needs. Because boxes have a known size, we can enable recursive types by inserting a box in the recursive type definition. As an example of a recursive type, let‚Äôs explore the cons list. This is a data type commonly found in functional programming languages. The cons list type we‚Äôll define is straightforward except for the recursion; therefore, the concepts in the example we‚Äôll work with will be useful anytime you get into more complex situations involving recursive types. Understanding the Cons List A cons list is a data structure that comes from the Lisp programming language and its dialects, is made up of nested pairs, and is the Lisp version of a linked list. Its name comes from the cons function (short for construct function ) in Lisp that constructs a new pair from its two arguments. By calling cons on a pair consisting of a value and another pair, we can construct cons lists made up of recursive pairs. For example, here‚Äôs a pseudocode representation of a cons list containing the list 1, 2, 3 with each pair in parentheses: (1, (2, (3, Nil))) Each item in a cons list contains two elements: the value of the current item and of the next item. The last item in the list contains only a value called Nil without a next item. A cons list is produced by recursively calling the cons function. The canonical name to denote the base case of the recursion is Nil. Note that this is not the same as the ‚Äúnull‚Äù or ‚Äúnil‚Äù concept discussed in Chapter 6, which is an invalid or absent value. The cons list isn‚Äôt a commonly used data structure in Rust. Most of the time when you have a list of items in Rust, Vec<T> is a better choice to use. Other, more complex recursive data types are useful in various situations, but by starting with the cons list in this chapter, we can explore how boxes let us define a recursive data type without much distraction. Listing 15-2 contains an enum definition for a cons list. Note that this code won‚Äôt compile yet, because the List type doesn‚Äôt have a known size, which we‚Äôll demonstrate. Filename: src/main.rs enum List { Cons(i32, List), Nil,\\n}\\n# # fn main() {} Listing 15-2: The first attempt at defining an enum to represent a cons list data structure of i32 values Note: We‚Äôre implementing a cons list that holds only i32 values for the purposes of this example. We could have implemented it using generics, as we discussed in Chapter 10, to define a cons list type that could store values of any type. Using the List type to store the list 1, 2, 3 would look like the code in Listing 15-3. Filename: src/main.rs # enum List {\\n# Cons(i32, List),\\n# Nil,\\n# }\\n# // --snip-- use crate::List::{Cons, Nil}; fn main() { let list = Cons(1, Cons(2, Cons(3, Nil)));\\n} Listing 15-3: Using the List enum to store the list 1, 2, 3 The first Cons value holds 1 and another List value. This List value is another Cons value that holds 2 and another List value. This List value is one more Cons value that holds 3 and a List value, which is finally Nil, the non-recursive variant that signals the end of the list. If we try to compile the code in Listing 15-3, we get the error shown in Listing 15-4. $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list)\\nerror[E0072]: recursive type `List` has infinite size --> src/main.rs:1:1 |\\n1 | enum List { | ^^^^^^^^^\\n2 | Cons(i32, List), | ---- recursive without indirection |\\nhelp: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle |\\n2 | Cons(i32, Box<List>), | ++++ + error[E0391]: cycle detected when computing when `List` needs drop --> src/main.rs:1:1 |\\n1 | enum List { | ^^^^^^^^^ | = note: ...which immediately requires computing when `List` needs drop again = note: cycle used when computing whether `List` needs drop = note: see https://rustc-dev-guide.rust-lang.org/overview.html#queries and https://rustc-dev-guide.rust-lang.org/query.html for more information Some errors have detailed explanations: E0072, E0391.\\nFor more information about an error, try `rustc --explain E0072`.\\nerror: could not compile `cons-list` (bin \\"cons-list\\") due to 2 previous errors Listing 15-4: The error we get when attempting to define a recursive enum The error shows this type ‚Äúhas infinite size.‚Äù The reason is that we‚Äôve defined List with a variant that is recursive: It holds another value of itself directly. As a result, Rust can‚Äôt figure out how much space it needs to store a List value. Let‚Äôs break down why we get this error. First, we‚Äôll look at how Rust decides how much space it needs to store a value of a non-recursive type. Computing the Size of a Non-Recursive Type Recall the Message enum we defined in Listing 6-2 when we discussed enum definitions in Chapter 6: enum Message { Quit, Move { x: i32, y: i32 }, Write(String), ChangeColor(i32, i32, i32),\\n}\\n# # fn main() {} To determine how much space to allocate for a Message value, Rust goes through each of the variants to see which variant needs the most space. Rust sees that Message::Quit doesn‚Äôt need any space, Message::Move needs enough space to store two i32 values, and so forth. Because only one variant will be used, the most space a Message value will need is the space it would take to store the largest of its variants. Contrast this with what happens when Rust tries to determine how much space a recursive type like the List enum in Listing 15-2 needs. The compiler starts by looking at the Cons variant, which holds a value of type i32 and a value of type List. Therefore, Cons needs an amount of space equal to the size of an i32 plus the size of a List. To figure out how much memory the List type needs, the compiler looks at the variants, starting with the Cons variant. The Cons variant holds a value of type i32 and a value of type List, and this process continues infinitely, as shown in Figure 15-1. Figure 15-1: An infinite List consisting of infinite Cons variants Getting a Recursive Type with a Known Size Because Rust can‚Äôt figure out how much space to allocate for recursively defined types, the compiler gives an error with this helpful suggestion: help: insert some indirection (e.g., a `Box`, `Rc`, or `&`) to break the cycle |\\n2 | Cons(i32, Box<List>), | ++++ + In this suggestion, indirection means that instead of storing a value directly, we should change the data structure to store the value indirectly by storing a pointer to the value instead. Because a Box<T> is a pointer, Rust always knows how much space a Box<T> needs: A pointer‚Äôs size doesn‚Äôt change based on the amount of data it‚Äôs pointing to. This means we can put a Box<T> inside the Cons variant instead of another List value directly. The Box<T> will point to the next List value that will be on the heap rather than inside the Cons variant. Conceptually, we still have a list, created with lists holding other lists, but this implementation is now more like placing the items next to one another rather than inside one another. We can change the definition of the List enum in Listing 15-2 and the usage of the List in Listing 15-3 to the code in Listing 15-5, which will compile. Filename: src/main.rs enum List { Cons(i32, Box<List>), Nil,\\n} use crate::List::{Cons, Nil}; fn main() { let list = Cons(1, Box::new(Cons(2, Box::new(Cons(3, Box::new(Nil))))));\\n} Listing 15-5: The definition of List that uses Box&lt;T&gt; in order to have a known size The Cons variant needs the size of an i32 plus the space to store the box‚Äôs pointer data. The Nil variant stores no values, so it needs less space on the stack than the Cons variant. We now know that any List value will take up the size of an i32 plus the size of a box‚Äôs pointer data. By using a box, we‚Äôve broken the infinite, recursive chain, so the compiler can figure out the size it needs to store a List value. Figure 15-2 shows what the Cons variant looks like now. Figure 15-2: A List that is not infinitely sized, because Cons holds a Box Boxes provide only the indirection and heap allocation; they don‚Äôt have any other special capabilities, like those we‚Äôll see with the other smart pointer types. They also don‚Äôt have the performance overhead that these special capabilities incur, so they can be useful in cases like the cons list where the indirection is the only feature we need. We‚Äôll look at more use cases for boxes in Chapter 18. The Box<T> type is a smart pointer because it implements the Deref trait, which allows Box<T> values to be treated like references. When a Box<T> value goes out of scope, the heap data that the box is pointing to is cleaned up as well because of the Drop trait implementation. These two traits will be even more important to the functionality provided by the other smart pointer types we‚Äôll discuss in the rest of this chapter. Let‚Äôs explore these two traits in more detail.","breadcrumbs":"Smart Pointers ¬ª Using Box<T> to Point to Data on the Heap ¬ª Enabling Recursive Types with Boxes","id":"271","title":"Enabling Recursive Types with Boxes"},"272":{"body":"Implementing the Deref trait allows you to customize the behavior of the dereference operator * (not to be confused with the multiplication or glob operator). By implementing Deref in such a way that a smart pointer can be treated like a regular reference, you can write code that operates on references and use that code with smart pointers too. Let‚Äôs first look at how the dereference operator works with regular references. Then, we‚Äôll try to define a custom type that behaves like Box<T> and see why the dereference operator doesn‚Äôt work like a reference on our newly defined type. We‚Äôll explore how implementing the Deref trait makes it possible for smart pointers to work in ways similar to references. Then, we‚Äôll look at Rust‚Äôs deref coercion feature and how it lets us work with either references or smart pointers.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Treating Smart Pointers Like Regular References","id":"272","title":"Treating Smart Pointers Like Regular References"},"273":{"body":"A regular reference is a type of pointer, and one way to think of a pointer is as an arrow to a value stored somewhere else. In Listing 15-6, we create a reference to an i32 value and then use the dereference operator to follow the reference to the value. Filename: src/main.rs fn main() { let x = 5; let y = &x; assert_eq!(5, x); assert_eq!(5, *y);\\n} Listing 15-6: Using the dereference operator to follow a reference to an i32 value The variable x holds an i32 value 5. We set y equal to a reference to x. We can assert that x is equal to 5. However, if we want to make an assertion about the value in y, we have to use *y to follow the reference to the value it‚Äôs pointing to (hence, dereference ) so that the compiler can compare the actual value. Once we dereference y, we have access to the integer value y is pointing to that we can compare with 5. If we tried to write assert_eq!(5, y); instead, we would get this compilation error: $ cargo run Compiling deref-example v0.1.0 (file:///projects/deref-example)\\nerror[E0277]: can\'t compare `{integer}` with `&{integer}` --> src/main.rs:6:5 |\\n6 | assert_eq!(5, y); | ^^^^^^^^^^^^^^^^ no implementation for `{integer} == &{integer}` | = help: the trait `PartialEq<&{integer}>` is not implemented for `{integer}` = note: this error originates in the macro `assert_eq` (in Nightly builds, run with -Z macro-backtrace for more info) For more information about this error, try `rustc --explain E0277`.\\nerror: could not compile `deref-example` (bin \\"deref-example\\") due to 1 previous error Comparing a number and a reference to a number isn‚Äôt allowed because they‚Äôre different types. We must use the dereference operator to follow the reference to the value it‚Äôs pointing to.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Following the Reference to the Value","id":"273","title":"Following the Reference to the Value"},"274":{"body":"We can rewrite the code in Listing 15-6 to use a Box<T> instead of a reference; the dereference operator used on the Box<T> in Listing 15-7 functions in the same way as the dereference operator used on the reference in Listing 15-6. Filename: src/main.rs fn main() { let x = 5; let y = Box::new(x); assert_eq!(5, x); assert_eq!(5, *y);\\n} Listing 15-7: Using the dereference operator on a Box&lt;i32&gt; The main difference between Listing 15-7 and Listing 15-6 is that here we set y to be an instance of a box pointing to a copied value of x rather than a reference pointing to the value of x. In the last assertion, we can use the dereference operator to follow the box‚Äôs pointer in the same way that we did when y was a reference. Next, we‚Äôll explore what is special about Box<T> that enables us to use the dereference operator by defining our own box type.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Using Box<T> Like a Reference","id":"274","title":"Using Box<T> Like a Reference"},"275":{"body":"Let‚Äôs build a wrapper type similar to the Box<T> type provided by the standard library to experience how smart pointer types behave differently from references by default. Then, we‚Äôll look at how to add the ability to use the dereference operator. Note: There‚Äôs one big difference between the MyBox<T> type we‚Äôre about to build and the real Box<T>: Our version will not store its data on the heap. We are focusing this example on Deref, so where the data is actually stored is less important than the pointer-like behavior. The Box<T> type is ultimately defined as a tuple struct with one element, so Listing 15-8 defines a MyBox<T> type in the same way. We‚Äôll also define a new function to match the new function defined on Box<T>. Filename: src/main.rs struct MyBox<T>(T); impl<T> MyBox<T> { fn new(x: T) -> MyBox<T> { MyBox(x) }\\n}\\n# # fn main() {} Listing 15-8: Defining a MyBox&lt;T&gt; type We define a struct named MyBox and declare a generic parameter T because we want our type to hold values of any type. The MyBox type is a tuple struct with one element of type T. The MyBox::new function takes one parameter of type T and returns a MyBox instance that holds the value passed in. Let‚Äôs try adding the main function in Listing 15-7 to Listing 15-8 and changing it to use the MyBox<T> type we‚Äôve defined instead of Box<T>. The code in Listing 15-9 won‚Äôt compile, because Rust doesn‚Äôt know how to dereference MyBox. Filename: src/main.rs # struct MyBox<T>(T);\\n# # impl<T> MyBox<T> {\\n# fn new(x: T) -> MyBox<T> {\\n# MyBox(x)\\n# }\\n# }\\n# fn main() { let x = 5; let y = MyBox::new(x); assert_eq!(5, x); assert_eq!(5, *y);\\n} Listing 15-9: Attempting to use MyBox&lt;T&gt; in the same way we used references and Box&lt;T&gt; Here‚Äôs the resultant compilation error: $ cargo run Compiling deref-example v0.1.0 (file:///projects/deref-example)\\nerror[E0614]: type `MyBox<{integer}>` cannot be dereferenced --> src/main.rs:14:19 |\\n14 | assert_eq!(5, *y); | ^^ For more information about this error, try `rustc --explain E0614`.\\nerror: could not compile `deref-example` (bin \\"deref-example\\") due to 1 previous error Our MyBox<T> type can‚Äôt be dereferenced because we haven‚Äôt implemented that ability on our type. To enable dereferencing with the * operator, we implement the Deref trait.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Defining Our Own Smart Pointer","id":"275","title":"Defining Our Own Smart Pointer"},"276":{"body":"As discussed in ‚ÄúImplementing a Trait on a Type‚Äù in Chapter 10, to implement a trait we need to provide implementations for the trait‚Äôs required methods. The Deref trait, provided by the standard library, requires us to implement one method named deref that borrows self and returns a reference to the inner data. Listing 15-10 contains an implementation of Deref to add to the definition of MyBox<T>. Filename: src/main.rs use std::ops::Deref; impl<T> Deref for MyBox<T> { type Target = T; fn deref(&self) -> &Self::Target { &self.0 }\\n}\\n# # struct MyBox<T>(T);\\n# # impl<T> MyBox<T> {\\n# fn new(x: T) -> MyBox<T> {\\n# MyBox(x)\\n# }\\n# }\\n# # fn main() {\\n# let x = 5;\\n# let y = MyBox::new(x);\\n# # assert_eq!(5, x);\\n# assert_eq!(5, *y);\\n# } Listing 15-10: Implementing Deref on MyBox&lt;T&gt; The type Target = T; syntax defines an associated type for the Deref trait to use. Associated types are a slightly different way of declaring a generic parameter, but you don‚Äôt need to worry about them for now; we‚Äôll cover them in more detail in Chapter 20. We fill in the body of the deref method with &self.0 so that deref returns a reference to the value we want to access with the * operator; recall from ‚ÄúCreating Different Types with Tuple Structs‚Äù in Chapter 5 that .0 accesses the first value in a tuple struct. The main function in Listing 15-9 that calls * on the MyBox<T> value now compiles, and the assertions pass! Without the Deref trait, the compiler can only dereference & references. The deref method gives the compiler the ability to take a value of any type that implements Deref and call the deref method to get a reference that it knows how to dereference. When we entered *y in Listing 15-9, behind the scenes Rust actually ran this code: *(y.deref()) Rust substitutes the * operator with a call to the deref method and then a plain dereference so that we don‚Äôt have to think about whether or not we need to call the deref method. This Rust feature lets us write code that functions identically whether we have a regular reference or a type that implements Deref. The reason the deref method returns a reference to a value, and that the plain dereference outside the parentheses in *(y.deref()) is still necessary, has to do with the ownership system. If the deref method returned the value directly instead of a reference to the value, the value would be moved out of self. We don‚Äôt want to take ownership of the inner value inside MyBox<T> in this case or in most cases where we use the dereference operator. Note that the * operator is replaced with a call to the deref method and then a call to the * operator just once, each time we use a * in our code. Because the substitution of the * operator does not recurse infinitely, we end up with data of type i32, which matches the 5 in assert_eq! in Listing 15-9.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Implementing the Deref Trait","id":"276","title":"Implementing the Deref Trait"},"277":{"body":"Deref coercion converts a reference to a type that implements the Deref trait into a reference to another type. For example, deref coercion can convert &String to &str because String implements the Deref trait such that it returns &str. Deref coercion is a convenience Rust performs on arguments to functions and methods, and it works only on types that implement the Deref trait. It happens automatically when we pass a reference to a particular type‚Äôs value as an argument to a function or method that doesn‚Äôt match the parameter type in the function or method definition. A sequence of calls to the deref method converts the type we provided into the type the parameter needs. Deref coercion was added to Rust so that programmers writing function and method calls don‚Äôt need to add as many explicit references and dereferences with & and *. The deref coercion feature also lets us write more code that can work for either references or smart pointers. To see deref coercion in action, let‚Äôs use the MyBox<T> type we defined in Listing 15-8 as well as the implementation of Deref that we added in Listing 15-10. Listing 15-11 shows the definition of a function that has a string slice parameter. Filename: src/main.rs fn hello(name: &str) { println!(\\"Hello, {name}!\\");\\n}\\n# # fn main() {} Listing 15-11: A hello function that has the parameter name of type &amp;str We can call the hello function with a string slice as an argument, such as hello(\\"Rust\\");, for example. Deref coercion makes it possible to call hello with a reference to a value of type MyBox<String>, as shown in Listing 15-12. Filename: src/main.rs # use std::ops::Deref;\\n# # impl<T> Deref for MyBox<T> {\\n# type Target = T;\\n# # fn deref(&self) -> &T {\\n# &self.0\\n# }\\n# }\\n# # struct MyBox<T>(T);\\n# # impl<T> MyBox<T> {\\n# fn new(x: T) -> MyBox<T> {\\n# MyBox(x)\\n# }\\n# }\\n# # fn hello(name: &str) {\\n# println!(\\"Hello, {name}!\\");\\n# }\\n# fn main() { let m = MyBox::new(String::from(\\"Rust\\")); hello(&m);\\n} Listing 15-12: Calling hello with a reference to a MyBox&lt;String&gt; value, which works because of deref coercion Here we‚Äôre calling the hello function with the argument &m, which is a reference to a MyBox<String> value. Because we implemented the Deref trait on MyBox<T> in Listing 15-10, Rust can turn &MyBox<String> into &String by calling deref. The standard library provides an implementation of Deref on String that returns a string slice, and this is in the API documentation for Deref. Rust calls deref again to turn the &String into &str, which matches the hello function‚Äôs definition. If Rust didn‚Äôt implement deref coercion, we would have to write the code in Listing 15-13 instead of the code in Listing 15-12 to call hello with a value of type &MyBox<String>. Filename: src/main.rs # use std::ops::Deref;\\n# # impl<T> Deref for MyBox<T> {\\n# type Target = T;\\n# # fn deref(&self) -> &T {\\n# &self.0\\n# }\\n# }\\n# # struct MyBox<T>(T);\\n# # impl<T> MyBox<T> {\\n# fn new(x: T) -> MyBox<T> {\\n# MyBox(x)\\n# }\\n# }\\n# # fn hello(name: &str) {\\n# println!(\\"Hello, {name}!\\");\\n# }\\n# fn main() { let m = MyBox::new(String::from(\\"Rust\\")); hello(&(*m)[..]);\\n} Listing 15-13: The code we would have to write if Rust didn‚Äôt have deref coercion The (*m) dereferences the MyBox<String> into a String. Then, the & and [..] take a string slice of the String that is equal to the whole string to match the signature of hello. This code without deref coercions is harder to read, write, and understand with all of these symbols involved. Deref coercion allows Rust to handle these conversions for us automatically. When the Deref trait is defined for the types involved, Rust will analyze the types and use Deref::deref as many times as necessary to get a reference to match the parameter‚Äôs type. The number of times that Deref::deref needs to be inserted is resolved at compile time, so there is no runtime penalty for taking advantage of deref coercion!","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Using Deref Coercion in Functions and Methods","id":"277","title":"Using Deref Coercion in Functions and Methods"},"278":{"body":"Similar to how you use the Deref trait to override the * operator on immutable references, you can use the DerefMut trait to override the * operator on mutable references. Rust does deref coercion when it finds types and trait implementations in three cases: From &T to &U when T: Deref<Target=U> From &mut T to &mut U when T: DerefMut<Target=U> From &mut T to &U when T: Deref<Target=U> The first two cases are the same except that the second implements mutability. The first case states that if you have a &T, and T implements Deref to some type U, you can get a &U transparently. The second case states that the same deref coercion happens for mutable references. The third case is trickier: Rust will also coerce a mutable reference to an immutable one. But the reverse is not possible: Immutable references will never coerce to mutable references. Because of the borrowing rules, if you have a mutable reference, that mutable reference must be the only reference to that data (otherwise, the program wouldn‚Äôt compile). Converting one mutable reference to one immutable reference will never break the borrowing rules. Converting an immutable reference to a mutable reference would require that the initial immutable reference is the only immutable reference to that data, but the borrowing rules don‚Äôt guarantee that. Therefore, Rust can‚Äôt make the assumption that converting an immutable reference to a mutable reference is possible.","breadcrumbs":"Smart Pointers ¬ª Treating Smart Pointers Like Regular References ¬ª Handling Deref Coercion with Mutable References","id":"278","title":"Handling Deref Coercion with Mutable References"},"279":{"body":"The second trait important to the smart pointer pattern is Drop, which lets you customize what happens when a value is about to go out of scope. You can provide an implementation for the Drop trait on any type, and that code can be used to release resources like files or network connections. We‚Äôre introducing Drop in the context of smart pointers because the functionality of the Drop trait is almost always used when implementing a smart pointer. For example, when a Box<T> is dropped, it will deallocate the space on the heap that the box points to. In some languages, for some types, the programmer must call code to free memory or resources every time they finish using an instance of those types. Examples include file handles, sockets, and locks. If the programmer forgets, the system might become overloaded and crash. In Rust, you can specify that a particular bit of code be run whenever a value goes out of scope, and the compiler will insert this code automatically. As a result, you don‚Äôt need to be careful about placing cleanup code everywhere in a program that an instance of a particular type is finished with‚Äîyou still won‚Äôt leak resources! You specify the code to run when a value goes out of scope by implementing the Drop trait. The Drop trait requires you to implement one method named drop that takes a mutable reference to self. To see when Rust calls drop, let‚Äôs implement drop with println! statements for now. Listing 15-14 shows a CustomSmartPointer struct whose only custom functionality is that it will print Dropping CustomSmartPointer! when the instance goes out of scope, to show when Rust runs the drop method. Filename: src/main.rs struct CustomSmartPointer { data: String,\\n} impl Drop for CustomSmartPointer { fn drop(&mut self) { println!(\\"Dropping CustomSmartPointer with data `{}`!\\", self.data); }\\n} fn main() { let c = CustomSmartPointer { data: String::from(\\"my stuff\\"), }; let d = CustomSmartPointer { data: String::from(\\"other stuff\\"), }; println!(\\"CustomSmartPointers created\\");\\n} Listing 15-14: A CustomSmartPointer struct that implements the Drop trait where we would put our cleanup code The Drop trait is included in the prelude, so we don‚Äôt need to bring it into scope. We implement the Drop trait on CustomSmartPointer and provide an implementation for the drop method that calls println!. The body of the drop method is where you would place any logic that you wanted to run when an instance of your type goes out of scope. We‚Äôre printing some text here to demonstrate visually when Rust will call drop. In main, we create two instances of CustomSmartPointer and then print CustomSmartPointers created. At the end of main, our instances of CustomSmartPointer will go out of scope, and Rust will call the code we put in the drop method, printing our final message. Note that we didn‚Äôt need to call the drop method explicitly. When we run this program, we‚Äôll see the following output: $ cargo run Compiling drop-example v0.1.0 (file:///projects/drop-example) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.60s Running `target/debug/drop-example`\\nCustomSmartPointers created\\nDropping CustomSmartPointer with data `other stuff`!\\nDropping CustomSmartPointer with data `my stuff`! Rust automatically called drop for us when our instances went out of scope, calling the code we specified. Variables are dropped in the reverse order of their creation, so d was dropped before c. This example‚Äôs purpose is to give you a visual guide to how the drop method works; usually you would specify the cleanup code that your type needs to run rather than a print message. Unfortunately, it‚Äôs not straightforward to disable the automatic drop functionality. Disabling drop isn‚Äôt usually necessary; the whole point of the Drop trait is that it‚Äôs taken care of automatically. Occasionally, however, you might want to clean up a value early. One example is when using smart pointers that manage locks: You might want to force the drop method that releases the lock so that other code in the same scope can acquire the lock. Rust doesn‚Äôt let you call the Drop trait‚Äôs drop method manually; instead, you have to call the std::mem::drop function provided by the standard library if you want to force a value to be dropped before the end of its scope. Trying to call the Drop trait‚Äôs drop method manually by modifying the main function from Listing 15-14 won‚Äôt work, as shown in Listing 15-15. Filename: src/main.rs # struct CustomSmartPointer {\\n# data: String,\\n# }\\n# # impl Drop for CustomSmartPointer {\\n# fn drop(&mut self) {\\n# println!(\\"Dropping CustomSmartPointer with data `{}`!\\", self.data);\\n# }\\n# }\\n# fn main() { let c = CustomSmartPointer { data: String::from(\\"some data\\"), }; println!(\\"CustomSmartPointer created\\"); c.drop(); println!(\\"CustomSmartPointer dropped before the end of main\\");\\n} Listing 15-15: Attempting to call the drop method from the Drop trait manually to clean up early When we try to compile this code, we‚Äôll get this error: $ cargo run Compiling drop-example v0.1.0 (file:///projects/drop-example)\\nerror[E0040]: explicit use of destructor method --> src/main.rs:16:7 |\\n16 | c.drop(); | ^^^^ explicit destructor calls not allowed |\\nhelp: consider using `drop` function |\\n16 | drop(c); | +++++ ~ For more information about this error, try `rustc --explain E0040`.\\nerror: could not compile `drop-example` (bin \\"drop-example\\") due to 1 previous error This error message states that we‚Äôre not allowed to explicitly call drop. The error message uses the term destructor , which is the general programming term for a function that cleans up an instance. A destructor is analogous to a constructor , which creates an instance. The drop function in Rust is one particular destructor. Rust doesn‚Äôt let us call drop explicitly, because Rust would still automatically call drop on the value at the end of main. This would cause a double free error because Rust would be trying to clean up the same value twice. We can‚Äôt disable the automatic insertion of drop when a value goes out of scope, and we can‚Äôt call the drop method explicitly. So, if we need to force a value to be cleaned up early, we use the std::mem::drop function. The std::mem::drop function is different from the drop method in the Drop trait. We call it by passing as an argument the value we want to force-drop. The function is in the prelude, so we can modify main in Listing 15-15 to call the drop function, as shown in Listing 15-16. Filename: src/main.rs # struct CustomSmartPointer {\\n# data: String,\\n# }\\n# # impl Drop for CustomSmartPointer {\\n# fn drop(&mut self) {\\n# println!(\\"Dropping CustomSmartPointer with data `{}`!\\", self.data);\\n# }\\n# }\\n# fn main() { let c = CustomSmartPointer { data: String::from(\\"some data\\"), }; println!(\\"CustomSmartPointer created\\"); drop(c); println!(\\"CustomSmartPointer dropped before the end of main\\");\\n} Listing 15-16: Calling std::mem::drop to explicitly drop a value before it goes out of scope Running this code will print the following: $ cargo run Compiling drop-example v0.1.0 (file:///projects/drop-example) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.73s Running `target/debug/drop-example`\\nCustomSmartPointer created\\nDropping CustomSmartPointer with data `some data`!\\nCustomSmartPointer dropped before the end of main The text Dropping CustomSmartPointer with data `some data`! is printed between the CustomSmartPointer created and CustomSmartPointer dropped before the end of main text, showing that the drop method code is called to drop c at that point. You can use code specified in a Drop trait implementation in many ways to make cleanup convenient and safe: For instance, you could use it to create your own memory allocator! With the Drop trait and Rust‚Äôs ownership system, you don‚Äôt have to remember to clean up, because Rust does it automatically. You also don‚Äôt have to worry about problems resulting from accidentally cleaning up values still in use: The ownership system that makes sure references are always valid also ensures that drop gets called only once when the value is no longer being used. Now that we‚Äôve examined Box<T> and some of the characteristics of smart pointers, let‚Äôs look at a few other smart pointers defined in the standard library.","breadcrumbs":"Smart Pointers ¬ª Running Code on Cleanup with the Drop Trait ¬ª Running Code on Cleanup with the Drop Trait","id":"279","title":"Running Code on Cleanup with the Drop Trait"},"28":{"body":"Let‚Äôs create a new project using Cargo and look at how it differs from our original ‚ÄúHello, world!‚Äù project. Navigate back to your projects directory (or wherever you decided to store your code). Then, on any operating system, run the following: $ cargo new hello_cargo\\n$ cd hello_cargo The first command creates a new directory and project called hello_cargo . We‚Äôve named our project hello_cargo , and Cargo creates its files in a directory of the same name. Go into the hello_cargo directory and list the files. You‚Äôll see that Cargo has generated two files and one directory for us: a Cargo.toml file and a src directory with a main.rs file inside. It has also initialized a new Git repository along with a .gitignore file. Git files won‚Äôt be generated if you run cargo new within an existing Git repository; you can override this behavior by using cargo new --vcs=git. Note: Git is a common version control system. You can change cargo new to use a different version control system or no version control system by using the --vcs flag. Run cargo new --help to see the available options. Open Cargo.toml in your text editor of choice. It should look similar to the code in Listing 1-2. Filename: Cargo.toml [package]\\nname = \\"hello_cargo\\"\\nversion = \\"0.1.0\\"\\nedition = \\"2024\\" [dependencies] Listing 1-2: Contents of Cargo.toml generated by cargo new This file is in the TOML ( Tom‚Äôs Obvious, Minimal Language ) format, which is Cargo‚Äôs configuration format. The first line, [package], is a section heading that indicates that the following statements are configuring a package. As we add more information to this file, we‚Äôll add other sections. The next three lines set the configuration information Cargo needs to compile your program: the name, the version, and the edition of Rust to use. We‚Äôll talk about the edition key in Appendix E . The last line, [dependencies], is the start of a section for you to list any of your project‚Äôs dependencies. In Rust, packages of code are referred to as crates . We won‚Äôt need any other crates for this project, but we will in the first project in Chapter 2, so we‚Äôll use this dependencies section then. Now open src/main.rs and take a look: Filename: src/main.rs fn main() { println!(\\"Hello, world!\\");\\n} Cargo has generated a ‚ÄúHello, world!‚Äù program for you, just like the one we wrote in Listing 1-1! So far, the differences between our project and the project Cargo generated are that Cargo placed the code in the src directory, and we have a Cargo.toml configuration file in the top directory. Cargo expects your source files to live inside the src directory. The top-level project directory is just for README files, license information, configuration files, and anything else not related to your code. Using Cargo helps you organize your projects. There‚Äôs a place for everything, and everything is in its place. If you started a project that doesn‚Äôt use Cargo, as we did with the ‚ÄúHello, world!‚Äù project, you can convert it to a project that does use Cargo. Move the project code into the src directory and create an appropriate Cargo.toml file. One easy way to get that Cargo.toml file is to run cargo init, which will create it for you automatically.","breadcrumbs":"Getting Started ¬ª Hello, Cargo! ¬ª Creating a Project with Cargo","id":"28","title":"Creating a Project with Cargo"},"280":{"body":"In the majority of cases, ownership is clear: You know exactly which variable owns a given value. However, there are cases when a single value might have multiple owners. For example, in graph data structures, multiple edges might point to the same node, and that node is conceptually owned by all of the edges that point to it. A node shouldn‚Äôt be cleaned up unless it doesn‚Äôt have any edges pointing to it and so has no owners. You have to enable multiple ownership explicitly by using the Rust type Rc<T>, which is an abbreviation for reference counting . The Rc<T> type keeps track of the number of references to a value to determine whether or not the value is still in use. If there are zero references to a value, the value can be cleaned up without any references becoming invalid. Imagine Rc<T> as a TV in a family room. When one person enters to watch TV, they turn it on. Others can come into the room and watch the TV. When the last person leaves the room, they turn off the TV because it‚Äôs no longer being used. If someone turns off the TV while others are still watching it, there would be an uproar from the remaining TV watchers! We use the Rc<T> type when we want to allocate some data on the heap for multiple parts of our program to read and we can‚Äôt determine at compile time which part will finish using the data last. If we knew which part would finish last, we could just make that part the data‚Äôs owner, and the normal ownership rules enforced at compile time would take effect. Note that Rc<T> is only for use in single-threaded scenarios. When we discuss concurrency in Chapter 16, we‚Äôll cover how to do reference counting in multithreaded programs.","breadcrumbs":"Smart Pointers ¬ª Rc<T>, the Reference Counted Smart Pointer ¬ª Rc<T>, the Reference-Counted Smart Pointer","id":"280","title":"Rc<T>, the Reference-Counted Smart Pointer"},"281":{"body":"Let‚Äôs return to our cons list example in Listing 15-5. Recall that we defined it using Box<T>. This time, we‚Äôll create two lists that both share ownership of a third list. Conceptually, this looks similar to Figure 15-3. Figure 15-3: Two lists, b and c, sharing ownership of a third list, a We‚Äôll create list a that contains 5 and then 10. Then, we‚Äôll make two more lists: b that starts with 3 and c that starts with 4. Both the b and c lists will then continue on to the first a list containing 5 and 10. In other words, both lists will share the first list containing 5 and 10. Trying to implement this scenario using our definition of List with Box<T> won‚Äôt work, as shown in Listing 15-17. Filename: src/main.rs enum List { Cons(i32, Box<List>), Nil,\\n} use crate::List::{Cons, Nil}; fn main() { let a = Cons(5, Box::new(Cons(10, Box::new(Nil)))); let b = Cons(3, Box::new(a)); let c = Cons(4, Box::new(a));\\n} Listing 15-17: Demonstrating that we‚Äôre not allowed to have two lists using Box&lt;T&gt; that try to share ownership of a third list When we compile this code, we get this error: $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list)\\nerror[E0382]: use of moved value: `a` --> src/main.rs:11:30 |\\n9 | let a = Cons(5, Box::new(Cons(10, Box::new(Nil)))); | - move occurs because `a` has type `List`, which does not implement the `Copy` trait\\n10 | let b = Cons(3, Box::new(a)); | - value moved here\\n11 | let c = Cons(4, Box::new(a)); | ^ value used here after move For more information about this error, try `rustc --explain E0382`.\\nerror: could not compile `cons-list` (bin \\"cons-list\\") due to 1 previous error The Cons variants own the data they hold, so when we create the b list, a is moved into b and b owns a. Then, when we try to use a again when creating c, we‚Äôre not allowed to because a has been moved. We could change the definition of Cons to hold references instead, but then we would have to specify lifetime parameters. By specifying lifetime parameters, we would be specifying that every element in the list will live at least as long as the entire list. This is the case for the elements and lists in Listing 15-17, but not in every scenario. Instead, we‚Äôll change our definition of List to use Rc<T> in place of Box<T>, as shown in Listing 15-18. Each Cons variant will now hold a value and an Rc<T> pointing to a List. When we create b, instead of taking ownership of a, we‚Äôll clone the Rc<List> that a is holding, thereby increasing the number of references from one to two and letting a and b share ownership of the data in that Rc<List>. We‚Äôll also clone a when creating c, increasing the number of references from two to three. Every time we call Rc::clone, the reference count to the data within the Rc<List> will increase, and the data won‚Äôt be cleaned up unless there are zero references to it. Filename: src/main.rs enum List { Cons(i32, Rc<List>), Nil,\\n} use crate::List::{Cons, Nil};\\nuse std::rc::Rc; fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); let b = Cons(3, Rc::clone(&a)); let c = Cons(4, Rc::clone(&a));\\n} Listing 15-18: A definition of List that uses Rc&lt;T&gt; We need to add a use statement to bring Rc<T> into scope because it‚Äôs not in the prelude. In main, we create the list holding 5 and 10 and store it in a new Rc<List> in a. Then, when we create b and c, we call the Rc::clone function and pass a reference to the Rc<List> in a as an argument. We could have called a.clone() rather than Rc::clone(&a), but Rust‚Äôs convention is to use Rc::clone in this case. The implementation of Rc::clone doesn‚Äôt make a deep copy of all the data like most types‚Äô implementations of clone do. The call to Rc::clone only increments the reference count, which doesn‚Äôt take much time. Deep copies of data can take a lot of time. By using Rc::clone for reference counting, we can visually distinguish between the deep-copy kinds of clones and the kinds of clones that increase the reference count. When looking for performance problems in the code, we only need to consider the deep-copy clones and can disregard calls to Rc::clone.","breadcrumbs":"Smart Pointers ¬ª Rc<T>, the Reference Counted Smart Pointer ¬ª Sharing Data","id":"281","title":"Sharing Data"},"282":{"body":"Let‚Äôs change our working example in Listing 15-18 so that we can see the reference counts changing as we create and drop references to the Rc<List> in a. In Listing 15-19, we‚Äôll change main so that it has an inner scope around list c; then, we can see how the reference count changes when c goes out of scope. Filename: src/main.rs # enum List {\\n# Cons(i32, Rc<List>),\\n# Nil,\\n# }\\n# # use crate::List::{Cons, Nil};\\n# use std::rc::Rc;\\n# // --snip-- fn main() { let a = Rc::new(Cons(5, Rc::new(Cons(10, Rc::new(Nil))))); println!(\\"count after creating a = {}\\", Rc::strong_count(&a)); let b = Cons(3, Rc::clone(&a)); println!(\\"count after creating b = {}\\", Rc::strong_count(&a)); { let c = Cons(4, Rc::clone(&a)); println!(\\"count after creating c = {}\\", Rc::strong_count(&a)); } println!(\\"count after c goes out of scope = {}\\", Rc::strong_count(&a));\\n} Listing 15-19: Printing the reference count At each point in the program where the reference count changes, we print the reference count, which we get by calling the Rc::strong_count function. This function is named strong_count rather than count because the Rc<T> type also has a weak_count; we‚Äôll see what weak_count is used for in ‚ÄúPreventing Reference Cycles Using Weak<T>‚Äù . This code prints the following: $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.45s Running `target/debug/cons-list`\\ncount after creating a = 1\\ncount after creating b = 2\\ncount after creating c = 3\\ncount after c goes out of scope = 2 We can see that the Rc<List> in a has an initial reference count of 1; then, each time we call clone, the count goes up by 1. When c goes out of scope, the count goes down by 1. We don‚Äôt have to call a function to decrease the reference count like we have to call Rc::clone to increase the reference count: The implementation of the Drop trait decreases the reference count automatically when an Rc<T> value goes out of scope. What we can‚Äôt see in this example is that when b and then a go out of scope at the end of main, the count is 0, and the Rc<List> is cleaned up completely. Using Rc<T> allows a single value to have multiple owners, and the count ensures that the value remains valid as long as any of the owners still exist. Via immutable references, Rc<T> allows you to share data between multiple parts of your program for reading only. If Rc<T> allowed you to have multiple mutable references too, you might violate one of the borrowing rules discussed in Chapter 4: Multiple mutable borrows to the same place can cause data races and inconsistencies. But being able to mutate data is very useful! In the next section, we‚Äôll discuss the interior mutability pattern and the RefCell<T> type that you can use in conjunction with an Rc<T> to work with this immutability restriction.","breadcrumbs":"Smart Pointers ¬ª Rc<T>, the Reference Counted Smart Pointer ¬ª Cloning to Increase the Reference Count","id":"282","title":"Cloning to Increase the Reference Count"},"283":{"body":"Interior mutability is a design pattern in Rust that allows you to mutate data even when there are immutable references to that data; normally, this action is disallowed by the borrowing rules. To mutate data, the pattern uses unsafe code inside a data structure to bend Rust‚Äôs usual rules that govern mutation and borrowing. Unsafe code indicates to the compiler that we‚Äôre checking the rules manually instead of relying on the compiler to check them for us; we will discuss unsafe code more in Chapter 20. We can use types that use the interior mutability pattern only when we can ensure that the borrowing rules will be followed at runtime, even though the compiler can‚Äôt guarantee that. The unsafe code involved is then wrapped in a safe API, and the outer type is still immutable. Let‚Äôs explore this concept by looking at the RefCell<T> type that follows the interior mutability pattern.","breadcrumbs":"Smart Pointers ¬ª RefCell<T> and the Interior Mutability Pattern ¬ª RefCell<T> and the Interior Mutability Pattern","id":"283","title":"RefCell<T> and the Interior Mutability Pattern"},"284":{"body":"Unlike Rc<T>, the RefCell<T> type represents single ownership over the data it holds. So, what makes RefCell<T> different from a type like Box<T>? Recall the borrowing rules you learned in Chapter 4: At any given time, you can have either one mutable reference or any number of immutable references (but not both). References must always be valid. With references and Box<T>, the borrowing rules‚Äô invariants are enforced at compile time. With RefCell<T>, these invariants are enforced at runtime . With references, if you break these rules, you‚Äôll get a compiler error. With RefCell<T>, if you break these rules, your program will panic and exit. The advantages of checking the borrowing rules at compile time are that errors will be caught sooner in the development process, and there is no impact on runtime performance because all the analysis is completed beforehand. For those reasons, checking the borrowing rules at compile time is the best choice in the majority of cases, which is why this is Rust‚Äôs default. The advantage of checking the borrowing rules at runtime instead is that certain memory-safe scenarios are then allowed, where they would‚Äôve been disallowed by the compile-time checks. Static analysis, like the Rust compiler, is inherently conservative. Some properties of code are impossible to detect by analyzing the code: The most famous example is the Halting Problem, which is beyond the scope of this book but is an interesting topic to research. Because some analysis is impossible, if the Rust compiler can‚Äôt be sure the code complies with the ownership rules, it might reject a correct program; in this way, it‚Äôs conservative. If Rust accepted an incorrect program, users wouldn‚Äôt be able to trust the guarantees Rust makes. However, if Rust rejects a correct program, the programmer will be inconvenienced, but nothing catastrophic can occur. The RefCell<T> type is useful when you‚Äôre sure your code follows the borrowing rules but the compiler is unable to understand and guarantee that. Similar to Rc<T>, RefCell<T> is only for use in single-threaded scenarios and will give you a compile-time error if you try using it in a multithreaded context. We‚Äôll talk about how to get the functionality of RefCell<T> in a multithreaded program in Chapter 16. Here is a recap of the reasons to choose Box<T>, Rc<T>, or RefCell<T>: Rc<T> enables multiple owners of the same data; Box<T> and RefCell<T> have single owners. Box<T> allows immutable or mutable borrows checked at compile time; Rc<T> allows only immutable borrows checked at compile time; RefCell<T> allows immutable or mutable borrows checked at runtime. Because RefCell<T> allows mutable borrows checked at runtime, you can mutate the value inside the RefCell<T> even when the RefCell<T> is immutable. Mutating the value inside an immutable value is the interior mutability pattern. Let‚Äôs look at a situation in which interior mutability is useful and examine how it‚Äôs possible.","breadcrumbs":"Smart Pointers ¬ª RefCell<T> and the Interior Mutability Pattern ¬ª Enforcing Borrowing Rules at Runtime","id":"284","title":"Enforcing Borrowing Rules at Runtime"},"285":{"body":"A consequence of the borrowing rules is that when you have an immutable value, you can‚Äôt borrow it mutably. For example, this code won‚Äôt compile: fn main() { let x = 5; let y = &mut x;\\n} If you tried to compile this code, you‚Äôd get the following error: $ cargo run Compiling borrowing v0.1.0 (file:///projects/borrowing)\\nerror[E0596]: cannot borrow `x` as mutable, as it is not declared as mutable --> src/main.rs:3:13 |\\n3 | let y = &mut x; | ^^^^^^ cannot borrow as mutable |\\nhelp: consider changing this to be mutable |\\n2 | let mut x = 5; | +++ For more information about this error, try `rustc --explain E0596`.\\nerror: could not compile `borrowing` (bin \\"borrowing\\") due to 1 previous error However, there are situations in which it would be useful for a value to mutate itself in its methods but appear immutable to other code. Code outside the value‚Äôs methods would not be able to mutate the value. Using RefCell<T> is one way to get the ability to have interior mutability, but RefCell<T> doesn‚Äôt get around the borrowing rules completely: The borrow checker in the compiler allows this interior mutability, and the borrowing rules are checked at runtime instead. If you violate the rules, you‚Äôll get a panic! instead of a compiler error. Let‚Äôs work through a practical example where we can use RefCell<T> to mutate an immutable value and see why that is useful. Testing with Mock Objects Sometimes during testing a programmer will use a type in place of another type, in order to observe particular behavior and assert that it‚Äôs implemented correctly. This placeholder type is called a test double . Think of it in the sense of a stunt double in filmmaking, where a person steps in and substitutes for an actor to do a particularly tricky scene. Test doubles stand in for other types when we‚Äôre running tests. Mock objects are specific types of test doubles that record what happens during a test so that you can assert that the correct actions took place. Rust doesn‚Äôt have objects in the same sense as other languages have objects, and Rust doesn‚Äôt have mock object functionality built into the standard library as some other languages do. However, you can definitely create a struct that will serve the same purposes as a mock object. Here‚Äôs the scenario we‚Äôll test: We‚Äôll create a library that tracks a value against a maximum value and sends messages based on how close to the maximum value the current value is. This library could be used to keep track of a user‚Äôs quota for the number of API calls they‚Äôre allowed to make, for example. Our library will only provide the functionality of tracking how close to the maximum a value is and what the messages should be at what times. Applications that use our library will be expected to provide the mechanism for sending the messages: The application could show the message to the user directly, send an email, send a text message, or do something else. The library doesn‚Äôt need to know that detail. All it needs is something that implements a trait we‚Äôll provide, called Messenger. Listing 15-20 shows the library code. Filename: src/lib.rs pub trait Messenger { fn send(&self, msg: &str);\\n} pub struct LimitTracker<\'a, T: Messenger> { messenger: &\'a T, value: usize, max: usize,\\n} impl<\'a, T> LimitTracker<\'a, T>\\nwhere T: Messenger,\\n{ pub fn new(messenger: &\'a T, max: usize) -> LimitTracker<\'a, T> { LimitTracker { messenger, value: 0, max, } } pub fn set_value(&mut self, value: usize) { self.value = value; let percentage_of_max = self.value as f64 / self.max as f64; if percentage_of_max >= 1.0 { self.messenger.send(\\"Error: You are over your quota!\\"); } else if percentage_of_max >= 0.9 { self.messenger .send(\\"Urgent warning: You\'ve used up over 90% of your quota!\\"); } else if percentage_of_max >= 0.75 { self.messenger .send(\\"Warning: You\'ve used up over 75% of your quota!\\"); } }\\n} Listing 15-20: A library to keep track of how close a value is to a maximum value and warn when the value is at certain levels One important part of this code is that the Messenger trait has one method called send that takes an immutable reference to self and the text of the message. This trait is the interface our mock object needs to implement so that the mock can be used in the same way a real object is. The other important part is that we want to test the behavior of the set_value method on the LimitTracker. We can change what we pass in for the value parameter, but set_value doesn‚Äôt return anything for us to make assertions on. We want to be able to say that if we create a LimitTracker with something that implements the Messenger trait and a particular value for max, the messenger is told to send the appropriate messages when we pass different numbers for value. We need a mock object that, instead of sending an email or text message when we call send, will only keep track of the messages it‚Äôs told to send. We can create a new instance of the mock object, create a LimitTracker that uses the mock object, call the set_value method on LimitTracker, and then check that the mock object has the messages we expect. Listing 15-21 shows an attempt to implement a mock object to do just that, but the borrow checker won‚Äôt allow it. Filename: src/lib.rs # pub trait Messenger {\\n# fn send(&self, msg: &str);\\n# }\\n# # pub struct LimitTracker<\'a, T: Messenger> {\\n# messenger: &\'a T,\\n# value: usize,\\n# max: usize,\\n# }\\n# # impl<\'a, T> LimitTracker<\'a, T>\\n# where\\n# T: Messenger,\\n# {\\n# pub fn new(messenger: &\'a T, max: usize) -> LimitTracker<\'a, T> {\\n# LimitTracker {\\n# messenger,\\n# value: 0,\\n# max,\\n# }\\n# }\\n# # pub fn set_value(&mut self, value: usize) {\\n# self.value = value;\\n# # let percentage_of_max = self.value as f64 / self.max as f64;\\n# # if percentage_of_max >= 1.0 {\\n# self.messenger.send(\\"Error: You are over your quota!\\");\\n# } else if percentage_of_max >= 0.9 {\\n# self.messenger\\n# .send(\\"Urgent warning: You\'ve used up over 90% of your quota!\\");\\n# } else if percentage_of_max >= 0.75 {\\n# self.messenger\\n# .send(\\"Warning: You\'ve used up over 75% of your quota!\\");\\n# }\\n# }\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; struct MockMessenger { sent_messages: Vec<String>, } impl MockMessenger { fn new() -> MockMessenger { MockMessenger { sent_messages: vec![], } } } impl Messenger for MockMessenger { fn send(&self, message: &str) { self.sent_messages.push(String::from(message)); } } #[test] fn it_sends_an_over_75_percent_warning_message() { let mock_messenger = MockMessenger::new(); let mut limit_tracker = LimitTracker::new(&mock_messenger, 100); limit_tracker.set_value(80); assert_eq!(mock_messenger.sent_messages.len(), 1); }\\n} Listing 15-21: An attempt to implement a MockMessenger that isn‚Äôt allowed by the borrow checker This test code defines a MockMessenger struct that has a sent_messages field with a Vec of String values to keep track of the messages it‚Äôs told to send. We also define an associated function new to make it convenient to create new MockMessenger values that start with an empty list of messages. We then implement the Messenger trait for MockMessenger so that we can give a MockMessenger to a LimitTracker. In the definition of the send method, we take the message passed in as a parameter and store it in the MockMessenger list of sent_messages. In the test, we‚Äôre testing what happens when the LimitTracker is told to set value to something that is more than 75 percent of the max value. First, we create a new MockMessenger, which will start with an empty list of messages. Then, we create a new LimitTracker and give it a reference to the new MockMessenger and a max value of 100. We call the set_value method on the LimitTracker with a value of 80, which is more than 75 percent of 100. Then, we assert that the list of messages that the MockMessenger is keeping track of should now have one message in it. However, there‚Äôs one problem with this test, as shown here: $ cargo test Compiling limit-tracker v0.1.0 (file:///projects/limit-tracker)\\nerror[E0596]: cannot borrow `self.sent_messages` as mutable, as it is behind a `&` reference --> src/lib.rs:58:13 |\\n58 | self.sent_messages.push(String::from(message)); | ^^^^^^^^^^^^^^^^^^ `self` is a `&` reference, so the data it refers to cannot be borrowed as mutable |\\nhelp: consider changing this to be a mutable reference in the `impl` method and the `trait` definition |\\n2 ~ fn send(&mut self, msg: &str);\\n3 | }\\n...\\n56 | impl Messenger for MockMessenger {\\n57 ~ fn send(&mut self, message: &str) { | For more information about this error, try `rustc --explain E0596`.\\nerror: could not compile `limit-tracker` (lib test) due to 1 previous error We can‚Äôt modify the MockMessenger to keep track of the messages, because the send method takes an immutable reference to self. We also can‚Äôt take the suggestion from the error text to use &mut self in both the impl method and the trait definition. We do not want to change the Messenger trait solely for the sake of testing. Instead, we need to find a way to make our test code work correctly with our existing design. This is a situation in which interior mutability can help! We‚Äôll store the sent_messages within a RefCell<T>, and then the send method will be able to modify sent_messages to store the messages we‚Äôve seen. Listing 15-22 shows what that looks like. Filename: src/lib.rs # pub trait Messenger {\\n# fn send(&self, msg: &str);\\n# }\\n# # pub struct LimitTracker<\'a, T: Messenger> {\\n# messenger: &\'a T,\\n# value: usize,\\n# max: usize,\\n# }\\n# # impl<\'a, T> LimitTracker<\'a, T>\\n# where\\n# T: Messenger,\\n# {\\n# pub fn new(messenger: &\'a T, max: usize) -> LimitTracker<\'a, T> {\\n# LimitTracker {\\n# messenger,\\n# value: 0,\\n# max,\\n# }\\n# }\\n# # pub fn set_value(&mut self, value: usize) {\\n# self.value = value;\\n# # let percentage_of_max = self.value as f64 / self.max as f64;\\n# # if percentage_of_max >= 1.0 {\\n# self.messenger.send(\\"Error: You are over your quota!\\");\\n# } else if percentage_of_max >= 0.9 {\\n# self.messenger\\n# .send(\\"Urgent warning: You\'ve used up over 90% of your quota!\\");\\n# } else if percentage_of_max >= 0.75 {\\n# self.messenger\\n# .send(\\"Warning: You\'ve used up over 75% of your quota!\\");\\n# }\\n# }\\n# }\\n# #[cfg(test)]\\nmod tests { use super::*; use std::cell::RefCell; struct MockMessenger { sent_messages: RefCell<Vec<String>>, } impl MockMessenger { fn new() -> MockMessenger { MockMessenger { sent_messages: RefCell::new(vec![]), } } } impl Messenger for MockMessenger { fn send(&self, message: &str) { self.sent_messages.borrow_mut().push(String::from(message)); } } #[test] fn it_sends_an_over_75_percent_warning_message() { // --snip--\\n# let mock_messenger = MockMessenger::new();\\n# let mut limit_tracker = LimitTracker::new(&mock_messenger, 100);\\n# # limit_tracker.set_value(80); assert_eq!(mock_messenger.sent_messages.borrow().len(), 1); }\\n} Listing 15-22: Using RefCell&lt;T&gt; to mutate an inner value while the outer value is considered immutable The sent_messages field is now of type RefCell<Vec<String>> instead of Vec<String>. In the new function, we create a new RefCell<Vec<String>> instance around the empty vector. For the implementation of the send method, the first parameter is still an immutable borrow of self, which matches the trait definition. We call borrow_mut on the RefCell<Vec<String>> in self.sent_messages to get a mutable reference to the value inside the RefCell<Vec<String>>, which is the vector. Then, we can call push on the mutable reference to the vector to keep track of the messages sent during the test. The last change we have to make is in the assertion: To see how many items are in the inner vector, we call borrow on the RefCell<Vec<String>> to get an immutable reference to the vector. Now that you‚Äôve seen how to use RefCell<T>, let‚Äôs dig into how it works! Tracking Borrows at Runtime When creating immutable and mutable references, we use the & and &mut syntax, respectively. With RefCell<T>, we use the borrow and borrow_mut methods, which are part of the safe API that belongs to RefCell<T>. The borrow method returns the smart pointer type Ref<T>, and borrow_mut returns the smart pointer type RefMut<T>. Both types implement Deref, so we can treat them like regular references. The RefCell<T> keeps track of how many Ref<T> and RefMut<T> smart pointers are currently active. Every time we call borrow, the RefCell<T> increases its count of how many immutable borrows are active. When a Ref<T> value goes out of scope, the count of immutable borrows goes down by 1. Just like the compile-time borrowing rules, RefCell<T> lets us have many immutable borrows or one mutable borrow at any point in time. If we try to violate these rules, rather than getting a compiler error as we would with references, the implementation of RefCell<T> will panic at runtime. Listing 15-23 shows a modification of the implementation of send in Listing 15-22. We‚Äôre deliberately trying to create two mutable borrows active for the same scope to illustrate that RefCell<T> prevents us from doing this at runtime. Filename: src/lib.rs # pub trait Messenger {\\n# fn send(&self, msg: &str);\\n# }\\n# # pub struct LimitTracker<\'a, T: Messenger> {\\n# messenger: &\'a T,\\n# value: usize,\\n# max: usize,\\n# }\\n# # impl<\'a, T> LimitTracker<\'a, T>\\n# where\\n# T: Messenger,\\n# {\\n# pub fn new(messenger: &\'a T, max: usize) -> LimitTracker<\'a, T> {\\n# LimitTracker {\\n# messenger,\\n# value: 0,\\n# max,\\n# }\\n# }\\n# # pub fn set_value(&mut self, value: usize) {\\n# self.value = value;\\n# # let percentage_of_max = self.value as f64 / self.max as f64;\\n# # if percentage_of_max >= 1.0 {\\n# self.messenger.send(\\"Error: You are over your quota!\\");\\n# } else if percentage_of_max >= 0.9 {\\n# self.messenger\\n# .send(\\"Urgent warning: You\'ve used up over 90% of your quota!\\");\\n# } else if percentage_of_max >= 0.75 {\\n# self.messenger\\n# .send(\\"Warning: You\'ve used up over 75% of your quota!\\");\\n# }\\n# }\\n# }\\n# # #[cfg(test)]\\n# mod tests {\\n# use super::*;\\n# use std::cell::RefCell;\\n# # struct MockMessenger {\\n# sent_messages: RefCell<Vec<String>>,\\n# }\\n# # impl MockMessenger {\\n# fn new() -> MockMessenger {\\n# MockMessenger {\\n# sent_messages: RefCell::new(vec![]),\\n# }\\n# }\\n# }\\n# impl Messenger for MockMessenger { fn send(&self, message: &str) { let mut one_borrow = self.sent_messages.borrow_mut(); let mut two_borrow = self.sent_messages.borrow_mut(); one_borrow.push(String::from(message)); two_borrow.push(String::from(message)); } }\\n# # #[test]\\n# fn it_sends_an_over_75_percent_warning_message() {\\n# let mock_messenger = MockMessenger::new();\\n# let mut limit_tracker = LimitTracker::new(&mock_messenger, 100);\\n# # limit_tracker.set_value(80);\\n# # assert_eq!(mock_messenger.sent_messages.borrow().len(), 1);\\n# }\\n# } Listing 15-23: Creating two mutable references in the same scope to see that RefCell&lt;T&gt; will panic We create a variable one_borrow for the RefMut<T> smart pointer returned from borrow_mut. Then, we create another mutable borrow in the same way in the variable two_borrow. This makes two mutable references in the same scope, which isn‚Äôt allowed. When we run the tests for our library, the code in Listing 15-23 will compile without any errors, but the test will fail: $ cargo test Compiling limit-tracker v0.1.0 (file:///projects/limit-tracker) Finished `test` profile [unoptimized + debuginfo] target(s) in 0.91s Running unittests src/lib.rs (target/debug/deps/limit_tracker-e599811fa246dbde) running 1 test\\ntest tests::it_sends_an_over_75_percent_warning_message ... FAILED failures: ---- tests::it_sends_an_over_75_percent_warning_message stdout ---- thread \'tests::it_sends_an_over_75_percent_warning_message\' panicked at src/lib.rs:60:53:\\nalready borrowed: BorrowMutError\\nnote: run with `RUST_BACKTRACE=1` environment variable to display a backtrace failures: tests::it_sends_an_over_75_percent_warning_message test result: FAILED. 0 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s error: test failed, to rerun pass `--lib` Notice that the code panicked with the message already borrowed: BorrowMutError. This is how RefCell<T> handles violations of the borrowing rules at runtime. Choosing to catch borrowing errors at runtime rather than compile time, as we‚Äôve done here, means you‚Äôd potentially be finding mistakes in your code later in the development process: possibly not until your code was deployed to production. Also, your code would incur a small runtime performance penalty as a result of keeping track of the borrows at runtime rather than compile time. However, using RefCell<T> makes it possible to write a mock object that can modify itself to keep track of the messages it has seen while you‚Äôre using it in a context where only immutable values are allowed. You can use RefCell<T> despite its trade-offs to get more functionality than regular references provide.","breadcrumbs":"Smart Pointers ¬ª RefCell<T> and the Interior Mutability Pattern ¬ª Using Interior Mutability","id":"285","title":"Using Interior Mutability"},"286":{"body":"A common way to use RefCell<T> is in combination with Rc<T>. Recall that Rc<T> lets you have multiple owners of some data, but it only gives immutable access to that data. If you have an Rc<T> that holds a RefCell<T>, you can get a value that can have multiple owners and that you can mutate! For example, recall the cons list example in Listing 15-18 where we used Rc<T> to allow multiple lists to share ownership of another list. Because Rc<T> holds only immutable values, we can‚Äôt change any of the values in the list once we‚Äôve created them. Let‚Äôs add in RefCell<T> for its ability to change the values in the lists. Listing 15-24 shows that by using a RefCell<T> in the Cons definition, we can modify the value stored in all the lists. Filename: src/main.rs #[derive(Debug)]\\nenum List { Cons(Rc<RefCell<i32>>, Rc<List>), Nil,\\n} use crate::List::{Cons, Nil};\\nuse std::cell::RefCell;\\nuse std::rc::Rc; fn main() { let value = Rc::new(RefCell::new(5)); let a = Rc::new(Cons(Rc::clone(&value), Rc::new(Nil))); let b = Cons(Rc::new(RefCell::new(3)), Rc::clone(&a)); let c = Cons(Rc::new(RefCell::new(4)), Rc::clone(&a)); *value.borrow_mut() += 10; println!(\\"a after = {a:?}\\"); println!(\\"b after = {b:?}\\"); println!(\\"c after = {c:?}\\");\\n} Listing 15-24: Using Rc&lt;RefCell&lt;i32&gt;&gt; to create a List that we can mutate We create a value that is an instance of Rc<RefCell<i32>> and store it in a variable named value so that we can access it directly later. Then, we create a List in a with a Cons variant that holds value. We need to clone value so that both a and value have ownership of the inner 5 value rather than transferring ownership from value to a or having a borrow from value. We wrap the list a in an Rc<T> so that when we create lists b and c, they can both refer to a, which is what we did in Listing 15-18. After we‚Äôve created the lists in a, b, and c, we want to add 10 to the value in value. We do this by calling borrow_mut on value, which uses the automatic dereferencing feature we discussed in ‚ÄúWhere‚Äôs the -> Operator?‚Äù in Chapter 5 to dereference the Rc<T> to the inner RefCell<T> value. The borrow_mut method returns a RefMut<T> smart pointer, and we use the dereference operator on it and change the inner value. When we print a, b, and c, we can see that they all have the modified value of 15 rather than 5: $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.63s Running `target/debug/cons-list`\\na after = Cons(RefCell { value: 15 }, Nil)\\nb after = Cons(RefCell { value: 3 }, Cons(RefCell { value: 15 }, Nil))\\nc after = Cons(RefCell { value: 4 }, Cons(RefCell { value: 15 }, Nil)) This technique is pretty neat! By using RefCell<T>, we have an outwardly immutable List value. But we can use the methods on RefCell<T> that provide access to its interior mutability so that we can modify our data when we need to. The runtime checks of the borrowing rules protect us from data races, and it‚Äôs sometimes worth trading a bit of speed for this flexibility in our data structures. Note that RefCell<T> does not work for multithreaded code! Mutex<T> is the thread-safe version of RefCell<T>, and we‚Äôll discuss Mutex<T> in Chapter 16.","breadcrumbs":"Smart Pointers ¬ª RefCell<T> and the Interior Mutability Pattern ¬ª Allowing Multiple Owners of Mutable Data","id":"286","title":"Allowing Multiple Owners of Mutable Data"},"287":{"body":"Rust‚Äôs memory safety guarantees make it difficult, but not impossible, to accidentally create memory that is never cleaned up (known as a memory leak ). Preventing memory leaks entirely is not one of Rust‚Äôs guarantees, meaning memory leaks are memory safe in Rust. We can see that Rust allows memory leaks by using Rc<T> and RefCell<T>: It‚Äôs possible to create references where items refer to each other in a cycle. This creates memory leaks because the reference count of each item in the cycle will never reach 0, and the values will never be dropped.","breadcrumbs":"Smart Pointers ¬ª Reference Cycles Can Leak Memory ¬ª Reference Cycles Can Leak Memory","id":"287","title":"Reference Cycles Can Leak Memory"},"288":{"body":"Let‚Äôs look at how a reference cycle might happen and how to prevent it, starting with the definition of the List enum and a tail method in Listing 15-25. Filename: src/main.rs use crate::List::{Cons, Nil};\\nuse std::cell::RefCell;\\nuse std::rc::Rc; #[derive(Debug)]\\nenum List { Cons(i32, RefCell<Rc<List>>), Nil,\\n} impl List { fn tail(&self) -> Option<&RefCell<Rc<List>>> { match self { Cons(_, item) => Some(item), Nil => None, } }\\n}\\n# # fn main() {} Listing 15-25: A cons list definition that holds a RefCell&lt;T&gt; so that we can modify what a Cons variant is referring to We‚Äôre using another variation of the List definition from Listing 15-5. The second element in the Cons variant is now RefCell<Rc<List>>, meaning that instead of having the ability to modify the i32 value as we did in Listing 15-24, we want to modify the List value a Cons variant is pointing to. We‚Äôre also adding a tail method to make it convenient for us to access the second item if we have a Cons variant. In Listing 15-26, we‚Äôre adding a main function that uses the definitions in Listing 15-25. This code creates a list in a and a list in b that points to the list in a. Then, it modifies the list in a to point to b, creating a reference cycle. There are println! statements along the way to show what the reference counts are at various points in this process. Filename: src/main.rs # use crate::List::{Cons, Nil};\\n# use std::cell::RefCell;\\n# use std::rc::Rc;\\n# # #[derive(Debug)]\\n# enum List {\\n# Cons(i32, RefCell<Rc<List>>),\\n# Nil,\\n# }\\n# # impl List {\\n# fn tail(&self) -> Option<&RefCell<Rc<List>>> {\\n# match self {\\n# Cons(_, item) => Some(item),\\n# Nil => None,\\n# }\\n# }\\n# }\\n# fn main() { let a = Rc::new(Cons(5, RefCell::new(Rc::new(Nil)))); println!(\\"a initial rc count = {}\\", Rc::strong_count(&a)); println!(\\"a next item = {:?}\\", a.tail()); let b = Rc::new(Cons(10, RefCell::new(Rc::clone(&a)))); println!(\\"a rc count after b creation = {}\\", Rc::strong_count(&a)); println!(\\"b initial rc count = {}\\", Rc::strong_count(&b)); println!(\\"b next item = {:?}\\", b.tail()); if let Some(link) = a.tail() { *link.borrow_mut() = Rc::clone(&b); } println!(\\"b rc count after changing a = {}\\", Rc::strong_count(&b)); println!(\\"a rc count after changing a = {}\\", Rc::strong_count(&a)); // Uncomment the next line to see that we have a cycle; // it will overflow the stack. // println!(\\"a next item = {:?}\\", a.tail());\\n} Listing 15-26: Creating a reference cycle of two List values pointing to each other We create an Rc<List> instance holding a List value in the variable a with an initial list of 5, Nil. We then create an Rc<List> instance holding another List value in the variable b that contains the value 10 and points to the list in a. We modify a so that it points to b instead of Nil, creating a cycle. We do that by using the tail method to get a reference to the RefCell<Rc<List>> in a, which we put in the variable link. Then, we use the borrow_mut method on the RefCell<Rc<List>> to change the value inside from an Rc<List> that holds a Nil value to the Rc<List> in b. When we run this code, keeping the last println! commented out for the moment, we‚Äôll get this output: $ cargo run Compiling cons-list v0.1.0 (file:///projects/cons-list) Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.53s Running `target/debug/cons-list`\\na initial rc count = 1\\na next item = Some(RefCell { value: Nil })\\na rc count after b creation = 2\\nb initial rc count = 1\\nb next item = Some(RefCell { value: Cons(5, RefCell { value: Nil }) })\\nb rc count after changing a = 2\\na rc count after changing a = 2 The reference count of the Rc<List> instances in both a and b is 2 after we change the list in a to point to b. At the end of main, Rust drops the variable b, which decreases the reference count of the b Rc<List> instance from 2 to 1. The memory that Rc<List> has on the heap won‚Äôt be dropped at this point because its reference count is 1, not 0. Then, Rust drops a, which decreases the reference count of the a Rc<List> instance from 2 to 1 as well. This instance‚Äôs memory can‚Äôt be dropped either, because the other Rc<List> instance still refers to it. The memory allocated to the list will remain uncollected forever. To visualize this reference cycle, we‚Äôve created the diagram in Figure 15-4. Figure 15-4: A reference cycle of lists a and b pointing to each other If you uncomment the last println! and run the program, Rust will try to print this cycle with a pointing to b pointing to a and so forth until it overflows the stack. Compared to a real-world program, the consequences of creating a reference cycle in this example aren‚Äôt very dire: Right after we create the reference cycle, the program ends. However, if a more complex program allocated lots of memory in a cycle and held onto it for a long time, the program would use more memory than it needed and might overwhelm the system, causing it to run out of available memory. Creating reference cycles is not easily done, but it‚Äôs not impossible either. If you have RefCell<T> values that contain Rc<T> values or similar nested combinations of types with interior mutability and reference counting, you must ensure that you don‚Äôt create cycles; you can‚Äôt rely on Rust to catch them. Creating a reference cycle would be a logic bug in your program that you should use automated tests, code reviews, and other software development practices to minimize. Another solution for avoiding reference cycles is reorganizing your data structures so that some references express ownership and some references don‚Äôt. As a result, you can have cycles made up of some ownership relationships and some non-ownership relationships, and only the ownership relationships affect whether or not a value can be dropped. In Listing 15-25, we always want Cons variants to own their list, so reorganizing the data structure isn‚Äôt possible. Let‚Äôs look at an example using graphs made up of parent nodes and child nodes to see when non-ownership relationships are an appropriate way to prevent reference cycles.","breadcrumbs":"Smart Pointers ¬ª Reference Cycles Can Leak Memory ¬ª Creating a Reference Cycle","id":"288","title":"Creating a Reference Cycle"},"289":{"body":"So far, we‚Äôve demonstrated that calling Rc::clone increases the strong_count of an Rc<T> instance, and an Rc<T> instance is only cleaned up if its strong_count is 0. You can also create a weak reference to the value within an Rc<T> instance by calling Rc::downgrade and passing a reference to the Rc<T>. Strong references are how you can share ownership of an Rc<T> instance. Weak references don‚Äôt express an ownership relationship, and their count doesn‚Äôt affect when an Rc<T> instance is cleaned up. They won‚Äôt cause a reference cycle, because any cycle involving some weak references will be broken once the strong reference count of values involved is 0. When you call Rc::downgrade, you get a smart pointer of type Weak<T>. Instead of increasing the strong_count in the Rc<T> instance by 1, calling Rc::downgrade increases the weak_count by 1. The Rc<T> type uses weak_count to keep track of how many Weak<T> references exist, similar to strong_count. The difference is the weak_count doesn‚Äôt need to be 0 for the Rc<T> instance to be cleaned up. Because the value that Weak<T> references might have been dropped, to do anything with the value that a Weak<T> is pointing to you must make sure the value still exists. Do this by calling the upgrade method on a Weak<T> instance, which will return an Option<Rc<T>>. You‚Äôll get a result of Some if the Rc<T> value has not been dropped yet and a result of None if the Rc<T> value has been dropped. Because upgrade returns an Option<Rc<T>>, Rust will ensure that the Some case and the None case are handled, and there won‚Äôt be an invalid pointer. As an example, rather than using a list whose items know only about the next item, we‚Äôll create a tree whose items know about their child items and their parent items. Creating a Tree Data Structure To start, we‚Äôll build a tree with nodes that know about their child nodes. We‚Äôll create a struct named Node that holds its own i32 value as well as references to its child Node values: Filename: src/main.rs use std::cell::RefCell;\\nuse std::rc::Rc; #[derive(Debug)]\\nstruct Node { value: i32, children: RefCell<Vec<Rc<Node>>>,\\n}\\n# # fn main() {\\n# let leaf = Rc::new(Node {\\n# value: 3,\\n# children: RefCell::new(vec![]),\\n# });\\n# # let branch = Rc::new(Node {\\n# value: 5,\\n# children: RefCell::new(vec![Rc::clone(&leaf)]),\\n# });\\n# } We want a Node to own its children, and we want to share that ownership with variables so that we can access each Node in the tree directly. To do this, we define the Vec<T> items to be values of type Rc<Node>. We also want to modify which nodes are children of another node, so we have a RefCell<T> in children around the Vec<Rc<Node>>. Next, we‚Äôll use our struct definition and create one Node instance named leaf with the value 3 and no children, and another instance named branch with the value 5 and leaf as one of its children, as shown in Listing 15-27. Filename: src/main.rs # use std::cell::RefCell;\\n# use std::rc::Rc;\\n# # #[derive(Debug)]\\n# struct Node {\\n# value: i32,\\n# children: RefCell<Vec<Rc<Node>>>,\\n# }\\n# fn main() { let leaf = Rc::new(Node { value: 3, children: RefCell::new(vec![]), }); let branch = Rc::new(Node { value: 5, children: RefCell::new(vec![Rc::clone(&leaf)]), });\\n} Listing 15-27: Creating a leaf node with no children and a branch node with leaf as one of its children We clone the Rc<Node> in leaf and store that in branch, meaning the Node in leaf now has two owners: leaf and branch. We can get from branch to leaf through branch.children, but there‚Äôs no way to get from leaf to branch. The reason is that leaf has no reference to branch and doesn‚Äôt know they‚Äôre related. We want leaf to know that branch is its parent. We‚Äôll do that next. Adding a Reference from a Child to Its Parent To make the child node aware of its parent, we need to add a parent field to our Node struct definition. The trouble is in deciding what the type of parent should be. We know it can‚Äôt contain an Rc<T>, because that would create a reference cycle with leaf.parent pointing to branch and branch.children pointing to leaf, which would cause their strong_count values to never be 0. Thinking about the relationships another way, a parent node should own its children: If a parent node is dropped, its child nodes should be dropped as well. However, a child should not own its parent: If we drop a child node, the parent should still exist. This is a case for weak references! So, instead of Rc<T>, we‚Äôll make the type of parent use Weak<T>, specifically a RefCell<Weak<Node>>. Now our Node struct definition looks like this: Filename: src/main.rs use std::cell::RefCell;\\nuse std::rc::{Rc, Weak}; #[derive(Debug)]\\nstruct Node { value: i32, parent: RefCell<Weak<Node>>, children: RefCell<Vec<Rc<Node>>>,\\n}\\n# # fn main() {\\n# let leaf = Rc::new(Node {\\n# value: 3,\\n# parent: RefCell::new(Weak::new()),\\n# children: RefCell::new(vec![]),\\n# });\\n# # println!(\\"leaf parent = {:?}\\", leaf.parent.borrow().upgrade());\\n# # let branch = Rc::new(Node {\\n# value: 5,\\n# parent: RefCell::new(Weak::new()),\\n# children: RefCell::new(vec![Rc::clone(&leaf)]),\\n# });\\n# # *leaf.parent.borrow_mut() = Rc::downgrade(&branch);\\n# # println!(\\"leaf parent = {:?}\\", leaf.parent.borrow().upgrade());\\n# } A node will be able to refer to its parent node but doesn‚Äôt own its parent. In Listing 15-28, we update main to use this new definition so that the leaf node will have a way to refer to its parent, branch. Filename: src/main.rs # use std::cell::RefCell;\\n# use std::rc::{Rc, Weak};\\n# # #[derive(Debug)]\\n# struct Node {\\n# value: i32,\\n# parent: RefCell<Weak<Node>>,\\n# children: RefCell<Vec<Rc<Node>>>,\\n# }\\n# fn main() { let leaf = Rc::new(Node { value: 3, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![]), }); println!(\\"leaf parent = {:?}\\", leaf.parent.borrow().upgrade()); let branch = Rc::new(Node { value: 5, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![Rc::clone(&leaf)]), }); *leaf.parent.borrow_mut() = Rc::downgrade(&branch); println!(\\"leaf parent = {:?}\\", leaf.parent.borrow().upgrade());\\n} Listing 15-28: A leaf node with a weak reference to its parent node, branch Creating the leaf node looks similar to Listing 15-27 with the exception of the parent field: leaf starts out without a parent, so we create a new, empty Weak<Node> reference instance. At this point, when we try to get a reference to the parent of leaf by using the upgrade method, we get a None value. We see this in the output from the first println! statement: leaf parent = None When we create the branch node, it will also have a new Weak<Node> reference in the parent field because branch doesn‚Äôt have a parent node. We still have leaf as one of the children of branch. Once we have the Node instance in branch, we can modify leaf to give it a Weak<Node> reference to its parent. We use the borrow_mut method on the RefCell<Weak<Node>> in the parent field of leaf, and then we use the Rc::downgrade function to create a Weak<Node> reference to branch from the Rc<Node> in branch. When we print the parent of leaf again, this time we‚Äôll get a Some variant holding branch: Now leaf can access its parent! When we print leaf, we also avoid the cycle that eventually ended in a stack overflow like we had in Listing 15-26; the Weak<Node> references are printed as (Weak): leaf parent = Some(Node { value: 5, parent: RefCell { value: (Weak) },\\nchildren: RefCell { value: [Node { value: 3, parent: RefCell { value: (Weak) },\\nchildren: RefCell { value: [] } }] } }) The lack of infinite output indicates that this code didn‚Äôt create a reference cycle. We can also tell this by looking at the values we get from calling Rc::strong_count and Rc::weak_count. Visualizing Changes to strong_count and weak_count Let‚Äôs look at how the strong_count and weak_count values of the Rc<Node> instances change by creating a new inner scope and moving the creation of branch into that scope. By doing so, we can see what happens when branch is created and then dropped when it goes out of scope. The modifications are shown in Listing 15-29. Filename: src/main.rs # use std::cell::RefCell;\\n# use std::rc::{Rc, Weak};\\n# # #[derive(Debug)]\\n# struct Node {\\n# value: i32,\\n# parent: RefCell<Weak<Node>>,\\n# children: RefCell<Vec<Rc<Node>>>,\\n# }\\n# fn main() { let leaf = Rc::new(Node { value: 3, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![]), }); println!( \\"leaf strong = {}, weak = {}\\", Rc::strong_count(&leaf), Rc::weak_count(&leaf), ); { let branch = Rc::new(Node { value: 5, parent: RefCell::new(Weak::new()), children: RefCell::new(vec![Rc::clone(&leaf)]), }); *leaf.parent.borrow_mut() = Rc::downgrade(&branch); println!( \\"branch strong = {}, weak = {}\\", Rc::strong_count(&branch), Rc::weak_count(&branch), ); println!( \\"leaf strong = {}, weak = {}\\", Rc::strong_count(&leaf), Rc::weak_count(&leaf), ); } println!(\\"leaf parent = {:?}\\", leaf.parent.borrow().upgrade()); println!( \\"leaf strong = {}, weak = {}\\", Rc::strong_count(&leaf), Rc::weak_count(&leaf), );\\n} Listing 15-29: Creating branch in an inner scope and examining strong and weak reference counts After leaf is created, its Rc<Node> has a strong count of 1 and a weak count of 0. In the inner scope, we create branch and associate it with leaf, at which point when we print the counts, the Rc<Node> in branch will have a strong count of 1 and a weak count of 1 (for leaf.parent pointing to branch with a Weak<Node>). When we print the counts in leaf, we‚Äôll see it will have a strong count of 2 because branch now has a clone of the Rc<Node> of leaf stored in branch.children but will still have a weak count of 0. When the inner scope ends, branch goes out of scope and the strong count of the Rc<Node> decreases to 0, so its Node is dropped. The weak count of 1 from leaf.parent has no bearing on whether or not Node is dropped, so we don‚Äôt get any memory leaks! If we try to access the parent of leaf after the end of the scope, we‚Äôll get None again. At the end of the program, the Rc<Node> in leaf has a strong count of 1 and a weak count of 0 because the variable leaf is now the only reference to the Rc<Node> again. All of the logic that manages the counts and value dropping is built into Rc<T> and Weak<T> and their implementations of the Drop trait. By specifying that the relationship from a child to its parent should be a Weak<T> reference in the definition of Node, you‚Äôre able to have parent nodes point to child nodes and vice versa without creating a reference cycle and memory leaks.","breadcrumbs":"Smart Pointers ¬ª Reference Cycles Can Leak Memory ¬ª Preventing Reference Cycles Using Weak<T>","id":"289","title":"Preventing Reference Cycles Using Weak<T>"},"29":{"body":"Now let‚Äôs look at what‚Äôs different when we build and run the ‚ÄúHello, world!‚Äù program with Cargo! From your hello_cargo directory, build your project by entering the following command: $ cargo build Compiling hello_cargo v0.1.0 (file:///projects/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 2.85 secs This command creates an executable file in target/debug/hello_cargo (or target\\\\debug\\\\hello_cargo.exe on Windows) rather than in your current directory. Because the default build is a debug build, Cargo puts the binary in a directory named debug . You can run the executable with this command: $ ./target/debug/hello_cargo # or .\\\\target\\\\debug\\\\hello_cargo.exe on Windows\\nHello, world! If all goes well, Hello, world! should print to the terminal. Running cargo build for the first time also causes Cargo to create a new file at the top level: Cargo.lock . This file keeps track of the exact versions of dependencies in your project. This project doesn‚Äôt have dependencies, so the file is a bit sparse. You won‚Äôt ever need to change this file manually; Cargo manages its contents for you. We just built a project with cargo build and ran it with ./target/debug/hello_cargo, but we can also use cargo run to compile the code and then run the resultant executable all in one command: $ cargo run Finished dev [unoptimized + debuginfo] target(s) in 0.0 secs Running `target/debug/hello_cargo`\\nHello, world! Using cargo run is more convenient than having to remember to run cargo build and then use the whole path to the binary, so most developers use cargo run. Notice that this time we didn‚Äôt see output indicating that Cargo was compiling hello_cargo. Cargo figured out that the files hadn‚Äôt changed, so it didn‚Äôt rebuild but just ran the binary. If you had modified your source code, Cargo would have rebuilt the project before running it, and you would have seen this output: $ cargo run Compiling hello_cargo v0.1.0 (file:///projects/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.33 secs Running `target/debug/hello_cargo`\\nHello, world! Cargo also provides a command called cargo check. This command quickly checks your code to make sure it compiles but doesn‚Äôt produce an executable: $ cargo check Checking hello_cargo v0.1.0 (file:///projects/hello_cargo) Finished dev [unoptimized + debuginfo] target(s) in 0.32 secs Why would you not want an executable? Often, cargo check is much faster than cargo build because it skips the step of producing an executable. If you‚Äôre continually checking your work while writing the code, using cargo check will speed up the process of letting you know if your project is still compiling! As such, many Rustaceans run cargo check periodically as they write their program to make sure it compiles. Then, they run cargo build when they‚Äôre ready to use the executable. Let‚Äôs recap what we‚Äôve learned so far about Cargo: We can create a project using cargo new. We can build a project using cargo build. We can build and run a project in one step using cargo run. We can build a project without producing a binary to check for errors using cargo check. Instead of saving the result of the build in the same directory as our code, Cargo stores it in the target/debug directory. An additional advantage of using Cargo is that the commands are the same no matter which operating system you‚Äôre working on. So, at this point, we‚Äôll no longer provide specific instructions for Linux and macOS versus Windows.","breadcrumbs":"Getting Started ¬ª Hello, Cargo! ¬ª Building and Running a Cargo Project","id":"29","title":"Building and Running a Cargo Project"},"290":{"body":"This chapter covered how to use smart pointers to make different guarantees and trade-offs from those Rust makes by default with regular references. The Box<T> type has a known size and points to data allocated on the heap. The Rc<T> type keeps track of the number of references to data on the heap so that the data can have multiple owners. The RefCell<T> type with its interior mutability gives us a type that we can use when we need an immutable type but need to change an inner value of that type; it also enforces the borrowing rules at runtime instead of at compile time. Also discussed were the Deref and Drop traits, which enable a lot of the functionality of smart pointers. We explored reference cycles that can cause memory leaks and how to prevent them using Weak<T>. If this chapter has piqued your interest and you want to implement your own smart pointers, check out ‚ÄúThe Rustonomicon‚Äù for more useful information. Next, we‚Äôll talk about concurrency in Rust. You‚Äôll even learn about a few new smart pointers.","breadcrumbs":"Smart Pointers ¬ª Reference Cycles Can Leak Memory ¬ª Summary","id":"290","title":"Summary"},"291":{"body":"Handling concurrent programming safely and efficiently is another of Rust‚Äôs major goals. Concurrent programming , in which different parts of a program execute independently, and parallel programming , in which different parts of a program execute at the same time, are becoming increasingly important as more computers take advantage of their multiple processors. Historically, programming in these contexts has been difficult and error-prone. Rust hopes to change that. Initially, the Rust team thought that ensuring memory safety and preventing concurrency problems were two separate challenges to be solved with different methods. Over time, the team discovered that the ownership and type systems are a powerful set of tools to help manage memory safety and concurrency problems! By leveraging ownership and type checking, many concurrency errors are compile-time errors in Rust rather than runtime errors. Therefore, rather than making you spend lots of time trying to reproduce the exact circumstances under which a runtime concurrency bug occurs, incorrect code will refuse to compile and present an error explaining the problem. As a result, you can fix your code while you‚Äôre working on it rather than potentially after it has been shipped to production. We‚Äôve nicknamed this aspect of Rust fearless concurrency . Fearless concurrency allows you to write code that is free of subtle bugs and is easy to refactor without introducing new bugs. Note: For simplicity‚Äôs sake, we‚Äôll refer to many of the problems as concurrent rather than being more precise by saying concurrent and/or parallel . For this chapter, please mentally substitute concurrent and/or parallel whenever we use concurrent . In the next chapter, where the distinction matters more, we‚Äôll be more specific. Many languages are dogmatic about the solutions they offer for handling concurrent problems. For example, Erlang has elegant functionality for message-passing concurrency but has only obscure ways to share state between threads. Supporting only a subset of possible solutions is a reasonable strategy for higher-level languages because a higher-level language promises benefits from giving up some control to gain abstractions. However, lower-level languages are expected to provide the solution with the best performance in any given situation and have fewer abstractions over the hardware. Therefore, Rust offers a variety of tools for modeling problems in whatever way is appropriate for your situation and requirements. Here are the topics we‚Äôll cover in this chapter: How to create threads to run multiple pieces of code at the same time Message-passing concurrency, where channels send messages between threads Shared-state concurrency, where multiple threads have access to some piece of data The Sync and Send traits, which extend Rust‚Äôs concurrency guarantees to user-defined types as well as types provided by the standard library","breadcrumbs":"Fearless Concurrency ¬ª Fearless Concurrency","id":"291","title":"Fearless Concurrency"},"292":{"body":"In most current operating systems, an executed program‚Äôs code is run in a process , and the operating system will manage multiple processes at once. Within a program, you can also have independent parts that run simultaneously. The features that run these independent parts are called threads . For example, a web server could have multiple threads so that it can respond to more than one request at the same time. Splitting the computation in your program into multiple threads to run multiple tasks at the same time can improve performance, but it also adds complexity. Because threads can run simultaneously, there‚Äôs no inherent guarantee about the order in which parts of your code on different threads will run. This can lead to problems, such as: Race conditions, in which threads are accessing data or resources in an inconsistent order Deadlocks, in which two threads are waiting for each other, preventing both threads from continuing Bugs that only happen in certain situations and are hard to reproduce and fix reliably Rust attempts to mitigate the negative effects of using threads, but programming in a multithreaded context still takes careful thought and requires a code structure that is different from that in programs running in a single thread. Programming languages implement threads in a few different ways, and many operating systems provide an API the programming language can call for creating new threads. The Rust standard library uses a 1:1 model of thread implementation, whereby a program uses one operating system thread per one language thread. There are crates that implement other models of threading that make different trade-offs to the 1:1 model. (Rust‚Äôs async system, which we will see in the next chapter, provides another approach to concurrency as well.)","breadcrumbs":"Fearless Concurrency ¬ª Using Threads to Run Code Simultaneously ¬ª Using Threads to Run Code Simultaneously","id":"292","title":"Using Threads to Run Code Simultaneously"},"293":{"body":"To create a new thread, we call the thread::spawn function and pass it a closure (we talked about closures in Chapter 13) containing the code we want to run in the new thread. The example in Listing 16-1 prints some text from a main thread and other text from a new thread. Filename: src/main.rs use std::thread;\\nuse std::time::Duration; fn main() { thread::spawn(|| { for i in 1..10 { println!(\\"hi number {i} from the spawned thread!\\"); thread::sleep(Duration::from_millis(1)); } }); for i in 1..5 { println!(\\"hi number {i} from the main thread!\\"); thread::sleep(Duration::from_millis(1)); }\\n} Listing 16-1: Creating a new thread to print one thing while the main thread prints something else Note that when the main thread of a Rust program completes, all spawned threads are shut down, whether or not they have finished running. The output from this program might be a little different every time, but it will look similar to the following: hi number 1 from the main thread!\\nhi number 1 from the spawned thread!\\nhi number 2 from the main thread!\\nhi number 2 from the spawned thread!\\nhi number 3 from the main thread!\\nhi number 3 from the spawned thread!\\nhi number 4 from the main thread!\\nhi number 4 from the spawned thread!\\nhi number 5 from the spawned thread! The calls to thread::sleep force a thread to stop its execution for a short duration, allowing a different thread to run. The threads will probably take turns, but that isn‚Äôt guaranteed: It depends on how your operating system schedules the threads. In this run, the main thread printed first, even though the print statement from the spawned thread appears first in the code. And even though we told the spawned thread to print until i is 9, it only got to 5 before the main thread shut down. If you run this code and only see output from the main thread, or don‚Äôt see any overlap, try increasing the numbers in the ranges to create more opportunities for the operating system to switch between the threads.","breadcrumbs":"Fearless Concurrency ¬ª Using Threads to Run Code Simultaneously ¬ª Creating a New Thread with spawn","id":"293","title":"Creating a New Thread with spawn"},"294":{"body":"The code in Listing 16-1 not only stops the spawned thread prematurely most of the time due to the main thread ending, but because there is no guarantee on the order in which threads run, we also can‚Äôt guarantee that the spawned thread will get to run at all! We can fix the problem of the spawned thread not running or of it ending prematurely by saving the return value of thread::spawn in a variable. The return type of thread::spawn is JoinHandle<T>. A JoinHandle<T> is an owned value that, when we call the join method on it, will wait for its thread to finish. Listing 16-2 shows how to use the JoinHandle<T> of the thread we created in Listing 16-1 and how to call join to make sure the spawned thread finishes before main exits. Filename: src/main.rs use std::thread;\\nuse std::time::Duration; fn main() { let handle = thread::spawn(|| { for i in 1..10 { println!(\\"hi number {i} from the spawned thread!\\"); thread::sleep(Duration::from_millis(1)); } }); for i in 1..5 { println!(\\"hi number {i} from the main thread!\\"); thread::sleep(Duration::from_millis(1)); } handle.join().unwrap();\\n} Listing 16-2: Saving a JoinHandle&lt;T&gt; from thread::spawn to guarantee the thread is run to completion Calling join on the handle blocks the thread currently running until the thread represented by the handle terminates. Blocking a thread means that thread is prevented from performing work or exiting. Because we‚Äôve put the call to join after the main thread‚Äôs for loop, running Listing 16-2 should produce output similar to this: hi number 1 from the main thread!\\nhi number 2 from the main thread!\\nhi number 1 from the spawned thread!\\nhi number 3 from the main thread!\\nhi number 2 from the spawned thread!\\nhi number 4 from the main thread!\\nhi number 3 from the spawned thread!\\nhi number 4 from the spawned thread!\\nhi number 5 from the spawned thread!\\nhi number 6 from the spawned thread!\\nhi number 7 from the spawned thread!\\nhi number 8 from the spawned thread!\\nhi number 9 from the spawned thread! The two threads continue alternating, but the main thread waits because of the call to handle.join() and does not end until the spawned thread is finished. But let‚Äôs see what happens when we instead move handle.join() before the for loop in main, like this: Filename: src/main.rs use std::thread;\\nuse std::time::Duration; fn main() { let handle = thread::spawn(|| { for i in 1..10 { println!(\\"hi number {i} from the spawned thread!\\"); thread::sleep(Duration::from_millis(1)); } }); handle.join().unwrap(); for i in 1..5 { println!(\\"hi number {i} from the main thread!\\"); thread::sleep(Duration::from_millis(1)); }\\n} The main thread will wait for the spawned thread to finish and then run its for loop, so the output won‚Äôt be interleaved anymore, as shown here: hi number 1 from the spawned thread!\\nhi number 2 from the spawned thread!\\nhi number 3 from the spawned thread!\\nhi number 4 from the spawned thread!\\nhi number 5 from the spawned thread!\\nhi number 6 from the spawned thread!\\nhi number 7 from the spawned thread!\\nhi number 8 from the spawned thread!\\nhi number 9 from the spawned thread!\\nhi number 1 from the main thread!\\nhi number 2 from the main thread!\\nhi number 3 from the main thread!\\nhi number 4 from the main thread! Small details, such as where join is called, can affect whether or not your threads run at the same time.","breadcrumbs":"Fearless Concurrency ¬ª Using Threads to Run Code Simultaneously ¬ª Waiting for All Threads to Finish","id":"294","title":"Waiting for All Threads to Finish"},"295":{"body":"We‚Äôll often use the move keyword with closures passed to thread::spawn because the closure will then take ownership of the values it uses from the environment, thus transferring ownership of those values from one thread to another. In ‚ÄúCapturing References or Moving Ownership‚Äù in Chapter 13, we discussed move in the context of closures. Now we‚Äôll concentrate more on the interaction between move and thread::spawn. Notice in Listing 16-1 that the closure we pass to thread::spawn takes no arguments: We‚Äôre not using any data from the main thread in the spawned thread‚Äôs code. To use data from the main thread in the spawned thread, the spawned thread‚Äôs closure must capture the values it needs. Listing 16-3 shows an attempt to create a vector in the main thread and use it in the spawned thread. However, this won‚Äôt work yet, as you‚Äôll see in a moment. Filename: src/main.rs use std::thread; fn main() { let v = vec![1, 2, 3]; let handle = thread::spawn(|| { println!(\\"Here\'s a vector: {v:?}\\"); }); handle.join().unwrap();\\n} Listing 16-3: Attempting to use a vector created by the main thread in another thread The closure uses v, so it will capture v and make it part of the closure‚Äôs environment. Because thread::spawn runs this closure in a new thread, we should be able to access v inside that new thread. But when we compile this example, we get the following error: $ cargo run Compiling threads v0.1.0 (file:///projects/threads)\\nerror[E0373]: closure may outlive the current function, but it borrows `v`, which is owned by the current function --> src/main.rs:6:32 |\\n6 | let handle = thread::spawn(|| { | ^^ may outlive borrowed value `v`\\n7 | println!(\\"Here\'s a vector: {v:?}\\"); | - `v` is borrowed here |\\nnote: function requires argument type to outlive `\'static` --> src/main.rs:6:18 |\\n6 | let handle = thread::spawn(|| { | __________________^\\n7 | | println!(\\"Here\'s a vector: {v:?}\\");\\n8 | | }); | |______^\\nhelp: to force the closure to take ownership of `v` (and any other referenced variables), use the `move` keyword |\\n6 | let handle = thread::spawn(move || { | ++++ For more information about this error, try `rustc --explain E0373`.\\nerror: could not compile `threads` (bin \\"threads\\") due to 1 previous error Rust infers how to capture v, and because println! only needs a reference to v, the closure tries to borrow v. However, there‚Äôs a problem: Rust can‚Äôt tell how long the spawned thread will run, so it doesn‚Äôt know whether the reference to v will always be valid. Listing 16-4 provides a scenario that‚Äôs more likely to have a reference to v that won‚Äôt be valid. Filename: src/main.rs use std::thread; fn main() { let v = vec![1, 2, 3]; let handle = thread::spawn(|| { println!(\\"Here\'s a vector: {v:?}\\"); }); drop(v); // oh no! handle.join().unwrap();\\n} Listing 16-4: A thread with a closure that attempts to capture a reference to v from a main thread that drops v If Rust allowed us to run this code, there‚Äôs a possibility that the spawned thread would be immediately put in the background without running at all. The spawned thread has a reference to v inside, but the main thread immediately drops v, using the drop function we discussed in Chapter 15. Then, when the spawned thread starts to execute, v is no longer valid, so a reference to it is also invalid. Oh no! To fix the compiler error in Listing 16-3, we can use the error message‚Äôs advice: help: to force the closure to take ownership of `v` (and any other referenced variables), use the `move` keyword |\\n6 | let handle = thread::spawn(move || { | ++++ By adding the move keyword before the closure, we force the closure to take ownership of the values it‚Äôs using rather than allowing Rust to infer that it should borrow the values. The modification to Listing 16-3 shown in Listing 16-5 will compile and run as we intend. Filename: src/main.rs use std::thread; fn main() { let v = vec![1, 2, 3]; let handle = thread::spawn(move || { println!(\\"Here\'s a vector: {v:?}\\"); }); handle.join().unwrap();\\n} Listing 16-5: Using the move keyword to force a closure to take ownership of the values it uses We might be tempted to try the same thing to fix the code in Listing 16-4 where the main thread called drop by using a move closure. However, this fix will not work because what Listing 16-4 is trying to do is disallowed for a different reason. If we added move to the closure, we would move v into the closure‚Äôs environment, and we could no longer call drop on it in the main thread. We would get this compiler error instead: $ cargo run Compiling threads v0.1.0 (file:///projects/threads)\\nerror[E0382]: use of moved value: `v` --> src/main.rs:10:10 |\\n4 | let v = vec![1, 2, 3]; | - move occurs because `v` has type `Vec<i32>`, which does not implement the `Copy` trait\\n5 |\\n6 | let handle = thread::spawn(move || { | ------- value moved into closure here\\n7 | println!(\\"Here\'s a vector: {v:?}\\"); | - variable moved due to use in closure\\n...\\n10 | drop(v); // oh no! | ^ value used here after move For more information about this error, try `rustc --explain E0382`.\\nerror: could not compile `threads` (bin \\"threads\\") due to 1 previous error Rust‚Äôs ownership rules have saved us again! We got an error from the code in Listing 16-3 because Rust was being conservative and only borrowing v for the thread, which meant the main thread could theoretically invalidate the spawned thread‚Äôs reference. By telling Rust to move ownership of v to the spawned thread, we‚Äôre guaranteeing to Rust that the main thread won‚Äôt use v anymore. If we change Listing 16-4 in the same way, we‚Äôre then violating the ownership rules when we try to use v in the main thread. The move keyword overrides Rust‚Äôs conservative default of borrowing; it doesn‚Äôt let us violate the ownership rules. Now that we‚Äôve covered what threads are and the methods supplied by the thread API, let‚Äôs look at some situations in which we can use threads.","breadcrumbs":"Fearless Concurrency ¬ª Using Threads to Run Code Simultaneously ¬ª Using move Closures with Threads","id":"295","title":"Using move Closures with Threads"},"296":{"body":"One increasingly popular approach to ensuring safe concurrency is message passing, where threads or actors communicate by sending each other messages containing data. Here‚Äôs the idea in a slogan from the Go language documentation : ‚ÄúDo not communicate by sharing memory; instead, share memory by communicating.‚Äù To accomplish message-sending concurrency, Rust‚Äôs standard library provides an implementation of channels. A channel is a general programming concept by which data is sent from one thread to another. You can imagine a channel in programming as being like a directional channel of water, such as a stream or a river. If you put something like a rubber duck into a river, it will travel downstream to the end of the waterway. A channel has two halves: a transmitter and a receiver. The transmitter half is the upstream location where you put the rubber duck into the river, and the receiver half is where the rubber duck ends up downstream. One part of your code calls methods on the transmitter with the data you want to send, and another part checks the receiving end for arriving messages. A channel is said to be closed if either the transmitter or receiver half is dropped. Here, we‚Äôll work up to a program that has one thread to generate values and send them down a channel, and another thread that will receive the values and print them out. We‚Äôll be sending simple values between threads using a channel to illustrate the feature. Once you‚Äôre familiar with the technique, you could use channels for any threads that need to communicate with each other, such as a chat system or a system where many threads perform parts of a calculation and send the parts to one thread that aggregates the results. First, in Listing 16-6, we‚Äôll create a channel but not do anything with it. Note that this won‚Äôt compile yet because Rust can‚Äôt tell what type of values we want to send over the channel. Filename: src/main.rs use std::sync::mpsc; fn main() { let (tx, rx) = mpsc::channel();\\n} Listing 16-6: Creating a channel and assigning the two halves to tx and rx We create a new channel using the mpsc::channel function; mpsc stands for multiple producer, single consumer . In short, the way Rust‚Äôs standard library implements channels means a channel can have multiple sending ends that produce values but only one receiving end that consumes those values. Imagine multiple streams flowing together into one big river: Everything sent down any of the streams will end up in one river at the end. We‚Äôll start with a single producer for now, but we‚Äôll add multiple producers when we get this example working. The mpsc::channel function returns a tuple, the first element of which is the sending end‚Äîthe transmitter‚Äîand the second element of which is the receiving end‚Äîthe receiver. The abbreviations tx and rx are traditionally used in many fields for transmitter and receiver , respectively, so we name our variables as such to indicate each end. We‚Äôre using a let statement with a pattern that destructures the tuples; we‚Äôll discuss the use of patterns in let statements and destructuring in Chapter 19. For now, know that using a let statement in this way is a convenient approach to extract the pieces of the tuple returned by mpsc::channel. Let‚Äôs move the transmitting end into a spawned thread and have it send one string so that the spawned thread is communicating with the main thread, as shown in Listing 16-7. This is like putting a rubber duck in the river upstream or sending a chat message from one thread to another. Filename: src/main.rs use std::sync::mpsc;\\nuse std::thread; fn main() { let (tx, rx) = mpsc::channel(); thread::spawn(move || { let val = String::from(\\"hi\\"); tx.send(val).unwrap(); });\\n} Listing 16-7: Moving tx to a spawned thread and sending \\"hi\\" Again, we‚Äôre using thread::spawn to create a new thread and then using move to move tx into the closure so that the spawned thread owns tx. The spawned thread needs to own the transmitter to be able to send messages through the channel. The transmitter has a send method that takes the value we want to send. The send method returns a Result<T, E> type, so if the receiver has already been dropped and there‚Äôs nowhere to send a value, the send operation will return an error. In this example, we‚Äôre calling unwrap to panic in case of an error. But in a real application, we would handle it properly: Return to Chapter 9 to review strategies for proper error handling. In Listing 16-8, we‚Äôll get the value from the receiver in the main thread. This is like retrieving the rubber duck from the water at the end of the river or receiving a chat message. Filename: src/main.rs use std::sync::mpsc;\\nuse std::thread; fn main() { let (tx, rx) = mpsc::channel(); thread::spawn(move || { let val = String::from(\\"hi\\"); tx.send(val).unwrap(); }); let received = rx.recv().unwrap(); println!(\\"Got: {received}\\");\\n} Listing 16-8: Receiving the value \\"hi\\" in the main thread and printing it The receiver has two useful methods: recv and try_recv. We‚Äôre using recv, short for receive , which will block the main thread‚Äôs execution and wait until a value is sent down the channel. Once a value is sent, recv will return it in a Result<T, E>. When the transmitter closes, recv will return an error to signal that no more values will be coming. The try_recv method doesn‚Äôt block, but will instead return a Result<T, E> immediately: an Ok value holding a message if one is available and an Err value if there aren‚Äôt any messages this time. Using try_recv is useful if this thread has other work to do while waiting for messages: We could write a loop that calls try_recv every so often, handles a message if one is available, and otherwise does other work for a little while until checking again. We‚Äôve used recv in this example for simplicity; we don‚Äôt have any other work for the main thread to do other than wait for messages, so blocking the main thread is appropriate. When we run the code in Listing 16-8, we‚Äôll see the value printed from the main thread: Got: hi Perfect!","breadcrumbs":"Fearless Concurrency ¬ª Transfer Data Between Threads with Message Passing ¬ª Transfer Data Between Threads with Message Passing","id":"296","title":"Transfer Data Between Threads with Message Passing"},"297":{"body":"The ownership rules play a vital role in message sending because they help you write safe, concurrent code. Preventing errors in concurrent programming is the advantage of thinking about ownership throughout your Rust programs. Let‚Äôs do an experiment to show how channels and ownership work together to prevent problems: We‚Äôll try to use a val value in the spawned thread after we‚Äôve sent it down the channel. Try compiling the code in Listing 16-9 to see why this code isn‚Äôt allowed. Filename: src/main.rs use std::sync::mpsc;\\nuse std::thread; fn main() { let (tx, rx) = mpsc::channel(); thread::spawn(move || { let val = String::from(\\"hi\\"); tx.send(val).unwrap(); println!(\\"val is {val}\\"); }); let received = rx.recv().unwrap(); println!(\\"Got: {received}\\");\\n} Listing 16-9: Attempting to use val after we‚Äôve sent it down the channel Here, we try to print val after we‚Äôve sent it down the channel via tx.send. Allowing this would be a bad idea: Once the value has been sent to another thread, that thread could modify or drop it before we try to use the value again. Potentially, the other thread‚Äôs modifications could cause errors or unexpected results due to inconsistent or nonexistent data. However, Rust gives us an error if we try to compile the code in Listing 16-9: $ cargo run Compiling message-passing v0.1.0 (file:///projects/message-passing)\\nerror[E0382]: borrow of moved value: `val` --> src/main.rs:10:26 |\\n8 | let val = String::from(\\"hi\\"); | --- move occurs because `val` has type `String`, which does not implement the `Copy` trait\\n9 | tx.send(val).unwrap(); | --- value moved here\\n10 | println!(\\"val is {val}\\"); | ^^^^^ value borrowed here after move | = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) For more information about this error, try `rustc --explain E0382`.\\nerror: could not compile `message-passing` (bin \\"message-passing\\") due to 1 previous error Our concurrency mistake has caused a compile-time error. The send function takes ownership of its parameter, and when the value is moved the receiver takes ownership of it. This stops us from accidentally using the value again after sending it; the ownership system checks that everything is okay.","breadcrumbs":"Fearless Concurrency ¬ª Transfer Data Between Threads with Message Passing ¬ª Transferring Ownership Through Channels","id":"297","title":"Transferring Ownership Through Channels"},"298":{"body":"The code in Listing 16-8 compiled and ran, but it didn‚Äôt clearly show us that two separate threads were talking to each other over the channel. In Listing 16-10, we‚Äôve made some modifications that will prove the code in Listing 16-8 is running concurrently: The spawned thread will now send multiple messages and pause for a second between each message. Filename: src/main.rs use std::sync::mpsc;\\nuse std::thread;\\nuse std::time::Duration; fn main() { let (tx, rx) = mpsc::channel(); thread::spawn(move || { let vals = vec![ String::from(\\"hi\\"), String::from(\\"from\\"), String::from(\\"the\\"), String::from(\\"thread\\"), ]; for val in vals { tx.send(val).unwrap(); thread::sleep(Duration::from_secs(1)); } }); for received in rx { println!(\\"Got: {received}\\"); }\\n} Listing 16-10: Sending multiple messages and pausing between each one This time, the spawned thread has a vector of strings that we want to send to the main thread. We iterate over them, sending each individually, and pause between each by calling the thread::sleep function with a Duration value of one second. In the main thread, we‚Äôre not calling the recv function explicitly anymore: Instead, we‚Äôre treating rx as an iterator. For each value received, we‚Äôre printing it. When the channel is closed, iteration will end. When running the code in Listing 16-10, you should see the following output with a one-second pause in between each line: Got: hi\\nGot: from\\nGot: the\\nGot: thread Because we don‚Äôt have any code that pauses or delays in the for loop in the main thread, we can tell that the main thread is waiting to receive values from the spawned thread.","breadcrumbs":"Fearless Concurrency ¬ª Transfer Data Between Threads with Message Passing ¬ª Sending Multiple Values","id":"298","title":"Sending Multiple Values"},"299":{"body":"Earlier we mentioned that mpsc was an acronym for multiple producer, single consumer . Let‚Äôs put mpsc to use and expand the code in Listing 16-10 to create multiple threads that all send values to the same receiver. We can do so by cloning the transmitter, as shown in Listing 16-11. Filename: src/main.rs # use std::sync::mpsc;\\n# use std::thread;\\n# use std::time::Duration;\\n# # fn main() { // --snip-- let (tx, rx) = mpsc::channel(); let tx1 = tx.clone(); thread::spawn(move || { let vals = vec![ String::from(\\"hi\\"), String::from(\\"from\\"), String::from(\\"the\\"), String::from(\\"thread\\"), ]; for val in vals { tx1.send(val).unwrap(); thread::sleep(Duration::from_secs(1)); } }); thread::spawn(move || { let vals = vec![ String::from(\\"more\\"), String::from(\\"messages\\"), String::from(\\"for\\"), String::from(\\"you\\"), ]; for val in vals { tx.send(val).unwrap(); thread::sleep(Duration::from_secs(1)); } }); for received in rx { println!(\\"Got: {received}\\"); } // --snip--\\n# } Listing 16-11: Sending multiple messages from multiple producers This time, before we create the first spawned thread, we call clone on the transmitter. This will give us a new transmitter we can pass to the first spawned thread. We pass the original transmitter to a second spawned thread. This gives us two threads, each sending different messages to the one receiver. When you run the code, your output should look something like this: Got: hi\\nGot: more\\nGot: from\\nGot: messages\\nGot: for\\nGot: the\\nGot: thread\\nGot: you You might see the values in another order, depending on your system. This is what makes concurrency interesting as well as difficult. If you experiment with thread::sleep, giving it various values in the different threads, each run will be more nondeterministic and create different output each time. Now that we‚Äôve looked at how channels work, let‚Äôs look at a different method of concurrency.","breadcrumbs":"Fearless Concurrency ¬ª Transfer Data Between Threads with Message Passing ¬ª Creating Multiple Producers","id":"299","title":"Creating Multiple Producers"},"3":{"body":"Rust is ideal for many people for a variety of reasons. Let‚Äôs look at a few of the most important groups.","breadcrumbs":"Introduction ¬ª Who Rust Is For","id":"3","title":"Who Rust Is For"},"30":{"body":"When your project is finally ready for release, you can use cargo build --release to compile it with optimizations. This command will create an executable in target/release instead of target/debug . The optimizations make your Rust code run faster, but turning them on lengthens the time it takes for your program to compile. This is why there are two different profiles: one for development, when you want to rebuild quickly and often, and another for building the final program you‚Äôll give to a user that won‚Äôt be rebuilt repeatedly and that will run as fast as possible. If you‚Äôre benchmarking your code‚Äôs running time, be sure to run cargo build --release and benchmark with the executable in target/release .","breadcrumbs":"Getting Started ¬ª Hello, Cargo! ¬ª Building for Release","id":"30","title":"Building for Release"},"300":{"body":"Message passing is a fine way to handle concurrency, but it‚Äôs not the only way. Another method would be for multiple threads to access the same shared data. Consider this part of the slogan from the Go language documentation again: ‚ÄúDo not communicate by sharing memory.‚Äù What would communicating by sharing memory look like? In addition, why would message-passing enthusiasts caution not to use memory sharing? In a way, channels in any programming language are similar to single ownership because once you transfer a value down a channel, you should no longer use that value. Shared-memory concurrency is like multiple ownership: Multiple threads can access the same memory location at the same time. As you saw in Chapter 15, where smart pointers made multiple ownership possible, multiple ownership can add complexity because these different owners need managing. Rust‚Äôs type system and ownership rules greatly assist in getting this management correct. For an example, let‚Äôs look at mutexes, one of the more common concurrency primitives for shared memory.","breadcrumbs":"Fearless Concurrency ¬ª Shared-State Concurrency ¬ª Shared-State Concurrency","id":"300","title":"Shared-State Concurrency"},"301":{"body":"Mutex is an abbreviation for mutual exclusion , as in a mutex allows only one thread to access some data at any given time. To access the data in a mutex, a thread must first signal that it wants access by asking to acquire the mutex‚Äôs lock. The lock is a data structure that is part of the mutex that keeps track of who currently has exclusive access to the data. Therefore, the mutex is described as guarding the data it holds via the locking system. Mutexes have a reputation for being difficult to use because you have to remember two rules: You must attempt to acquire the lock before using the data. When you‚Äôre done with the data that the mutex guards, you must unlock the data so that other threads can acquire the lock. For a real-world metaphor for a mutex, imagine a panel discussion at a conference with only one microphone. Before a panelist can speak, they have to ask or signal that they want to use the microphone. When they get the microphone, they can talk for as long as they want to and then hand the microphone to the next panelist who requests to speak. If a panelist forgets to hand the microphone off when they‚Äôre finished with it, no one else is able to speak. If management of the shared microphone goes wrong, the panel won‚Äôt work as planned! Management of mutexes can be incredibly tricky to get right, which is why so many people are enthusiastic about channels. However, thanks to Rust‚Äôs type system and ownership rules, you can‚Äôt get locking and unlocking wrong. The API of Mutex<T> As an example of how to use a mutex, let‚Äôs start by using a mutex in a single-threaded context, as shown in Listing 16-12. Filename: src/main.rs use std::sync::Mutex; fn main() { let m = Mutex::new(5); { let mut num = m.lock().unwrap(); *num = 6; } println!(\\"m = {m:?}\\");\\n} Listing 16-12: Exploring the API of Mutex&lt;T&gt; in a single-threaded context for simplicity As with many types, we create a Mutex<T> using the associated function new. To access the data inside the mutex, we use the lock method to acquire the lock. This call will block the current thread so that it can‚Äôt do any work until it‚Äôs our turn to have the lock. The call to lock would fail if another thread holding the lock panicked. In that case, no one would ever be able to get the lock, so we‚Äôve chosen to unwrap and have this thread panic if we‚Äôre in that situation. After we‚Äôve acquired the lock, we can treat the return value, named num in this case, as a mutable reference to the data inside. The type system ensures that we acquire a lock before using the value in m. The type of m is Mutex<i32>, not i32, so we must call lock to be able to use the i32 value. We can‚Äôt forget; the type system won‚Äôt let us access the inner i32 otherwise. The call to lock returns a type called MutexGuard, wrapped in a LockResult that we handled with the call to unwrap. The MutexGuard type implements Deref to point at our inner data; the type also has a Drop implementation that releases the lock automatically when a MutexGuard goes out of scope, which happens at the end of the inner scope. As a result, we don‚Äôt risk forgetting to release the lock and blocking the mutex from being used by other threads because the lock release happens automatically. After dropping the lock, we can print the mutex value and see that we were able to change the inner i32 to 6. Shared Access to Mutex<T> Now let‚Äôs try to share a value between multiple threads using Mutex<T>. We‚Äôll spin up 10 threads and have them each increment a counter value by 1, so the counter goes from 0 to 10. The example in Listing 16-13 will have a compiler error, and we‚Äôll use that error to learn more about using Mutex<T> and how Rust helps us use it correctly. Filename: src/main.rs use std::sync::Mutex;\\nuse std::thread; fn main() { let counter = Mutex::new(0); let mut handles = vec![]; for _ in 0..10 { let handle = thread::spawn(move || { let mut num = counter.lock().unwrap(); *num += 1; }); handles.push(handle); } for handle in handles { handle.join().unwrap(); } println!(\\"Result: {}\\", *counter.lock().unwrap());\\n} Listing 16-13: Ten threads, each incrementing a counter guarded by a Mutex&lt;T&gt; We create a counter variable to hold an i32 inside a Mutex<T>, as we did in Listing 16-12. Next, we create 10 threads by iterating over a range of numbers. We use thread::spawn and give all the threads the same closure: one that moves the counter into the thread, acquires a lock on the Mutex<T> by calling the lock method, and then adds 1 to the value in the mutex. When a thread finishes running its closure, num will go out of scope and release the lock so that another thread can acquire it. In the main thread, we collect all the join handles. Then, as we did in Listing 16-2, we call join on each handle to make sure all the threads finish. At that point, the main thread will acquire the lock and print the result of this program. We hinted that this example wouldn‚Äôt compile. Now let‚Äôs find out why! $ cargo run Compiling shared-state v0.1.0 (file:///projects/shared-state)\\nerror[E0382]: borrow of moved value: `counter` --> src/main.rs:21:29 |\\n5 | let counter = Mutex::new(0); | ------- move occurs because `counter` has type `Mutex<i32>`, which does not implement the `Copy` trait\\n...\\n8 | for _ in 0..10 { | -------------- inside of this loop\\n9 | let handle = thread::spawn(move || { | ------- value moved into closure here, in previous iteration of loop\\n...\\n21 | println!(\\"Result: {}\\", *counter.lock().unwrap()); | ^^^^^^^ value borrowed here after move |\\nhelp: consider moving the expression out of the loop so it is only moved once |\\n8 ~ let mut value = counter.lock();\\n9 ~ for _ in 0..10 {\\n10 | let handle = thread::spawn(move || {\\n11 ~ let mut num = value.unwrap(); | For more information about this error, try `rustc --explain E0382`.\\nerror: could not compile `shared-state` (bin \\"shared-state\\") due to 1 previous error The error message states that the counter value was moved in the previous iteration of the loop. Rust is telling us that we can‚Äôt move the ownership of lock counter into multiple threads. Let‚Äôs fix the compiler error with the multiple-ownership method we discussed in Chapter 15. Multiple Ownership with Multiple Threads In Chapter 15, we gave a value to multiple owners by using the smart pointer Rc<T> to create a reference-counted value. Let‚Äôs do the same here and see what happens. We‚Äôll wrap the Mutex<T> in Rc<T> in Listing 16-14 and clone the Rc<T> before moving ownership to the thread. Filename: src/main.rs use std::rc::Rc;\\nuse std::sync::Mutex;\\nuse std::thread; fn main() { let counter = Rc::new(Mutex::new(0)); let mut handles = vec![]; for _ in 0..10 { let counter = Rc::clone(&counter); let handle = thread::spawn(move || { let mut num = counter.lock().unwrap(); *num += 1; }); handles.push(handle); } for handle in handles { handle.join().unwrap(); } println!(\\"Result: {}\\", *counter.lock().unwrap());\\n} Listing 16-14: Attempting to use Rc&lt;T&gt; to allow multiple threads to own the Mutex&lt;T&gt; Once again, we compile and get‚Ä¶ different errors! The compiler is teaching us a lot: $ cargo run Compiling shared-state v0.1.0 (file:///projects/shared-state)\\nerror[E0277]: `Rc<Mutex<i32>>` cannot be sent between threads safely --> src/main.rs:11:36 |\\n11 | let handle = thread::spawn(move || { | ------------- ^------ | | | | ______________________|_____________within this `{closure@src/main.rs:11:36: 11:43}` | | | | | required by a bound introduced by this call\\n12 | | let mut num = counter.lock().unwrap();\\n13 | |\\n14 | | *num += 1;\\n15 | | }); | |_________^ `Rc<Mutex<i32>>` cannot be sent between threads safely | = help: within `{closure@src/main.rs:11:36: 11:43}`, the trait `Send` is not implemented for `Rc<Mutex<i32>>`\\nnote: required because it\'s used within this closure --> src/main.rs:11:36 |\\n11 | let handle = thread::spawn(move || { | ^^^^^^^\\nnote: required by a bound in `spawn` --> /rustc/4eb161250e340c8f48f66e2b929ef4a5bed7c181/library/std/src/thread/mod.rs:728:1 For more information about this error, try `rustc --explain E0277`.\\nerror: could not compile `shared-state` (bin \\"shared-state\\") due to 1 previous error Wow, that error message is very wordy! Here‚Äôs the important part to focus on: `Rc<Mutex<i32>>` cannot be sent between threads safely. The compiler is also telling us the reason why: the trait `Send` is not implemented for `Rc<Mutex<i32>>`. We‚Äôll talk about Send in the next section: It‚Äôs one of the traits that ensures that the types we use with threads are meant for use in concurrent situations. Unfortunately, Rc<T> is not safe to share across threads. When Rc<T> manages the reference count, it adds to the count for each call to clone and subtracts from the count when each clone is dropped. But it doesn‚Äôt use any concurrency primitives to make sure that changes to the count can‚Äôt be interrupted by another thread. This could lead to wrong counts‚Äîsubtle bugs that could in turn lead to memory leaks or a value being dropped before we‚Äôre done with it. What we need is a type that is exactly like Rc<T>, but that makes changes to the reference count in a thread-safe way. Atomic Reference Counting with Arc<T> Fortunately, Arc<T> is a type like Rc<T> that is safe to use in concurrent situations. The a stands for atomic , meaning it‚Äôs an atomically reference-counted type. Atomics are an additional kind of concurrency primitive that we won‚Äôt cover in detail here: See the standard library documentation for std::sync::atomic for more details. At this point, you just need to know that atomics work like primitive types but are safe to share across threads. You might then wonder why all primitive types aren‚Äôt atomic and why standard library types aren‚Äôt implemented to use Arc<T> by default. The reason is that thread safety comes with a performance penalty that you only want to pay when you really need to. If you‚Äôre just performing operations on values within a single thread, your code can run faster if it doesn‚Äôt have to enforce the guarantees atomics provide. Let‚Äôs return to our example: Arc<T> and Rc<T> have the same API, so we fix our program by changing the use line, the call to new, and the call to clone. The code in Listing 16-15 will finally compile and run. Filename: src/main.rs use std::sync::{Arc, Mutex};\\nuse std::thread; fn main() { let counter = Arc::new(Mutex::new(0)); let mut handles = vec![]; for _ in 0..10 { let counter = Arc::clone(&counter); let handle = thread::spawn(move || { let mut num = counter.lock().unwrap(); *num += 1; }); handles.push(handle); } for handle in handles { handle.join().unwrap(); } println!(\\"Result: {}\\", *counter.lock().unwrap());\\n} Listing 16-15: Using an Arc&lt;T&gt; to wrap the Mutex&lt;T&gt; to be able to share ownership across multiple threads This code will print the following: Result: 10 We did it! We counted from 0 to 10, which may not seem very impressive, but it did teach us a lot about Mutex<T> and thread safety. You could also use this program‚Äôs structure to do more complicated operations than just incrementing a counter. Using this strategy, you can divide a calculation into independent parts, split those parts across threads, and then use a Mutex<T> to have each thread update the final result with its part. Note that if you are doing simple numerical operations, there are types simpler than Mutex<T> types provided by the std::sync::atomic module of the standard library . These types provide safe, concurrent, atomic access to primitive types. We chose to use Mutex<T> with a primitive type for this example so that we could concentrate on how Mutex<T> works.","breadcrumbs":"Fearless Concurrency ¬ª Shared-State Concurrency ¬ª Controlling Access with Mutexes","id":"301","title":"Controlling Access with Mutexes"},"302":{"body":"You might have noticed that counter is immutable but that we could get a mutable reference to the value inside it; this means Mutex<T> provides interior mutability, as the Cell family does. In the same way we used RefCell<T> in Chapter 15 to allow us to mutate contents inside an Rc<T>, we use Mutex<T> to mutate contents inside an Arc<T>. Another detail to note is that Rust can‚Äôt protect you from all kinds of logic errors when you use Mutex<T>. Recall from Chapter 15 that using Rc<T> came with the risk of creating reference cycles, where two Rc<T> values refer to each other, causing memory leaks. Similarly, Mutex<T> comes with the risk of creating deadlocks . These occur when an operation needs to lock two resources and two threads have each acquired one of the locks, causing them to wait for each other forever. If you‚Äôre interested in deadlocks, try creating a Rust program that has a deadlock; then, research deadlock mitigation strategies for mutexes in any language and have a go at implementing them in Rust. The standard library API documentation for Mutex<T> and MutexGuard offers useful information. We‚Äôll round out this chapter by talking about the Send and Sync traits and how we can use them with custom types.","breadcrumbs":"Fearless Concurrency ¬ª Shared-State Concurrency ¬ª Comparing RefCell<T>/Rc<T> and Mutex<T>/Arc<T>","id":"302","title":"Comparing RefCell<T>/Rc<T> and Mutex<T>/Arc<T>"},"303":{"body":"Interestingly, almost every concurrency feature we‚Äôve talked about so far in this chapter has been part of the standard library, not the language. Your options for handling concurrency are not limited to the language or the standard library; you can write your own concurrency features or use those written by others. However, among the key concurrency concepts that are embedded in the language rather than the standard library are the std::marker traits Send and Sync.","breadcrumbs":"Fearless Concurrency ¬ª Extensible Concurrency with Send and Sync ¬ª Extensible Concurrency with Send and Sync","id":"303","title":"Extensible Concurrency with Send and Sync"},"304":{"body":"The Send marker trait indicates that ownership of values of the type implementing Send can be transferred between threads. Almost every Rust type implements Send, but there are some exceptions, including Rc<T>: This cannot implement Send because if you cloned an Rc<T> value and tried to transfer ownership of the clone to another thread, both threads might update the reference count at the same time. For this reason, Rc<T> is implemented for use in single-threaded situations where you don‚Äôt want to pay the thread-safe performance penalty. Therefore, Rust‚Äôs type system and trait bounds ensure that you can never accidentally send an Rc<T> value across threads unsafely. When we tried to do this in Listing 16-14, we got the error the trait `Send` is not implemented for `Rc<Mutex<i32>>`. When we switched to Arc<T>, which does implement Send, the code compiled. Any type composed entirely of Send types is automatically marked as Send as well. Almost all primitive types are Send, aside from raw pointers, which we‚Äôll discuss in Chapter 20.","breadcrumbs":"Fearless Concurrency ¬ª Extensible Concurrency with Send and Sync ¬ª Transferring Ownership Between Threads","id":"304","title":"Transferring Ownership Between Threads"},"305":{"body":"The Sync marker trait indicates that it is safe for the type implementing Sync to be referenced from multiple threads. In other words, any type T implements Sync if &T (an immutable reference to T) implements Send, meaning the reference can be sent safely to another thread. Similar to Send, primitive types all implement Sync, and types composed entirely of types that implement Sync also implement Sync. The smart pointer Rc<T> also doesn‚Äôt implement Sync for the same reasons that it doesn‚Äôt implement Send. The RefCell<T> type (which we talked about in Chapter 15) and the family of related Cell<T> types don‚Äôt implement Sync. The implementation of borrow checking that RefCell<T> does at runtime is not thread-safe. The smart pointer Mutex<T> implements Sync and can be used to share access with multiple threads, as you saw in ‚ÄúShared Access to Mutex<T>‚Äù .","breadcrumbs":"Fearless Concurrency ¬ª Extensible Concurrency with Send and Sync ¬ª Accessing from Multiple Threads","id":"305","title":"Accessing from Multiple Threads"},"306":{"body":"Because types composed entirely of other types that implement the Send and Sync traits also automatically implement Send and Sync, we don‚Äôt have to implement those traits manually. As marker traits, they don‚Äôt even have any methods to implement. They‚Äôre just useful for enforcing invariants related to concurrency. Manually implementing these traits involves implementing unsafe Rust code. We‚Äôll talk about using unsafe Rust code in Chapter 20; for now, the important information is that building new concurrent types not made up of Send and Sync parts requires careful thought to uphold the safety guarantees. ‚ÄúThe Rustonomicon‚Äù has more information about these guarantees and how to uphold them.","breadcrumbs":"Fearless Concurrency ¬ª Extensible Concurrency with Send and Sync ¬ª Implementing Send and Sync Manually Is Unsafe","id":"306","title":"Implementing Send and Sync Manually Is Unsafe"},"307":{"body":"This isn‚Äôt the last you‚Äôll see of concurrency in this book: The next chapter focuses on async programming, and the project in Chapter 21 will use the concepts in this chapter in a more realistic situation than the smaller examples discussed here. As mentioned earlier, because very little of how Rust handles concurrency is part of the language, many concurrency solutions are implemented as crates. These evolve more quickly than the standard library, so be sure to search online for the current, state-of-the-art crates to use in multithreaded situations. The Rust standard library provides channels for message passing and smart pointer types, such as Mutex<T> and Arc<T>, that are safe to use in concurrent contexts. The type system and the borrow checker ensure that the code using these solutions won‚Äôt end up with data races or invalid references. Once you get your code to compile, you can rest assured that it will happily run on multiple threads without the kinds of hard-to-track-down bugs common in other languages. Concurrent programming is no longer a concept to be afraid of: Go forth and make your programs concurrent, fearlessly!","breadcrumbs":"Fearless Concurrency ¬ª Extensible Concurrency with Send and Sync ¬ª Summary","id":"307","title":"Summary"},"308":{"body":"Many operations we ask the computer to do can take a while to finish. It would be nice if we could do something else while we‚Äôre waiting for those long-running processes to complete. Modern computers offer two techniques for working on more than one operation at a time: parallelism and concurrency. Our programs‚Äô logic, however, is written in a mostly linear fashion. We‚Äôd like to be able to specify the operations a program should perform and points at which a function could pause and some other part of the program could run instead, without needing to specify up front exactly the order and manner in which each bit of code should run. Asynchronous programming is an abstraction that lets us express our code in terms of potential pausing points and eventual results that takes care of the details of coordination for us. This chapter builds on Chapter 16‚Äôs use of threads for parallelism and concurrency by introducing an alternative approach to writing code: Rust‚Äôs futures, streams, and the async and await syntax that let us express how operations could be asynchronous, and the third-party crates that implement asynchronous runtimes: code that manages and coordinates the execution of asynchronous operations. Let‚Äôs consider an example. Say you‚Äôre exporting a video you‚Äôve created of a family celebration, an operation that could take anywhere from minutes to hours. The video export will use as much CPU and GPU power as it can. If you had only one CPU core and your operating system didn‚Äôt pause that export until it completed‚Äîthat is, if it executed the export synchronously ‚Äîyou couldn‚Äôt do anything else on your computer while that task was running. That would be a pretty frustrating experience. Fortunately, your computer‚Äôs operating system can, and does, invisibly interrupt the export often enough to let you get other work done simultaneously. Now say you‚Äôre downloading a video shared by someone else, which can also take a while but does not take up as much CPU time. In this case, the CPU has to wait for data to arrive from the network. While you can start reading the data once it starts to arrive, it might take some time for all of it to show up. Even once the data is all present, if the video is quite large, it could take at least a second or two to load it all. That might not sound like much, but it‚Äôs a very long time for a modern processor, which can perform billions of operations every second. Again, your operating system will invisibly interrupt your program to allow the CPU to perform other work while waiting for the network call to finish. The video export is an example of a CPU-bound or compute-bound operation. It‚Äôs limited by the computer‚Äôs potential data processing speed within the CPU or GPU, and how much of that speed it can dedicate to the operation. The video download is an example of an I/O-bound operation, because it‚Äôs limited by the speed of the computer‚Äôs input and output ; it can only go as fast as the data can be sent across the network. In both of these examples, the operating system‚Äôs invisible interrupts provide a form of concurrency. That concurrency happens only at the level of the entire program, though: the operating system interrupts one program to let other programs get work done. In many cases, because we understand our programs at a much more granular level than the operating system does, we can spot opportunities for concurrency that the operating system can‚Äôt see. For example, if we‚Äôre building a tool to manage file downloads, we should be able to write our program so that starting one download won‚Äôt lock up the UI, and users should be able to start multiple downloads at the same time. Many operating system APIs for interacting with the network are blocking , though; that is, they block the program‚Äôs progress until the data they‚Äôre processing is completely ready. Note: This is how most function calls work, if you think about it. However, the term blocking is usually reserved for function calls that interact with files, the network, or other resources on the computer, because those are the cases where an individual program would benefit from the operation being non -blocking. We could avoid blocking our main thread by spawning a dedicated thread to download each file. However, the overhead of the system resources used by those threads would eventually become a problem. It would be preferable if the call didn‚Äôt block in the first place, and instead we could define a number of tasks that we‚Äôd like our program to complete and allow the runtime to choose the best order and manner in which to run them. That is exactly what Rust‚Äôs async (short for asynchronous ) abstraction gives us. In this chapter, you‚Äôll learn all about async as we cover the following topics: How to use Rust‚Äôs async and await syntax and execute asynchronous functions with a runtime How to use the async model to solve some of the same challenges we looked at in Chapter 16 How multithreading and async provide complementary solutions that you can combine in many cases Before we see how async works in practice, though, we need to take a short detour to discuss the differences between parallelism and concurrency.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams","id":"308","title":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams"},"309":{"body":"We‚Äôve treated parallelism and concurrency as mostly interchangeable so far. Now we need to distinguish between them more precisely, because the differences will show up as we start working. Consider the different ways a team could split up work on a software project. You could assign a single member multiple tasks, assign each member one task, or use a mix of the two approaches. When an individual works on several different tasks before any of them is complete, this is concurrency . One way to implement concurrency is similar to having two different projects checked out on your computer, and when you get bored or stuck on one project, you switch to the other. You‚Äôre just one person, so you can‚Äôt make progress on both tasks at the exact same time, but you can multitask, making progress on one at a time by switching between them (see Figure 17-1). Figure 17-1: A concurrent workflow, switching between Task A and Task B When the team splits up a group of tasks by having each member take one task and work on it alone, this is parallelism . Each person on the team can make progress at the exact same time (see Figure 17-2). Figure 17-2: A parallel workflow, where work happens on Task A and Task B independently In both of these workflows, you might have to coordinate between different tasks. Maybe you thought the task assigned to one person was totally independent from everyone else‚Äôs work, but it actually requires another person on the team to finish their task first. Some of the work could be done in parallel, but some of it was actually serial : it could only happen in a series, one task after the other, as in Figure 17-3. Figure 17-3: A partially parallel workflow, where work happens on Task A and Task B independently until Task A3 is blocked on the results of Task B3. Likewise, you might realize that one of your own tasks depends on another of your tasks. Now your concurrent work has also become serial. Parallelism and concurrency can intersect with each other, too. If you learn that a colleague is stuck until you finish one of your tasks, you‚Äôll probably focus all your efforts on that task to ‚Äúunblock‚Äù your colleague. You and your coworker are no longer able to work in parallel, and you‚Äôre also no longer able to work concurrently on your own tasks. The same basic dynamics come into play with software and hardware. On a machine with a single CPU core, the CPU can perform only one operation at a time, but it can still work concurrently. Using tools such as threads, processes, and async, the computer can pause one activity and switch to others before eventually cycling back to that first activity again. On a machine with multiple CPU cores, it can also do work in parallel. One core can be performing one task while another core performs a completely unrelated one, and those operations actually happen at the same time. Running async code in Rust usually happens concurrently. Depending on the hardware, the operating system, and the async runtime we are using (more on async runtimes shortly), that concurrency may also use parallelism under the hood. Now, let‚Äôs dive into how async programming in Rust actually works.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Parallelism and Concurrency","id":"309","title":"Parallelism and Concurrency"},"31":{"body":"With simple projects, Cargo doesn‚Äôt provide a lot of value over just using rustc, but it will prove its worth as your programs become more intricate. Once programs grow to multiple files or need a dependency, it‚Äôs much easier to let Cargo coordinate the build. Even though the hello_cargo project is simple, it now uses much of the real tooling you‚Äôll use in the rest of your Rust career. In fact, to work on any existing projects, you can use the following commands to check out the code using Git, change to that project‚Äôs directory, and build: $ git clone example.org/someproject\\n$ cd someproject\\n$ cargo build For more information about Cargo, check out its documentation .","breadcrumbs":"Getting Started ¬ª Hello, Cargo! ¬ª Leveraging Cargo‚Äôs Conventions","id":"31","title":"Leveraging Cargo‚Äôs Conventions"},"310":{"body":"The key elements of asynchronous programming in Rust are futures and Rust‚Äôs async and await keywords. A future is a value that may not be ready now but will become ready at some point in the future. (This same concept shows up in many languages, sometimes under other names such as task or promise .) Rust provides a Future trait as a building block so that different async operations can be implemented with different data structures but with a common interface. In Rust, futures are types that implement the Future trait. Each future holds its own information about the progress that has been made and what ‚Äúready‚Äù means. You can apply the async keyword to blocks and functions to specify that they can be interrupted and resumed. Within an async block or async function, you can use the await keyword to await a future (that is, wait for it to become ready). Any point where you await a future within an async block or function is a potential spot for that block or function to pause and resume. The process of checking with a future to see if its value is available yet is called polling . Some other languages, such as C# and JavaScript, also use async and await keywords for async programming. If you‚Äôre familiar with those languages, you may notice some significant differences in how Rust handles the syntax. That‚Äôs for good reason, as we‚Äôll see! When writing async Rust, we use the async and await keywords most of the time. Rust compiles them into equivalent code using the Future trait, much as it compiles for loops into equivalent code using the Iterator trait. Because Rust provides the Future trait, though, you can also implement it for your own data types when you need to. Many of the functions we‚Äôll see throughout this chapter return types with their own implementations of Future. We‚Äôll return to the definition of the trait at the end of the chapter and dig into more of how it works, but this is enough detail to keep us moving forward. This may all feel a bit abstract, so let‚Äôs write our first async program: a little web scraper. We‚Äôll pass in two URLs from the command line, fetch both of them concurrently, and return the result of whichever one finishes first. This example will have a fair bit of new syntax, but don‚Äôt worry‚Äîwe‚Äôll explain everything you need to know as we go.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Futures and the Async Syntax ¬ª Futures and the Async Syntax","id":"310","title":"Futures and the Async Syntax"},"311":{"body":"To keep the focus of this chapter on learning async rather than juggling parts of the ecosystem, we‚Äôve created the trpl crate (trpl is short for ‚ÄúThe Rust Programming Language‚Äù). It re-exports all the types, traits, and functions you‚Äôll need, primarily from the futures and tokio crates. The futures crate is an official home for Rust experimentation for async code, and it‚Äôs actually where the Future trait was originally designed. Tokio is the most widely used async runtime in Rust today, especially for web applications. There are other great runtimes out there, and they may be more suitable for your purposes. We use the tokio crate under the hood for trpl because it‚Äôs well tested and widely used. In some cases, trpl also renames or wraps the original APIs to keep you focused on the details relevant to this chapter. If you want to understand what the crate does, we encourage you to check out its source code . You‚Äôll be able to see what crate each re-export comes from, and we‚Äôve left extensive comments explaining what the crate does. Create a new binary project named hello-async and add the trpl crate as a dependency: $ cargo new hello-async\\n$ cd hello-async\\n$ cargo add trpl Now we can use the various pieces provided by trpl to write our first async program. We‚Äôll build a little command line tool that fetches two web pages, pulls the <title> element from each, and prints out the title of whichever page finishes that whole process first.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Futures and the Async Syntax ¬ª Our First Async Program","id":"311","title":"Our First Async Program"},"312":{"body":"Let‚Äôs start by writing a function that takes one page URL as a parameter, makes a request to it, and returns the text of the <title> element (see Listing 17-1). Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # fn main() {\\n# // TODO: we\'ll add this next!\\n# }\\n# use trpl::Html; async fn page_title(url: &str) -> Option<String> { let response = trpl::get(url).await; let response_text = response.text().await; Html::parse(&response_text) .select_first(\\"title\\") .map(|title| title.inner_html())\\n} Listing 17-1: Defining an async function to get the title element from an HTML page First, we define a function named page_title and mark it with the async keyword. Then we use the trpl::get function to fetch whatever URL is passed in and add the await keyword to await the response. To get the text of the response, we call its text method and once again await it with the await keyword. Both of these steps are asynchronous. For the get function, we have to wait for the server to send back the first part of its response, which will include HTTP headers, cookies, and so on and can be delivered separately from the response body. Especially if the body is very large, it can take some time for it all to arrive. Because we have to wait for the entirety of the response to arrive, the text method is also async. We have to explicitly await both of these futures, because futures in Rust are lazy : they don‚Äôt do anything until you ask them to with the await keyword. (In fact, Rust will show a compiler warning if you don‚Äôt use a future.) This might remind you of the discussion of iterators in the ‚ÄúProcessing a Series of Items with Iterators‚Äù section in Chapter 13. Iterators do nothing unless you call their next method‚Äîwhether directly or by using for loops or methods such as map that use next under the hood. Likewise, futures do nothing unless you explicitly ask them to. This laziness allows Rust to avoid running async code until it‚Äôs actually needed. Note: This is different from the behavior we saw when using thread::spawn in the ‚ÄúCreating a New Thread with spawn‚Äù section in Chapter 16, where the closure we passed to another thread started running immediately. It‚Äôs also different from how many other languages approach async. But it‚Äôs important for Rust to be able to provide its performance guarantees, just as it is with iterators. Once we have response_text, we can parse it into an instance of the Html type using Html::parse. Instead of a raw string, we now have a data type we can use to work with the HTML as a richer data structure. In particular, we can use the select_first method to find the first instance of a given CSS selector. By passing the string \\"title\\", we‚Äôll get the first <title> element in the document, if there is one. Because there may not be any matching element, select_first returns an Option<ElementRef>. Finally, we use the Option::map method, which lets us work with the item in the Option if it‚Äôs present, and do nothing if it isn‚Äôt. (We could also use a match expression here, but map is more idiomatic.) In the body of the function we supply to map, we call inner_html on the title to get its content, which is a String. When all is said and done, we have an Option<String>. Notice that Rust‚Äôs await keyword goes after the expression you‚Äôre awaiting, not before it. That is, it‚Äôs a postfix keyword. This may differ from what you‚Äôre used to if you‚Äôve used async in other languages, but in Rust it makes chains of methods much nicer to work with. As a result, we could change the body of page_title to chain the trpl::get and text function calls together with await between them, as shown in Listing 17-2. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use trpl::Html;\\n# # fn main() {\\n# // TODO: we\'ll add this next!\\n# }\\n# # async fn page_title(url: &str) -> Option<String> { let response_text = trpl::get(url).await.text().await;\\n# Html::parse(&response_text)\\n# .select_first(\\"title\\")\\n# .map(|title| title.inner_html())\\n# } Listing 17-2: Chaining with the await keyword With that, we have successfully written our first async function! Before we add some code in main to call it, let‚Äôs talk a little more about what we‚Äôve written and what it means. When Rust sees a block marked with the async keyword, it compiles it into a unique, anonymous data type that implements the Future trait. When Rust sees a function marked with async, it compiles it into a non-async function whose body is an async block. An async function‚Äôs return type is the type of the anonymous data type the compiler creates for that async block. Thus, writing async fn is equivalent to writing a function that returns a future of the return type. To the compiler, a function definition such as the async fn page_title in Listing 17-1 is roughly equivalent to a non-async function defined like this: # extern crate trpl; // required for mdbook test\\nuse std::future::Future;\\nuse trpl::Html; fn page_title(url: &str) -> impl Future<Output = Option<String>> { async move { let text = trpl::get(url).await.text().await; Html::parse(&text) .select_first(\\"title\\") .map(|title| title.inner_html()) }\\n} Let‚Äôs walk through each part of the transformed version: It uses the impl Trait syntax we discussed back in Chapter 10 in the ‚ÄúTraits as Parameters‚Äù section. The returned value implements the Future trait with an associated type of Output. Notice that the Output type is Option<String>, which is the same as the original return type from the async fn version of page_title. All of the code called in the body of the original function is wrapped in an async move block. Remember that blocks are expressions. This whole block is the expression returned from the function. This async block produces a value with the type Option<String>, as just described. That value matches the Output type in the return type. This is just like other blocks you have seen. The new function body is an async move block because of how it uses the url parameter. (We‚Äôll talk much more about async versus async move later in the chapter.) Now we can call page_title in main.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Futures and the Async Syntax ¬ª Defining the page_title Function","id":"312","title":"Defining the page_title Function"},"313":{"body":"To start, we‚Äôll get the title for a single page, shown in Listing 17-3. Unfortunately, this code doesn‚Äôt compile yet. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use trpl::Html;\\n# async fn main() { let args: Vec<String> = std::env::args().collect(); let url = &args[1]; match page_title(url).await { Some(title) => println!(\\"The title for {url} was {title}\\"), None => println!(\\"{url} had no title\\"), }\\n}\\n# # async fn page_title(url: &str) -> Option<String> {\\n# let response_text = trpl::get(url).await.text().await;\\n# Html::parse(&response_text)\\n# .select_first(\\"title\\")\\n# .map(|title| title.inner_html())\\n# } Listing 17-3: Calling the page_title function from main with a user-supplied argument We follow the same pattern we used to get command line arguments in the ‚ÄúAccepting Command Line Arguments‚Äù section in Chapter 12. Then we pass the URL argument to page_title and await the result. Because the value produced by the future is an Option<String>, we use a match expression to print different messages to account for whether the page had a <title>. The only place we can use the await keyword is in async functions or blocks, and Rust won‚Äôt let us mark the special main function as async. error[E0752]: `main` function is not allowed to be `async` --> src/main.rs:6:1 |\\n6 | async fn main() { | ^^^^^^^^^^^^^^^ `main` function is not allowed to be `async` The reason main can‚Äôt be marked async is that async code needs a runtime : a Rust crate that manages the details of executing asynchronous code. A program‚Äôs main function can initialize a runtime, but it‚Äôs not a runtime itself . (We‚Äôll see more about why this is the case in a bit.) Every Rust program that executes async code has at least one place where it sets up a runtime that executes the futures. Most languages that support async bundle a runtime, but Rust does not. Instead, there are many different async runtimes available, each of which makes different tradeoffs suitable to the use case it targets. For example, a high-throughput web server with many CPU cores and a large amount of RAM has very different needs than a microcontroller with a single core, a small amount of RAM, and no heap allocation ability. The crates that provide those runtimes also often supply async versions of common functionality such as file or network I/O. Here, and throughout the rest of this chapter, we‚Äôll use the block_on function from the trpl crate, which takes a future as an argument and blocks the current thread until this future runs to completion. Behind the scenes, calling block_on sets up a runtime using the tokio crate that‚Äôs used to run the future passed in (the trpl crate‚Äôs block_on behavior is similar to other runtime crates‚Äô block_on functions). Once the future completes, block_on returns whatever value the future produced. We could pass the future returned by page_title directly to block_on and, once it completed, we could match on the resulting Option<String> as we tried to do in Listing 17-3. However, for most of the examples in the chapter (and most async code in the real world), we‚Äôll be doing more than just one async function call, so instead we‚Äôll pass an async block and explicitly await the result of the page_title call, as in Listing 17-4. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use trpl::Html;\\n# fn main() { let args: Vec<String> = std::env::args().collect(); trpl::block_on(async { let url = &args[1]; match page_title(url).await { Some(title) => println!(\\"The title for {url} was {title}\\"), None => println!(\\"{url} had no title\\"), } })\\n}\\n# # async fn page_title(url: &str) -> Option<String> {\\n# let response_text = trpl::get(url).await.text().await;\\n# Html::parse(&response_text)\\n# .select_first(\\"title\\")\\n# .map(|title| title.inner_html())\\n# } Listing 17-4: Awaiting an async block with trpl::block_on When we run this code, we get the behavior we expected initially: $ cargo run -- \\"https://www.rust-lang.org\\" Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.05s Running `target/debug/async_await \'https://www.rust-lang.org\'`\\nThe title for https://www.rust-lang.org was Rust Programming Language Phew‚Äîwe finally have some working async code! But before we add the code to race two sites against each other, let‚Äôs briefly turn our attention back to how futures work. Each await point ‚Äîthat is, every place where the code uses the await keyword‚Äîrepresents a place where control is handed back to the runtime. To make that work, Rust needs to keep track of the state involved in the async block so that the runtime could kick off some other work and then come back when it‚Äôs ready to try advancing the first one again. This is an invisible state machine, as if you‚Äôd written an enum like this to save the current state at each await point: # extern crate trpl; // required for mdbook test\\n# enum PageTitleFuture<\'a> { Initial { url: &\'a str }, GetAwaitPoint { url: &\'a str }, TextAwaitPoint { response: trpl::Response },\\n} Writing the code to transition between each state by hand would be tedious and error-prone, however, especially when you need to add more functionality and more states to the code later. Fortunately, the Rust compiler creates and manages the state machine data structures for async code automatically. The normal borrowing and ownership rules around data structures all still apply, and happily, the compiler also handles checking those for us and provides useful error messages. We‚Äôll work through a few of those later in the chapter. Ultimately, something has to execute this state machine, and that something is a runtime. (This is why you may come across mentions of executors when looking into runtimes: an executor is the part of a runtime responsible for executing the async code.) Now you can see why the compiler stopped us from making main itself an async function back in Listing 17-3. If main were an async function, something else would need to manage the state machine for whatever future main returned, but main is the starting point for the program! Instead, we called the trpl::block_on function in main to set up a runtime and run the future returned by the async block until it‚Äôs done. Note: Some runtimes provide macros so you can write an async main function. Those macros rewrite async fn main() { ... } to be a normal fn main, which does the same thing we did by hand in Listing 17-4: call a function that runs a future to completion the way trpl::block_on does. Now let‚Äôs put these pieces together and see how we can write concurrent code.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Futures and the Async Syntax ¬ª Executing an Async Function with a Runtime","id":"313","title":"Executing an Async Function with a Runtime"},"314":{"body":"In Listing 17-5, we call page_title with two different URLs passed in from the command line and race them by selecting whichever future finishes first. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# use trpl::{Either, Html}; fn main() { let args: Vec<String> = std::env::args().collect(); trpl::block_on(async { let title_fut_1 = page_title(&args[1]); let title_fut_2 = page_title(&args[2]); let (url, maybe_title) = match trpl::select(title_fut_1, title_fut_2).await { Either::Left(left) => left, Either::Right(right) => right, }; println!(\\"{url} returned first\\"); match maybe_title { Some(title) => println!(\\"Its page title was: \'{title}\'\\"), None => println!(\\"It had no title.\\"), } })\\n} async fn page_title(url: &str) -> (&str, Option<String>) { let response_text = trpl::get(url).await.text().await; let title = Html::parse(&response_text) .select_first(\\"title\\") .map(|title| title.inner_html()); (url, title)\\n} Listing 17-5: Calling page_title for two URLs to see which returns first We begin by calling page_title for each of the user-supplied URLs. We save the resulting futures as title_fut_1 and title_fut_2. Remember, these don‚Äôt do anything yet, because futures are lazy and we haven‚Äôt yet awaited them. Then we pass the futures to trpl::select, which returns a value to indicate which of the futures passed to it finishes first. Note: Under the hood, trpl::select is built on a more general select function defined in the futures crate. The futures crate‚Äôs select function can do a lot of things that the trpl::select function can‚Äôt, but it also has some additional complexity that we can skip over for now. Either future can legitimately ‚Äúwin,‚Äù so it doesn‚Äôt make sense to return a Result. Instead, trpl::select returns a type we haven‚Äôt seen before, trpl::Either. The Either type is somewhat similar to a Result in that it has two cases. Unlike Result, though, there is no notion of success or failure baked into Either. Instead, it uses Left and Right to indicate ‚Äúone or the other‚Äù: enum Either<A, B> { Left(A), Right(B),\\n} The select function returns Left with that future‚Äôs output if the first argument wins, and Right with the second future argument‚Äôs output if that one wins. This matches the order the arguments appear in when calling the function: the first argument is to the left of the second argument. We also update page_title to return the same URL passed in. That way, if the page that returns first does not have a <title> we can resolve, we can still print a meaningful message. With that information available, we wrap up by updating our println! output to indicate both which URL finished first and what, if any, the <title> is for the web page at that URL. You have built a small working web scraper now! Pick a couple URLs and run the command line tool. You may discover that some sites are consistently faster than others, while in other cases the faster site varies from run to run. More importantly, you‚Äôve learned the basics of working with futures, so now we can dig deeper into what we can do with async.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Futures and the Async Syntax ¬ª Racing Two URLs Against Each Other Concurrently","id":"314","title":"Racing Two URLs Against Each Other Concurrently"},"315":{"body":"In this section, we‚Äôll apply async to some of the same concurrency challenges we tackled with threads in Chapter 16. Because we already talked about a lot of the key ideas there, in this section we‚Äôll focus on what‚Äôs different between threads and futures. In many cases, the APIs for working with concurrency using async are very similar to those for using threads. In other cases, they end up being quite different. Even when the APIs look similar between threads and async, they often have different behavior‚Äîand they nearly always have different performance characteristics.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Applying Concurrency with Async ¬ª Applying Concurrency with Async","id":"315","title":"Applying Concurrency with Async"},"316":{"body":"The first operation we tackled in the ‚ÄúCreating a New Thread with spawn‚Äù section in Chapter 16 was counting up on two separate threads. Let‚Äôs do the same using async. The trpl crate supplies a spawn_task function that looks very similar to the thread::spawn API, and a sleep function that is an async version of the thread::sleep API. We can use these together to implement the counting example, as shown in Listing 17-6. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# use std::time::Duration; fn main() { trpl::block_on(async { trpl::spawn_task(async { for i in 1..10 { println!(\\"hi number {i} from the first task!\\"); trpl::sleep(Duration::from_millis(500)).await; } }); for i in 1..5 { println!(\\"hi number {i} from the second task!\\"); trpl::sleep(Duration::from_millis(500)).await; } });\\n} Listing 17-6: Creating a new task to print one thing while the main task prints something else As our starting point, we set up our main function with trpl::block_on so that our top-level function can be async. Note: From this point forward in the chapter, every example will include this exact same wrapping code with trpl::block_on in main, so we‚Äôll often skip it just as we do with main. Remember to include it in your code! Then we write two loops within that block, each containing a trpl::sleep call, which waits for half a second (500 milliseconds) before sending the next message. We put one loop in the body of a trpl::spawn_task and the other in a top-level for loop. We also add an await after the sleep calls. This code behaves similarly to the thread-based implementation‚Äîincluding the fact that you may see the messages appear in a different order in your own terminal when you run it: hi number 1 from the second task!\\nhi number 1 from the first task!\\nhi number 2 from the first task!\\nhi number 2 from the second task!\\nhi number 3 from the first task!\\nhi number 3 from the second task!\\nhi number 4 from the first task!\\nhi number 4 from the second task!\\nhi number 5 from the first task! This version stops as soon as the for loop in the body of the main async block finishes, because the task spawned by spawn_task is shut down when the main function ends. If you want it to run all the way to the task‚Äôs completion, you will need to use a join handle to wait for the first task to complete. With threads, we used the join method to ‚Äúblock‚Äù until the thread was done running. In Listing 17-7, we can use await to do the same thing, because the task handle itself is a future. Its Output type is a Result, so we also unwrap it after awaiting it. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async { let handle = trpl::spawn_task(async { for i in 1..10 { println!(\\"hi number {i} from the first task!\\"); trpl::sleep(Duration::from_millis(500)).await; } }); for i in 1..5 { println!(\\"hi number {i} from the second task!\\"); trpl::sleep(Duration::from_millis(500)).await; } handle.await.unwrap();\\n# });\\n# } Listing 17-7: Using await with a join handle to run a task to completion This updated version runs until both loops finish: hi number 1 from the second task!\\nhi number 1 from the first task!\\nhi number 2 from the first task!\\nhi number 2 from the second task!\\nhi number 3 from the first task!\\nhi number 3 from the second task!\\nhi number 4 from the first task!\\nhi number 4 from the second task!\\nhi number 5 from the first task!\\nhi number 6 from the first task!\\nhi number 7 from the first task!\\nhi number 8 from the first task!\\nhi number 9 from the first task! So far, it looks like async and threads give us similar outcomes, just with different syntax: using await instead of calling join on the join handle, and awaiting the sleep calls. The bigger difference is that we didn‚Äôt need to spawn another operating system thread to do this. In fact, we don‚Äôt even need to spawn a task here. Because async blocks compile to anonymous futures, we can put each loop in an async block and have the runtime run them both to completion using the trpl::join function. In the ‚ÄúWaiting for All Threads to Finish‚Äù section in Chapter 16, we showed how to use the join method on the JoinHandle type returned when you call std::thread::spawn. The trpl::join function is similar, but for futures. When you give it two futures, it produces a single new future whose output is a tuple containing the output of each future you passed in once they both complete. Thus, in Listing 17-8, we use trpl::join to wait for both fut1 and fut2 to finish. We do not await fut1 and fut2 but instead the new future produced by trpl::join. We ignore the output, because it‚Äôs just a tuple containing two unit values. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async { let fut1 = async { for i in 1..10 { println!(\\"hi number {i} from the first task!\\"); trpl::sleep(Duration::from_millis(500)).await; } }; let fut2 = async { for i in 1..5 { println!(\\"hi number {i} from the second task!\\"); trpl::sleep(Duration::from_millis(500)).await; } }; trpl::join(fut1, fut2).await;\\n# });\\n# } Listing 17-8: Using trpl::join to await two anonymous futures When we run this, we see both futures run to completion: hi number 1 from the first task!\\nhi number 1 from the second task!\\nhi number 2 from the first task!\\nhi number 2 from the second task!\\nhi number 3 from the first task!\\nhi number 3 from the second task!\\nhi number 4 from the first task!\\nhi number 4 from the second task!\\nhi number 5 from the first task!\\nhi number 6 from the first task!\\nhi number 7 from the first task!\\nhi number 8 from the first task!\\nhi number 9 from the first task! Now, you‚Äôll see the exact same order every time, which is very different from what we saw with threads and with trpl::spawn_task in Listing 17-7. That is because the trpl::join function is fair , meaning it checks each future equally often, alternating between them, and never lets one race ahead if the other is ready. With threads, the operating system decides which thread to check and how long to let it run. With async Rust, the runtime decides which task to check. (In practice, the details get complicated because an async runtime might use operating system threads under the hood as part of how it manages concurrency, so guaranteeing fairness can be more work for a runtime‚Äîbut it‚Äôs still possible!) Runtimes don‚Äôt have to guarantee fairness for any given operation, and they often offer different APIs to let you choose whether or not you want fairness. Try some of these variations on awaiting the futures and see what they do: Remove the async block from around either or both of the loops. Await each async block immediately after defining it. Wrap only the first loop in an async block, and await the resulting future after the body of second loop. For an extra challenge, see if you can figure out what the output will be in each case before running the code!","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Applying Concurrency with Async ¬ª Creating a New Task with spawn_task","id":"316","title":"Creating a New Task with spawn_task"},"317":{"body":"Sharing data between futures will also be familiar: we‚Äôll use message passing again, but this time with async versions of the types and functions. We‚Äôll take a slightly different path than we did in the ‚ÄúTransfer Data Between Threads with Message Passing‚Äù section in Chapter 16 to illustrate some of the key differences between thread-based and futures-based concurrency. In Listing 17-9, we‚Äôll begin with just a single async block‚Äî not spawning a separate task as we spawned a separate thread. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # fn main() {\\n# trpl::block_on(async { let (tx, mut rx) = trpl::channel(); let val = String::from(\\"hi\\"); tx.send(val).unwrap(); let received = rx.recv().await.unwrap(); println!(\\"received \'{received}\'\\");\\n# });\\n# } Listing 17-9: Creating an async channel and assigning the two halves to tx and rx Here, we use trpl::channel, an async version of the multiple-producer, single-consumer channel API we used with threads back in Chapter 16. The async version of the API is only a little different from the thread-based version: it uses a mutable rather than an immutable receiver rx, and its recv method produces a future we need to await rather than producing the value directly. Now we can send messages from the sender to the receiver. Notice that we don‚Äôt have to spawn a separate thread or even a task; we merely need to await the rx.recv call. The synchronous Receiver::recv method in std::mpsc::channel blocks until it receives a message. The trpl::Receiver::recv method does not, because it is async. Instead of blocking, it hands control back to the runtime until either a message is received or the send side of the channel closes. By contrast, we don‚Äôt await the send call, because it doesn‚Äôt block. It doesn‚Äôt need to, because the channel we‚Äôre sending it into is unbounded. Note: Because all of this async code runs in an async block in a trpl::block_on call, everything within it can avoid blocking. However, the code outside it will block on the block_on function returning. That‚Äôs the whole point of the trpl::block_on function: it lets you choose where to block on some set of async code, and thus where to transition between sync and async code. Notice two things about this example. First, the message will arrive right away. Second, although we use a future here, there‚Äôs no concurrency yet. Everything in the listing happens in sequence, just as it would if there were no futures involved. Let‚Äôs address the first part by sending a series of messages and sleeping in between them, as shown in Listing 17-10. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async { let (tx, mut rx) = trpl::channel(); let vals = vec![ String::from(\\"hi\\"), String::from(\\"from\\"), String::from(\\"the\\"), String::from(\\"future\\"), ]; for val in vals { tx.send(val).unwrap(); trpl::sleep(Duration::from_millis(500)).await; } while let Some(value) = rx.recv().await { println!(\\"received \'{value}\'\\"); }\\n# });\\n# } Listing 17-10: Sending and receiving multiple messages over the async channel and sleeping with an await between each message In addition to sending the messages, we need to receive them. In this case, because we know how many messages are coming in, we could do that manually by calling rx.recv().await four times. In the real world, though, we‚Äôll generally be waiting on some unknown number of messages, so we need to keep waiting until we determine that there are no more messages. In Listing 16-10, we used a for loop to process all the items received from a synchronous channel. Rust doesn‚Äôt yet have a way to use a for loop with an asynchronously produced series of items, however, so we need to use a loop we haven‚Äôt seen before: the while let conditional loop. This is the loop version of the if let construct we saw back in the ‚ÄúConcise Control Flow with if let and let else‚Äù section in Chapter 6. The loop will continue executing as long as the pattern it specifies continues to match the value. The rx.recv call produces a future, which we await. The runtime will pause the future until it is ready. Once a message arrives, the future will resolve to Some(message) as many times as a message arrives. When the channel closes, regardless of whether any messages have arrived, the future will instead resolve to None to indicate that there are no more values and thus we should stop polling‚Äîthat is, stop awaiting. The while let loop pulls all of this together. If the result of calling rx.recv().await is Some(message), we get access to the message and we can use it in the loop body, just as we could with if let. If the result is None, the loop ends. Every time the loop completes, it hits the await point again, so the runtime pauses it again until another message arrives. The code now successfully sends and receives all of the messages. Unfortunately, there are still a couple of problems. For one thing, the messages do not arrive at half-second intervals. They arrive all at once, 2 seconds (2,000 milliseconds) after we start the program. For another, this program also never exits! Instead, it waits forever for new messages. You will need to shut it down using ctrl-C. Code Within One Async Block Executes Linearly Let‚Äôs start by examining why the messages come in all at once after the full delay, rather than coming in with delays between each one. Within a given async block, the order in which await keywords appear in the code is also the order in which they‚Äôre executed when the program runs. There‚Äôs only one async block in Listing 17-10, so everything in it runs linearly. There‚Äôs still no concurrency. All the tx.send calls happen, interspersed with all of the trpl::sleep calls and their associated await points. Only then does the while let loop get to go through any of the await points on the recv calls. To get the behavior we want, where the sleep delay happens between each message, we need to put the tx and rx operations in their own async blocks, as shown in Listing 17-11. Then the runtime can execute each of them separately using trpl::join, just as in Listing 17-8. Once again, we await the result of calling trpl::join, not the individual futures. If we awaited the individual futures in sequence, we would just end up back in a sequential flow‚Äîexactly what we‚Äôre trying not to do. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async {\\n# let (tx, mut rx) = trpl::channel();\\n# let tx_fut = async { let vals = vec![ String::from(\\"hi\\"), String::from(\\"from\\"), String::from(\\"the\\"), String::from(\\"future\\"), ]; for val in vals { tx.send(val).unwrap(); trpl::sleep(Duration::from_millis(500)).await; } }; let rx_fut = async { while let Some(value) = rx.recv().await { println!(\\"received \'{value}\'\\"); } }; trpl::join(tx_fut, rx_fut).await;\\n# });\\n# } Listing 17-11: Separating send and recv into their own async blocks and awaiting the futures for those blocks With the updated code in Listing 17-11, the messages get printed at 500-millisecond intervals, rather than all in a rush after 2 seconds. Moving Ownership Into an Async Block The program still never exits, though, because of the way the while let loop interacts with trpl::join: The future returned from trpl::join completes only once both futures passed to it have completed. The tx_fut future completes once it finishes sleeping after sending the last message in vals. The rx_fut future won‚Äôt complete until the while let loop ends. The while let loop won‚Äôt end until awaiting rx.recv produces None. Awaiting rx.recv will return None only once the other end of the channel is closed. The channel will close only if we call rx.close or when the sender side, tx, is dropped. We don‚Äôt call rx.close anywhere, and tx won‚Äôt be dropped until the outermost async block passed to trpl::block_on ends. The block can‚Äôt end because it is blocked on trpl::join completing, which takes us back to the top of this list. Right now, the async block where we send the messages only borrows tx because sending a message doesn‚Äôt require ownership, but if we could move tx into that async block, it would be dropped once that block ends. In the ‚ÄúCapturing References or Moving Ownership‚Äù section in Chapter 13, you learned how to use the move keyword with closures, and, as discussed in the ‚ÄúUsing move Closures with Threads‚Äù section in Chapter 16, we often need to move data into closures when working with threads. The same basic dynamics apply to async blocks, so the move keyword works with async blocks just as it does with closures. In Listing 17-12, we change the block used to send messages from async to async move. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async { let (tx, mut rx) = trpl::channel(); let tx_fut = async move { // --snip--\\n# let vals = vec![\\n# String::from(\\"hi\\"),\\n# String::from(\\"from\\"),\\n# String::from(\\"the\\"),\\n# String::from(\\"future\\"),\\n# ];\\n# # for val in vals {\\n# tx.send(val).unwrap();\\n# trpl::sleep(Duration::from_millis(500)).await;\\n# }\\n# };\\n# # let rx_fut = async {\\n# while let Some(value) = rx.recv().await {\\n# println!(\\"received \'{value}\'\\");\\n# }\\n# };\\n# # trpl::join(tx_fut, rx_fut).await;\\n# });\\n# } Listing 17-12: A revision of the code from Listing 17-11 that correctly shuts down when complete When we run this version of the code, it shuts down gracefully after the last message is sent and received. Next, let‚Äôs see what would need to change to send data from more than one future. Joining a Number of Futures with the join! Macro This async channel is also a multiple-producer channel, so we can call clone on tx if we want to send messages from multiple futures, as shown in Listing 17-13. Filename: src/main.rs # extern crate trpl; // required for mdbook test\\n# # use std::time::Duration;\\n# # fn main() {\\n# trpl::block_on(async { let (tx, mut rx) = trpl::channel(); let tx1 = tx.clone(); let tx1_fut = async move { let vals = vec![ String::from(\\"hi\\"), String::from(\\"from\\"), String::from(\\"the\\"), String::from(\\"future\\"), ]; for val in vals { tx1.send(val).unwrap(); trpl::sleep(Duration::from_millis(500)).await; } }; let rx_fut = async { while let Some(value) = rx.recv().await { println!(\\"received \'{value}\'\\"); } }; let tx_fut = async move { let vals = vec![ String::from(\\"more\\"), String::from(\\"messages\\"), String::from(\\"for\\"), String::from(\\"you\\"), ]; for val in vals { tx.send(val).unwrap(); trpl::sleep(Duration::from_millis(1500)).await; } }; trpl::join!(tx1_fut, tx_fut, rx_fut);\\n# });\\n# } Listing 17-13: Using multiple producers with async blocks First, we clone tx, creating tx1 outside the first async block. We move tx1 into that block just as we did before with tx. Then, later, we move the original tx into a new async block, where we send more messages on a slightly slower delay. We happen to put this new async block after the async block for receiving messages, but it could go before it just as well. The key is the order in which the futures are awaited, not in which they‚Äôre created. Both of the async blocks for sending messages need to be async move blocks so that both tx and tx1 get dropped when those blocks finish. Otherwise, we‚Äôll end up back in the same infinite loop we started out in. Finally, we switch from trpl::join to trpl::join! to handle the additional future: the join! macro awaits an arbitrary number of futures where we know the number of futures at compile time. We‚Äôll discuss awaiting a collection of an unknown number of futures later in this chapter. Now we see all the messages from both sending futures, and because the sending futures use slightly different delays after sending, the messages are also received at those different intervals: received \'hi\'\\nreceived \'more\'\\nreceived \'from\'\\nreceived \'the\'\\nreceived \'messages\'\\nreceived \'future\'\\nreceived \'for\'\\nreceived \'you\' We‚Äôve explored how to use message passing to send data between futures, how code within an async block runs sequentially, how to move ownership into an async block, and how to join multiple futures. Next, let‚Äôs discuss how and why to tell the runtime it can switch to another task.","breadcrumbs":"Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams ¬ª Applying Concurrency with Async ¬ª Sending Data Between Two Tasks Using Message Passing","id":"317","title":"Sending Data Between Two Tasks Using Message Passing"},"318":{"body":"Recall from the ‚ÄúOur First Async Program‚Äù section that at each await point, Rust gives a runtime a chance to pause the task and switch to another one if the future being awaited isn‚Äôt ready. The inverse is also true: Rust only pauses async blocks and hands control back to a runtime at an await point. Everything between await points is synchronous. That means if you do a bunch of work in an async block without an await point, that future will block any other futures from making progress. You may sometimes hear this referred to as one future starving other futures. In some cases, that may not be a big deal. However, if you are doing some kind of expensive setup or long-running work, or if you have a future that will